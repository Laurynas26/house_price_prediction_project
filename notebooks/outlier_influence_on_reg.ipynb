{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74332b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "tracking_uri = \"../logs/mlruns\"\n",
    "os.makedirs(os.path.join(tracking_uri, \".trash\"), exist_ok=True)\n",
    "\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "mlflow.set_experiment(\"house_price_prediction\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3119169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "\n",
    "# Adjust the path to your project root folder\n",
    "project_root = os.path.abspath(\n",
    "    os.path.join(\"..\")\n",
    ")  # from notebooks/ up one level\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from src.data_loading.data_loading.data_loader import load_data_from_json\n",
    "from src.data_loading.preprocessing.preprocessing import preprocess_df\n",
    "from src.data_loading.preprocessing.imputation import impute_missing_values\n",
    "\n",
    "\n",
    "# go two levels up from notebook dir -> project root\n",
    "ROOT = (\n",
    "    Path(__file__).resolve().parents[2]\n",
    "    if \"__file__\" in globals()\n",
    "    else Path.cwd().parents[1]\n",
    ")\n",
    "CONFIG_PATH = (\n",
    "    ROOT\n",
    "    / \"house_price_prediction_project\"\n",
    "    / \"config\"\n",
    "    / \"preprocessing_config.yaml\"\n",
    ")\n",
    "\n",
    "with open(CONFIG_PATH) as f:\n",
    "    CONFIG = yaml.safe_load(f)\n",
    "\n",
    "df_raw = load_data_from_json(\"../data/parsed_json/*.json\")\n",
    "df_clean = preprocess_df(\n",
    "    df_raw,\n",
    "    drop_raw=CONFIG[\"preprocessing\"][\"drop_raw\"],\n",
    "    numeric_cols=CONFIG[\"preprocessing\"][\"numeric_cols\"],\n",
    ")\n",
    "df_clean = impute_missing_values(\n",
    "    df_clean, CONFIG[\"preprocessing\"][\"imputation\"]\n",
    ")\n",
    "# Drop price_num NaNs for the training of the model\n",
    "df_clean = df_clean[df_clean[\"price_num\"].notna()]\n",
    "df_clean.drop(columns=[\"living_area\"], inplace=True)\n",
    "\n",
    "####\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# # Copy to avoid mutating original df\n",
    "# df_outlier_test = df_clean.copy()\n",
    "\n",
    "# # Numeric features only\n",
    "# numeric_cols = df_outlier_test.select_dtypes(include=['number']).columns\n",
    "# X_numeric = df_outlier_test[numeric_cols]\n",
    "\n",
    "# # 1️⃣ Detect outliers with IsolationForest\n",
    "# iso = IsolationForest(\n",
    "#     contamination=0.02,  # ~2% of data flagged as outliers, tune as needed\n",
    "#     random_state=42\n",
    "# )\n",
    "# outlier_labels = iso.fit_predict(X_numeric)\n",
    "\n",
    "# # 2️⃣ Separate outliers and inliers\n",
    "# mask_outliers = outlier_labels == -1\n",
    "# df_outliers = df_outlier_test[mask_outliers].reset_index(drop=True)\n",
    "# df_inliers = df_outlier_test[~mask_outliers].reset_index(drop=True)\n",
    "\n",
    "# print(f\"Original shape: {df_outlier_test.shape}\")\n",
    "# print(f\"Outliers detected: {df_outliers.shape[0]}\")\n",
    "\n",
    "# # 3️⃣ Winsorize only the upper tail (99th percentile of inliers)\n",
    "# winsor_limits = {}\n",
    "# df_winsorized = df_outlier_test.copy()\n",
    "\n",
    "# for col in numeric_cols:\n",
    "#     upper_limit = np.percentile(df_inliers[col], 95)\n",
    "#     winsor_limits[col] = upper_limit\n",
    "#     # Track which rows are capped\n",
    "#     capped_mask = df_winsorized[col] > upper_limit\n",
    "#     df_winsorized.loc[capped_mask, col] = upper_limit\n",
    "#     if capped_mask.any():\n",
    "#         print(f\"{capped_mask.sum()} rows in '{col}' capped at {upper_limit:.2f}\")\n",
    "\n",
    "# print(\"Winsorizing applied: only upper extremes capped.\")\n",
    "\n",
    "# # ✅ Now df_winsorized can be used for modeling\n",
    "\n",
    "# Now df_outlier_test has all rows, but extreme numeric values are capped\n",
    "# df_clean = df_winsorized.copy()\n",
    "####\n",
    "\n",
    "# df_clean = df_clean[:100] \n",
    "df = df_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b444b72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.data_prep_for_modelling.data_preparation import prepare_data\n",
    "\n",
    "FEATURES_CONFIG_PATH = (\n",
    "    ROOT / \"house_price_prediction_project\" / \"config\" / \"model_config.yaml\"\n",
    ")\n",
    "\n",
    "# Scaled features (applies scaling according to YAML)\n",
    "X_train_scaled, X_test_scaled, y_train, y_test, X_val, y_val, scaler, _ = prepare_data(\n",
    "    df,\n",
    "    config_path=FEATURES_CONFIG_PATH,\n",
    "    model_name=\"linear_regression\",  # uses the unified YAML key\n",
    "    use_extended_features=False,       # set True if you want extended features\n",
    "    cv=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de64fb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.evaluate import ModelEvaluator\n",
    "from src.model.mlflow_logger import MLFlowLogger\n",
    "\n",
    "evaluator = ModelEvaluator()\n",
    "logger = MLFlowLogger()\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# Evaluate\n",
    "trained_lr, y_train_pred, y_val_pred, y_test_pred, lr_results = evaluator.evaluate(\n",
    "    model=lr_model,\n",
    "    X_train=X_train_scaled,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test_scaled,\n",
    "    y_test=y_test,\n",
    "    model_params={},   \n",
    "    fit_params={},     \n",
    "    use_xgb_train=False\n",
    ")\n",
    "\n",
    "# Log the model and results\n",
    "logger.log_model(trained_lr, \"LinearRegression\", lr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b7fce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.feature_engineering.encoding import encode_energy_label\n",
    "\n",
    "X_train, X_test, y_train, y_test, scaler, X_val, y_val, _ = prepare_data(\n",
    "    df_clean,\n",
    "    config_path=FEATURES_CONFIG_PATH, \n",
    "    model_name=\"random_forest\",\n",
    "    use_extended_features=False,     \n",
    "    cv=False \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45d8c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor()\n",
    "\n",
    "trained_rf, y_train_pred, y_val_pred, y_test_pred, rf_results = evaluator.evaluate(\n",
    "    model=rf_model,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    model_params={},  \n",
    "    fit_params={},    \n",
    "    use_xgb_train=False\n",
    ")\n",
    "logger.log_model(trained_rf, \"RandomForestRegression\", rf_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bd0ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.utils import load_model_config_and_search_space\n",
    "\n",
    "X_train, X_test, y_train, y_test, X_val, y_val, scaler, _ = prepare_data(\n",
    "    df_clean, config_path=FEATURES_CONFIG_PATH, model_name=\"xgboost\", \n",
    "    use_extended_features=False, cv=False\n",
    ")\n",
    "\n",
    "MODEL_CONFIG_PATH = (\n",
    "    ROOT / \"house_price_prediction_project\" / \"config\" / \"model_config.yaml\"\n",
    ")\n",
    "\n",
    "model_params, fit_params, _ = load_model_config_and_search_space(\n",
    "    MODEL_CONFIG_PATH, model_name=\"xgboost\"\n",
    ")\n",
    "fit_params_safe = fit_params.copy()\n",
    "n_estimators = fit_params_safe.pop(\"n_estimators\", 100)  \n",
    "\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=n_estimators,\n",
    "    **model_params\n",
    ")\n",
    "\n",
    "trained_xgb, y_train_pred, y_val_pred, y_test_pred, xgb_results = evaluator.evaluate(\n",
    "    xgb_model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    fit_params=fit_params_safe, \n",
    "    use_xgb_train=False,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    ")\n",
    "logger.log_model(trained_xgb, \"XGBoostRegression\", xgb_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e904564f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a979685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, X_val, y_val, scaler, _ = prepare_data(\n",
    "    df_clean,\n",
    "    config_path=FEATURES_CONFIG_PATH,\n",
    "    model_name=\"xgboost_early_stopping\",\n",
    "    use_extended_features=False,\n",
    "    cv=False,\n",
    ")\n",
    "\n",
    "xgb_model_params, xgb_fit_params, _ = load_model_config_and_search_space(\n",
    "    MODEL_CONFIG_PATH, \"xgboost_early_stopping\"\n",
    ")\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(**xgb_model_params)\n",
    "\n",
    "\n",
    "trained_xgb, y_train_pred, y_val_pred, y_test_pred, xgb_results = evaluator.evaluate(\n",
    "    None,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    fit_params=xgb_fit_params,\n",
    "    model_params=xgb_model_params,\n",
    "    use_xgb_train=True,  \n",
    ")\n",
    "\n",
    "logger.log_model(\n",
    "    trained_xgb, \"xgb_with_early_stopping\", xgb_results, use_xgb_train=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521546b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize evaluator with log-transform if used\n",
    "evaluator = ModelEvaluator(target_transform=np.log1p, inverse_transform=np.expm1)\n",
    "xgb_model = xgb.XGBRegressor(**xgb_model_params)\n",
    "\n",
    "\n",
    "trained_xgb, y_train_pred, y_val_pred, y_test_pred, xgb_results = evaluator.evaluate(\n",
    "    None,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    fit_params=xgb_fit_params,\n",
    "    model_params=xgb_model_params,\n",
    "    use_xgb_train=True,  \n",
    ")\n",
    "\n",
    "logger.log_model(\n",
    "    trained_xgb, \"xgb_with_early_stopping\", xgb_results, use_xgb_train=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895be2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# Outlier removal\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Copy to avoid mutating original df\n",
    "df_outlier_test = df_clean.copy()\n",
    "\n",
    "# 1️⃣ Select only numeric features for outlier detection\n",
    "numeric_cols = df_outlier_test.select_dtypes(include=['number']).columns\n",
    "X_numeric = df_outlier_test[numeric_cols]\n",
    "\n",
    "# 2️⃣ Fit IsolationForest on numeric subset\n",
    "iso = IsolationForest(\n",
    "    contamination=0.02,  # ~2% flagged as outliers (tune this!)\n",
    "    random_state=42\n",
    ")\n",
    "outlier_labels = iso.fit_predict(X_numeric)\n",
    "\n",
    "# 3️⃣ Filter outliers (label = -1 are outliers)\n",
    "df_no_outliers = df_outlier_test[outlier_labels == 1].reset_index(drop=True)\n",
    "\n",
    "print(f\"Original shape: {df_outlier_test.shape}\")\n",
    "print(f\"After removing outliers: {df_no_outliers.shape}\")\n",
    "\n",
    "# Rows removed (outliers)\n",
    "mask_outliers = outlier_labels == -1\n",
    "df_removed = df_outlier_test[mask_outliers].reset_index(drop=True)\n",
    "\n",
    "df_clean_no_outliers = df_no_outliers.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236df650",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, X_val, y_val, scaler, _ = prepare_data(\n",
    "    df_clean_no_outliers,\n",
    "    config_path=FEATURES_CONFIG_PATH,\n",
    "    model_name=\"xgboost_early_stopping\",\n",
    "    use_extended_features=False,\n",
    "    cv=False,\n",
    ")\n",
    "\n",
    "xgb_model_params, xgb_fit_params, _ = load_model_config_and_search_space(\n",
    "    MODEL_CONFIG_PATH, \"xgboost_early_stopping\"\n",
    ")\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(**xgb_model_params)\n",
    "\n",
    "\n",
    "trained_xgb, y_train_pred, y_val_pred, y_test_pred, xgb_results = evaluator.evaluate(\n",
    "    None,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    fit_params=xgb_fit_params,\n",
    "    model_params=xgb_model_params,\n",
    "    use_xgb_train=True,  \n",
    ")\n",
    "\n",
    "logger.log_model(\n",
    "    trained_xgb, \"xgb_with_early_stopping\", xgb_results, use_xgb_train=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae305c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "sns.set(style=\"whitegrid\", font_scale=1.1)\n",
    "\n",
    "# --- Define results ---\n",
    "results = {\n",
    "    \"Pre Outlier Removal\": {\n",
    "        'Test RMSE (€)': 230288.89126193404,\n",
    "        'Test MAE (€)': 77554.62162063953\n",
    "    },\n",
    "    \"Post Outlier Removal\": {\n",
    "        'Test RMSE (€)': 108337.01919120285,\n",
    "        'Test MAE (€)': 53868.54959964413\n",
    "    }\n",
    "}\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "bar_width = 0.35\n",
    "colors = ['skyblue', 'orange']\n",
    "\n",
    "# ---------- RMSE & MAE ----------\n",
    "metrics = df_results.index\n",
    "y_pos = np.arange(len(metrics))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.barh(y_pos - bar_width/2, df_results['Pre Outlier Removal'], height=bar_width, color=colors[0], label='Pre Outlier Removal')\n",
    "plt.barh(y_pos + bar_width/2, df_results['Post Outlier Removal'], height=bar_width, color=colors[1], label='Post Outlier Removal')\n",
    "plt.yticks(y_pos, metrics)\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "# Data labels\n",
    "for i, metric in enumerate(metrics):\n",
    "    pre_val = df_results.loc[metric, 'Pre Outlier Removal']\n",
    "    post_val = df_results.loc[metric, 'Post Outlier Removal']\n",
    "    plt.text(pre_val + 5000, i - bar_width/2, f\"{pre_val:,.0f}\", va='center', fontsize=10)\n",
    "    plt.text(post_val + 5000, i + bar_width/2, f\"{post_val:,.0f}\", va='center', fontsize=10)\n",
    "\n",
    "plt.xlabel(\"Error (€)\")\n",
    "plt.title(\"XGBoost with Early Stopping: Test RMSE & MAE Pre vs Post Outlier Removal\")\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1,0.5))\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d79b7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "sns.set(style=\"whitegrid\", font_scale=1.1)\n",
    "\n",
    "# --- Define results ---\n",
    "results = {\n",
    "    \"Pre Outlier Removal\": {\n",
    "        'Test RMSE (€)': 230288.89,\n",
    "        'Test MAE (€)': 77554.62\n",
    "    },\n",
    "    \"Post Outlier Removal\": {\n",
    "        'Test RMSE (€)': 108337.02,\n",
    "        'Test MAE (€)': 53868.55\n",
    "    },\n",
    "    \"Last Week Model\": {\n",
    "        'Test RMSE (€)': 211172,\n",
    "        'Test MAE (€)': 72964\n",
    "    }\n",
    "}\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Bar parameters\n",
    "bar_width = 0.25\n",
    "colors = ['skyblue', 'orange', 'green']\n",
    "\n",
    "metrics = df_results.index\n",
    "y_pos = np.arange(len(metrics))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Horizontal bars: three bars per metric\n",
    "plt.barh(y_pos - bar_width, df_results['Pre Outlier Removal'], height=bar_width, color=colors[0], label='Pre Outlier Removal')\n",
    "plt.barh(y_pos, df_results['Post Outlier Removal'], height=bar_width, color=colors[1], label='Post Outlier Removal')\n",
    "plt.barh(y_pos + bar_width, df_results['Last Week Model'], height=bar_width, color=colors[2], label='Last Week XGB + Optuna + basic FE')\n",
    "\n",
    "plt.yticks(y_pos, metrics)\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "# Data labels\n",
    "for i, metric in enumerate(metrics):\n",
    "    for j, col in enumerate(df_results.columns):\n",
    "        val = df_results.loc[metric, col]\n",
    "        plt.text(val + 5000, i - bar_width + j*bar_width, f\"{val:,.0f}\", va='center', fontsize=10)\n",
    "\n",
    "plt.xlabel(\"Error (€)\")\n",
    "plt.title(\"XGBoost Test RMSE & MAE: Pre vs Post Outlier Removal vs Last Week Model\")\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1,0.5))\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1072139b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "sns.set(style=\"whitegrid\", font_scale=1.1)\n",
    "\n",
    "# Assume 'df_clean' has the 'price' column\n",
    "prices = df_clean['price_num']\n",
    "\n",
    "# Log-transform\n",
    "log_prices = np.log1p(prices)  # log1p to handle zeros if any\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# ---------- Raw Price ----------\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(prices, bins=60, color='skyblue', alpha=0.7)\n",
    "plt.title(\"Raw Price Distribution\")\n",
    "plt.xlabel(\"Price (€)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# ---------- Log-Transformed Price ----------\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(log_prices, bins=60, color='orange', alpha=0.7)\n",
    "plt.title(\"Log-Transformed Price Distribution\")\n",
    "plt.xlabel(\"Log(Price + 1)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eb1e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "sns.set(style=\"whitegrid\", font_scale=1.1)\n",
    "\n",
    "prices = df_clean['price_num']\n",
    "log_prices = np.log1p(prices)  # log(1 + price)\n",
    "\n",
    "# 99th percentile threshold\n",
    "p99 = np.percentile(prices, 99)\n",
    "extremes = prices[prices > p99]\n",
    "max_val = extremes.max()\n",
    "num_extremes = len(extremes)\n",
    "\n",
    "# Formatter for raw prices\n",
    "def euro_formatter(x, pos):\n",
    "    return f\"€{int(x/1000):,}k\"  # show in thousands with k\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# ---------- Raw Price (capped at 99th percentile) ----------\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(prices[prices <= p99], bins=60, color='skyblue', alpha=0.7)\n",
    "plt.axvline(p99, color='red', linestyle='--', linewidth=2, label='99th percentile')\n",
    "\n",
    "# Annotate extreme outliers\n",
    "plt.text(p99 * 1.02, plt.gca().get_ylim()[1]*0.8, \n",
    "         f\"{num_extremes} extreme listings\\nup to €{int(max_val):,}\", \n",
    "         color='red', fontsize=10, ha='left', va='top')\n",
    "\n",
    "plt.title(\"Raw Price Distribution (capped at 99th percentile)\")\n",
    "plt.xlabel(\"Price (€)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.gca().xaxis.set_major_formatter(FuncFormatter(euro_formatter))\n",
    "\n",
    "# ---------- Log-Transformed Price ----------\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(log_prices, bins=60, color='orange', alpha=0.7)\n",
    "plt.title(\"Log-Transformed Price Distribution\")\n",
    "plt.xlabel(\"Log(Price + 1)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694c1d1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
