{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "#### 1. Imports and Set-up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "mlflow.set_tracking_uri(\"../logs/mlruns\")\n",
    "mlflow.set_experiment(\"house_price_prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "#### 2. Load and prep data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "\n",
    "# Adjust the path to your project root folder\n",
    "project_root = os.path.abspath(\n",
    "    os.path.join(\"..\")\n",
    ")  # from notebooks/ up one level\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from src.data_loading.data_loading.data_loader import load_data_from_json\n",
    "from src.data_loading.preprocessing.preprocessing import preprocess_df\n",
    "from src.data_loading.preprocessing.imputation import impute_missing_values\n",
    "\n",
    "\n",
    "# go two levels up from notebook dir -> project root\n",
    "ROOT = (\n",
    "    Path(__file__).resolve().parents[2]\n",
    "    if \"__file__\" in globals()\n",
    "    else Path.cwd().parents[1]\n",
    ")\n",
    "CONFIG_PATH = (\n",
    "    ROOT\n",
    "    / \"house_price_prediction_project\"\n",
    "    / \"config\"\n",
    "    / \"preprocessing_config.yaml\"\n",
    ")\n",
    "\n",
    "with open(CONFIG_PATH) as f:\n",
    "    CONFIG = yaml.safe_load(f)\n",
    "\n",
    "df_raw = load_data_from_json(\"../data/parsed_json/*.json\")\n",
    "df_clean = preprocess_df(\n",
    "    df_raw,\n",
    "    drop_raw=CONFIG[\"preprocessing\"][\"drop_raw\"],\n",
    "    numeric_cols=CONFIG[\"preprocessing\"][\"numeric_cols\"],\n",
    ")\n",
    "df_clean = impute_missing_values(\n",
    "    df_clean, CONFIG[\"preprocessing\"][\"imputation\"]\n",
    ")\n",
    "# Drop price_num NaNs for the training of the model\n",
    "df = df_clean[df_clean[\"price_num\"].notna()]\n",
    "df = df_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_year(year):\n",
    "#     if isinstance(year, str):\n",
    "#         if year.startswith(\"Voor\"):  # e.g., \"Voor 1906\"\n",
    "#             return int(year.split()[-1]) - 1  # use 1905\n",
    "#         elif year.startswith(\"Na\"):  # e.g., \"Na 2020\"\n",
    "#             return int(year.split()[-1]) + 1  # use 2021\n",
    "#         elif year.isdigit():\n",
    "#             return int(year)\n",
    "#         else:\n",
    "#             return None  # invalid string\n",
    "#     elif isinstance(year, (int, float)):\n",
    "#         return int(year)\n",
    "#     else:\n",
    "#         return None\n",
    "\n",
    "\n",
    "# df[\"year_of_construction\"] = df[\"year_of_construction\"].apply(clean_year)\n",
    "# df[\"year_of_construction\"] = df[\"year_of_construction\"].fillna(\n",
    "#     df[\"year_of_construction\"].median()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric_cols = [\"bedrooms\", \"nr_rooms\", \"bathrooms\", \"toilets\"]\n",
    "\n",
    "# df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_features = [\n",
    "    \"size_num\",\n",
    "    \"bedrooms\",\n",
    "    \"year_of_construction\",\n",
    "    \"nr_rooms\",\n",
    "    \"bathrooms\",\n",
    "    \"toilets\",\n",
    "    \"contribution_vve_num\",\n",
    "    \"external_storage_num\",\n",
    "    \"inhabitants_in_neighborhood\",\n",
    "    \"families_with_children_pct\",\n",
    "    \"price_per_m2_neighborhood\",\n",
    "]\n",
    "target = \"price_num\"\n",
    "\n",
    "X = df[linear_features].replace(\"N/A\", np.nan).fillna(0)\n",
    "y = df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "#### 3. Code for evaluating and logging models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    model, X_train, y_train, X_test, y_test, metrics=None, fit_params=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Fit model, predict, and return evaluation metrics.\n",
    "    \"\"\"\n",
    "    if fit_params is None:\n",
    "        fit_params = {}\n",
    "    model.fit(X_train, y_train, **fit_params)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    results = {}\n",
    "    if metrics is None:\n",
    "        metrics = {\n",
    "            \"rmse\": lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred)),\n",
    "            \"mea\": lambda y, y_pred: mean_absolute_error(y, y_pred),\n",
    "            \"r2\": r2_score,\n",
    "        }\n",
    "\n",
    "    for name, func in metrics.items():\n",
    "        results[f\"train_{name}\"] = func(y_train, y_train_pred)\n",
    "        results[f\"test_{name}\"] = func(y_test, y_test_pred)\n",
    "\n",
    "    return model, results\n",
    "\n",
    "\n",
    "def log_to_mlflow(model, model_name, results):\n",
    "    \"\"\"\n",
    "    Log model and metrics to MLflow.\n",
    "    \"\"\"\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        mlflow.sklearn.log_model(model, f\"{model_name}_model\")\n",
    "        mlflow.log_metrics(results)\n",
    "        if hasattr(model, \"get_params\"):\n",
    "            mlflow.log_params(model.get_params())\n",
    "        print(f\"{model_name} -> {results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "#### 4. Linear Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, lr_results = evaluate_model(\n",
    "    LinearRegression(), X_train_scaled, y_train, X_test_scaled, y_test\n",
    ")\n",
    "log_to_mlflow(lr, \"Linear_Regression\", lr_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "#### 5. Random Forest Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = [\n",
    "    \"size_num\",\n",
    "    \"bedrooms\",\n",
    "    \"energy_label\",\n",
    "    \"year_of_construction\",\n",
    "    \"nr_rooms\",\n",
    "    \"bathrooms\",\n",
    "    \"toilets\",\n",
    "    \"contribution_vve_num\",\n",
    "    \"external_storage_num\",\n",
    "    \"has_mechanische_ventilatie\",\n",
    "    \"has_tv_kabel\",\n",
    "    \"has_lift\",\n",
    "    \"has_natuurlijke_ventilatie\",\n",
    "    \"has_n/a\",\n",
    "    \"has_schuifpui\",\n",
    "    \"has_glasvezelkabel\",\n",
    "    \"has_frans_balkon\",\n",
    "    \"has_buitenzonwering\",\n",
    "    \"has_zonnepanelen\",\n",
    "    \"has_airconditioning\",\n",
    "    \"has_balansventilatie\",\n",
    "    \"has_dakraam\",\n",
    "    \"has_alarminstallatie\",\n",
    "    \"has_domotica\",\n",
    "    \"has_rookkanaal\",\n",
    "    \"has_elektra\",\n",
    "    \"has_sauna\",\n",
    "    \"has_zonnecollectoren\",\n",
    "    \"has_cctv\",\n",
    "    \"has_rolluiken\",\n",
    "    \"has_stromend_water\",\n",
    "    \"has_satellietschotel\",\n",
    "    \"num_facilities\",\n",
    "    \"inhabitants_in_neighborhood\",\n",
    "    \"families_with_children_pct\",\n",
    "    \"price_per_m2_neighborhood\",\n",
    "]\n",
    "\n",
    "X = df[all_features].replace(\"N/A\", np.nan).fillna(0)\n",
    "\n",
    "X[\"energy_label\"] = X[\"energy_label\"].replace({0: \"G\"})\n",
    "energy_order = [\n",
    "    \"G\",\n",
    "    \"F\",\n",
    "    \"E\",\n",
    "    \"D\",\n",
    "    \"C\",\n",
    "    \"B\",\n",
    "    \"A\",\n",
    "    \"A+\",\n",
    "    \"A++\",\n",
    "    \"A+++\",\n",
    "    \"A++++\",\n",
    "]\n",
    "encoder = OrdinalEncoder(categories=[energy_order])\n",
    "X[\"energy_label_encoded\"] = encoder.fit_transform(X[[\"energy_label\"]])\n",
    "X = X.drop(columns=[\"energy_label\"])\n",
    "\n",
    "y = df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.energy_label_encoded.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf, rf_results = evaluate_model(\n",
    "    RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42),\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    ")\n",
    "log_to_mlflow(rf, \"Random_Forest_Regression\", rf_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "#### 6. XGBoost model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=500, max_depth=6, learning_rate=0.05, random_state=42\n",
    ")\n",
    "xgb_model, results = evaluate_model(\n",
    "    xgb_model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    ")\n",
    "log_to_mlflow(xgb_model, \"XGBoost_Regression\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "#### 7. XGBoost with early stopping and more tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Convert to DMatrix\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Parameters\n",
    "params = {\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"max_depth\": 6,\n",
    "    \"eta\": 0.05,\n",
    "    \"seed\": 42,\n",
    "}\n",
    "\n",
    "# Train with early stopping\n",
    "xgb_model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=500,\n",
    "    evals=[(dtest, \"eval\")],\n",
    "    early_stopping_rounds=50,\n",
    "    verbose_eval=False,\n",
    ")\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = xgb_model.predict(dtrain)\n",
    "y_test_pred = xgb_model.predict(dtest)\n",
    "\n",
    "# Metrics\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\n",
    "    f\"Train RMSE: {train_rmse:.2f}, MAE: {train_mae:.2f}, train_R²: {train_r2:.3f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Test RMSE: {test_rmse:.2f}, MAE: {test_mae:.2f}, test_R²: {test_r2:.3f}\"\n",
    ")\n",
    "\n",
    "with mlflow.start_run(run_name=\"XGBoost_Regression\"):\n",
    "    # Log model\n",
    "    mlflow.xgboost.log_model(xgb_model, artifact_path=\"xgb_model\")\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "    mlflow.log_metric(\"train_mae\", train_mae)\n",
    "    mlflow.log_metric(\"test_mae\", test_mae)\n",
    "    mlflow.log_metric(\"train_r2\", train_r2)\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "#### 7. Compare models using MLflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"house_price_prediction\"\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "experiment_id = experiment.experiment_id\n",
    "\n",
    "\n",
    "runs_df = mlflow.search_runs(experiment_ids=[experiment_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_of_interest = [\n",
    "    \"metrics.train_rmse\",\n",
    "    \"metrics.test_rmse\",\n",
    "    \"metrics.train_r2\",\n",
    "    \"metrics.test_r2\",\n",
    "]\n",
    "comparison_df = runs_df[\n",
    "    [\"run_id\", \"tags.mlflow.runName\"] + metrics_of_interest\n",
    "]\n",
    "\n",
    "comparison_df.sort_values(\"metrics.test_r2\", ascending=False, inplace=True)\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = comparison_df.sort_values(\n",
    "    \"metrics.test_r2\", ascending=False\n",
    ").iloc[0]\n",
    "print(\"Best model based on test R²:\")\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "#### 8. Hyperparameter tuning with Optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_xgb(trial):\n",
    "    params = {\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"eta\": trial.suggest_float(\"eta\", 0.01, 0.3, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"seed\": 42,\n",
    "        \"tree_method\": \"hist\",\n",
    "    }\n",
    "\n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=1000,\n",
    "        evals=[(dtest, \"eval\")],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=False,\n",
    "    )\n",
    "\n",
    "    # Predictions\n",
    "    y_train_pred = model.predict(dtrain)\n",
    "    y_test_pred = model.predict(dtest)\n",
    "\n",
    "    # Metrics\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    print(\n",
    "        f\"Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}, Train R²: {train_r2:.3f}, Test R²: {test_r2:.3f}\"\n",
    "    )\n",
    "\n",
    "    # Optuna only optimizes one metric, here test RMSE\n",
    "    return test_rmse\n",
    "\n",
    "\n",
    "def objective_rf(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 1000),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 5, 30),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 4),\n",
    "        \"max_features\": trial.suggest_categorical(\n",
    "            \"max_features\", [\"sqrt\", \"log2\", None]\n",
    "        ),\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1,\n",
    "    }\n",
    "\n",
    "    model = RandomForestRegressor(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_xgb = optuna.create_study(direction=\"minimize\")\n",
    "study_xgb.optimize(objective_xgb, n_trials=30)\n",
    "\n",
    "print(\"Best XGBoost params:\", study_xgb.best_params)\n",
    "print(\"Best XGBoost Test RMSE:\", study_xgb.best_value)\n",
    "\n",
    "# Run Optuna for RandomForest\n",
    "study_rf = optuna.create_study(direction=\"minimize\")\n",
    "study_rf.optimize(objective_rf, n_trials=30)\n",
    "\n",
    "print(\"Best RF params:\", study_rf.best_params)\n",
    "print(\"Best RF Test RMSE:\", study_rf.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "#### 9. RF and Xgboost with best parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = RandomForestRegressor(**study_rf.best_params)\n",
    "best_rf, results_rf = evaluate_model(best_rf, X_train, y_train, X_test, y_test)\n",
    "log_to_mlflow(best_rf, \"RF_Optuna\", results_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_xgb_dmatrix(\n",
    "    params,\n",
    "    dtrain,\n",
    "    dtest,\n",
    "    run_name=\"XGBoost_Regression\",\n",
    "    num_boost_round=500,\n",
    "    early_stopping_rounds=50,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train and evaluate an XGBoost model using DMatrix + xgb.train,\n",
    "    log metrics and model to MLflow.\n",
    "    \"\"\"\n",
    "    # Train\n",
    "    xgb_model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        evals=[(dtest, \"eval\")],\n",
    "        early_stopping_rounds=early_stopping_rounds,\n",
    "        verbose_eval=False,\n",
    "    )\n",
    "\n",
    "    # Predictions\n",
    "    y_train_pred = xgb_model.predict(dtrain)\n",
    "    y_test_pred = xgb_model.predict(dtest)\n",
    "\n",
    "    # Metrics\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    results = {\n",
    "        \"train_rmse\": train_rmse,\n",
    "        \"test_rmse\": test_rmse,\n",
    "        \"train_mae\": train_mae,\n",
    "        \"test_mae\": test_mae,\n",
    "        \"train_r2\": train_r2,\n",
    "        \"test_r2\": test_r2,\n",
    "    }\n",
    "\n",
    "    print(\n",
    "        f\"Train RMSE: {train_rmse:.2f}, MAE: {train_mae:.2f}, train_R²: {train_r2:.3f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Test RMSE: {test_rmse:.2f}, MAE: {test_mae:.2f}, test_R²: {test_r2:.3f}\"\n",
    "    )\n",
    "\n",
    "    # Log to MLflow\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        mlflow.xgboost.log_model(xgb_model, artifact_path=\"xgb_model\")\n",
    "        mlflow.log_metrics(results)\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "    return xgb_model, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study_xgb.best_params\n",
    "best_params.update(\n",
    "    {\"objective\": \"reg:squarederror\", \"seed\": 42, \"tree_method\": \"hist\"}\n",
    ")\n",
    "best_xgb, results_xgb = evaluate_xgb_dmatrix(\n",
    "    best_params, dtrain, dtest, run_name=\"XGB_Optuna\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "#### 10. Let's see how outliers skew RMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot target distribution\n",
    "sns.boxplot(y=y_test)\n",
    "plt.show()\n",
    "\n",
    "# Optional: scatter of predictions vs true values\n",
    "plt.scatter(y_test, y_test_pred, alpha=0.5)\n",
    "plt.xlabel(\"True\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute residuals\n",
    "residuals = y_test - y_test_pred\n",
    "\n",
    "# Summary stats\n",
    "print(\"Residuals summary:\")\n",
    "print(\"Min:\", np.min(residuals))\n",
    "print(\"Max:\", np.max(residuals))\n",
    "print(\"Median:\", np.median(residuals))\n",
    "print(\"Mean:\", np.mean(residuals))\n",
    "print(\"Std:\", np.std(residuals))\n",
    "\n",
    "# Plot histogram\n",
    "plt.hist(residuals, bins=50)\n",
    "plt.title(\"Residuals Distribution\")\n",
    "plt.xlabel(\"Residual\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Train MAE: {train_mae:.2f}\")\n",
    "print(f\"Test MAE:  {test_mae:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "So outliers are skewing the RMSE statistic quite heavily. Hence, I will log transform the target and dot he same analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_log = np.log1p(y_train)  # log(1 + price)\n",
    "y_test_log = np.log1p(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_log(model, X_train, y_train_log, X_test, y_test_log):\n",
    "    \"\"\"Fit model on log-transformed target and compute predictions on original scale.\"\"\"\n",
    "\n",
    "    # Fit model\n",
    "    model.fit(X_train, y_train_log)\n",
    "\n",
    "    # Predict and back-transform\n",
    "    y_train_pred = np.expm1(model.predict(X_train))\n",
    "    y_test_pred = np.expm1(model.predict(X_test))\n",
    "\n",
    "    # Metrics\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    results = {\n",
    "        \"train_rmse\": train_rmse,\n",
    "        \"test_rmse\": test_rmse,\n",
    "        \"train_mae\": train_mae,\n",
    "        \"test_mae\": test_mae,\n",
    "        \"train_r2\": train_r2,\n",
    "        \"test_r2\": test_r2,\n",
    "    }\n",
    "\n",
    "    # Residuals\n",
    "    residuals = y_test - y_test_pred\n",
    "\n",
    "    # Plot residuals\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.hist(residuals, bins=50)\n",
    "    plt.title(\"Residuals Distribution\")\n",
    "    plt.xlabel(\"Residual\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()\n",
    "\n",
    "    return model, results, y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42)\n",
    "rf, rf_results, rf_pred = evaluate_model_log(\n",
    "    rf, X_train, y_train_log, X_test, y_test_log\n",
    ")\n",
    "log_to_mlflow(rf, \"RF_LogTransform\", rf_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_xgb_dmatrix_log(\n",
    "    params,\n",
    "    dtrain,\n",
    "    dtest,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    run_name=\"XGBoost_Regression_Log\",\n",
    "    num_boost_round=500,\n",
    "    early_stopping_rounds=50,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train and evaluate an XGBoost model using DMatrix + xgb.train on log-transformed target,\n",
    "    log metrics and model to MLflow.\n",
    "\n",
    "    y_train, y_test: original (untransformed) target arrays, used for computing metrics on original scale.\n",
    "    \"\"\"\n",
    "    # Train\n",
    "    xgb_model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        evals=[(dtest, \"eval\")],\n",
    "        early_stopping_rounds=early_stopping_rounds,\n",
    "        verbose_eval=False,\n",
    "    )\n",
    "\n",
    "    # Predictions on log scale\n",
    "    y_train_pred_log = xgb_model.predict(dtrain)\n",
    "    y_test_pred_log = xgb_model.predict(dtest)\n",
    "\n",
    "    # Back-transform to original scale\n",
    "    y_train_pred = np.expm1(y_train_pred_log)\n",
    "    y_test_pred = np.expm1(y_test_pred_log)\n",
    "\n",
    "    # Metrics\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    results = {\n",
    "        \"train_rmse\": train_rmse,\n",
    "        \"test_rmse\": test_rmse,\n",
    "        \"train_mae\": train_mae,\n",
    "        \"test_mae\": test_mae,\n",
    "        \"train_r2\": train_r2,\n",
    "        \"test_r2\": test_r2,\n",
    "    }\n",
    "\n",
    "    print(\n",
    "        f\"Train RMSE: {train_rmse:.2f}, MAE: {train_mae:.2f}, R²: {train_r2:.3f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Test RMSE: {test_rmse:.2f}, MAE: {test_mae:.2f}, R²: {test_r2:.3f}\"\n",
    "    )\n",
    "\n",
    "    # Residuals\n",
    "    residuals = y_test - y_test_pred\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.hist(residuals, bins=50)\n",
    "    plt.title(\"Residuals Distribution\")\n",
    "    plt.xlabel(\"Residual\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()\n",
    "\n",
    "    # Log to MLflow\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        mlflow.xgboost.log_model(xgb_model, artifact_path=\"xgb_model\")\n",
    "        mlflow.log_metrics(results)\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "    return xgb_model, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-transform y for DMatrix\n",
    "dtrain = xgb.DMatrix(X_train, label=np.log1p(y_train))\n",
    "dtest = xgb.DMatrix(X_test, label=np.log1p(y_test))\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"max_depth\": 6,\n",
    "    \"eta\": 0.05,\n",
    "    \"seed\": 42,\n",
    "    \"tree_method\": \"hist\",\n",
    "}\n",
    "\n",
    "xgb_model_log, results_log = evaluate_xgb_dmatrix_log(\n",
    "    params, dtrain, dtest, y_train, y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute residuals\n",
    "residuals = y_test - y_test_pred\n",
    "\n",
    "# Define extreme outliers: e.g., top 5% of absolute residuals\n",
    "threshold = np.percentile(np.abs(residuals), 95)\n",
    "outliers_mask = np.abs(residuals) >= threshold\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot non-outliers\n",
    "plt.scatter(\n",
    "    y_test[~outliers_mask],\n",
    "    y_test_pred[~outliers_mask],\n",
    "    alpha=0.5,\n",
    "    label=\"Normal listings\",\n",
    ")\n",
    "\n",
    "# Highlight extreme residuals\n",
    "plt.scatter(\n",
    "    y_test[outliers_mask],\n",
    "    y_test_pred[outliers_mask],\n",
    "    color=\"red\",\n",
    "    label=\"Extreme listings\",\n",
    ")\n",
    "\n",
    "# Diagonal line (perfect prediction)\n",
    "max_val = max(y_test.max(), y_test_pred.max())\n",
    "plt.plot(\n",
    "    [0, max_val],\n",
    "    [0, max_val],\n",
    "    color=\"black\",\n",
    "    linestyle=\"--\",\n",
    "    label=\"Perfect prediction\",\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Actual Price (€)\")\n",
    "plt.ylabel(\"Predicted Price (€)\")\n",
    "plt.title(\"Predicted vs Actual Prices with Extreme Listings Highlighted\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "This is a clear visualization to see how predictions behave across the entire range and highlight the extreme listings that inflate RMSE. Large RMSE is not a deal breaker since:\n",
    "\n",
    "**Statistical justification**\n",
    "Skewed distribution: My dataset has a few extremely expensive houses that are far from the mean. RMSE is sensitive to large errors because it squares residuals, so these few points dominate the metric.\n",
    "\n",
    "MAE is more robust: By reporting MAE alongside RMSE, I show the typical prediction error for most listings, which is a fairer assessment of model performance.\n",
    "\n",
    "Log-transform mitigates skew: Training on log1p(y) reduces the influence of outliers and stabilizes variance, producing a more reliable model for the bulk of the data.\n",
    "\n",
    "**Practical/business justification**\n",
    "\n",
    "The extreme listings (multi-million € homes) are rare. The model performs well on 99% of listings, which is what matters for most users or business decisions.\n",
    "\n",
    "Trying to perfectly predict the top 1–5% of luxury listings would:\n",
    "\n",
    "Require specialized models or additional data\n",
    "\n",
    "Complicate the pipeline\n",
    "\n",
    "Increase overfitting risk\n",
    "\n",
    "Reporting MAE and residual distributions communicates clearly that errors on extreme listings exist, but are expected and do not invalidate the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "#### 11. New approach and moving with optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from optuna.integration import XGBoostPruningCallback\n",
    "\n",
    "\n",
    "# XGBoost objective for Optuna (optimize MAE)\n",
    "def objective_xgb(trial, X_train, y_train, X_test, y_test):\n",
    "    # Log-transform target\n",
    "    y_train_log = np.log1p(y_train)\n",
    "    y_test_log = np.log1p(y_test)\n",
    "\n",
    "    # Create DMatrix\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train_log)\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test_log)\n",
    "\n",
    "    # Hyperparameters\n",
    "    params = {\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"eval_metric\": \"mae\",\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"eta\": trial.suggest_float(\"eta\", 0.01, 0.3, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 5.0),\n",
    "        \"seed\": 42,\n",
    "        \"tree_method\": \"hist\",\n",
    "    }\n",
    "\n",
    "    pruning_callback = XGBoostPruningCallback(trial, \"eval-mae\")\n",
    "\n",
    "    # Train model\n",
    "    evals_result = {}\n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=2000,\n",
    "        evals=[(dtest, \"eval\")],\n",
    "        evals_result=evals_result,\n",
    "        early_stopping_rounds=100,\n",
    "        verbose_eval=False,\n",
    "        callbacks=[pruning_callback],\n",
    "    )\n",
    "\n",
    "    # Back-transform predictions\n",
    "    y_train_pred = np.expm1(model.predict(dtrain))\n",
    "    y_test_pred = np.expm1(model.predict(dtest))\n",
    "\n",
    "    # Report pruning metric\n",
    "    trial.report(\n",
    "        evals_result[\"eval\"][\"mae\"][model.best_iteration],\n",
    "        step=model.best_iteration,\n",
    "    )\n",
    "    if trial.should_prune():\n",
    "        raise optuna.TrialPruned()\n",
    "\n",
    "    # Compute MAE on original scale\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "    print(f\"Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\n",
    "\n",
    "    return test_mae  # Optuna optimizes this\n",
    "\n",
    "\n",
    "# Random Forest objective for Optuna (optimize MAE)\n",
    "def objective_rf(trial, X_train, y_train, X_test, y_test):\n",
    "    # Log-transform target\n",
    "    y_train_log = np.log1p(y_train)\n",
    "\n",
    "    # Hyperparameters\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 1000),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 5, 30),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 4),\n",
    "        \"max_features\": trial.suggest_categorical(\n",
    "            \"max_features\", [\"sqrt\", \"log2\", None]\n",
    "        ),\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1,\n",
    "    }\n",
    "\n",
    "    model = RandomForestRegressor(**params)\n",
    "    model.fit(X_train, y_train_log)\n",
    "\n",
    "    # Back-transform predictions\n",
    "    y_pred = np.expm1(model.predict(X_test))\n",
    "    test_mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    return test_mae  # Optuna optimizes this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Optuna for XGBoost\n",
    "sampler = optuna.samplers.TPESampler(seed=42)\n",
    "pruner = optuna.pruners.MedianPruner(n_warmup_steps=10)\n",
    "\n",
    "study_xgb = optuna.create_study(\n",
    "    direction=\"minimize\", sampler=sampler, pruner=pruner\n",
    ")\n",
    "study_xgb.optimize(\n",
    "    lambda trial: objective_xgb(trial, X_train, y_train, X_test, y_test),\n",
    "    n_trials=200,\n",
    ")\n",
    "\n",
    "print(\"Best XGBoost params:\", study_xgb.best_params)\n",
    "print(\"Best XGBoost Test MAE:\", study_xgb.best_value)\n",
    "\n",
    "# Run Optuna for Random Forest\n",
    "study_rf = optuna.create_study(\n",
    "    direction=\"minimize\", sampler=sampler, pruner=pruner\n",
    ")\n",
    "study_rf.optimize(\n",
    "    lambda trial: objective_rf(trial, X_train, y_train, X_test, y_test),\n",
    "    n_trials=100,\n",
    ")\n",
    "\n",
    "print(\"Best RF params:\", study_rf.best_params)\n",
    "print(\"Best RF Test MAE:\", study_rf.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_xgb_dmatrix(\n",
    "    params,\n",
    "    dtrain,\n",
    "    dtest,\n",
    "    y_train_orig,\n",
    "    y_test_orig,\n",
    "    run_name=\"XGBoost_Regression\",\n",
    "    num_boost_round=500,\n",
    "    early_stopping_rounds=50,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train and evaluate an XGBoost model using DMatrix + xgb.train,\n",
    "    with support for log-transformed targets.\n",
    "    Logs RMSE, MAE, R², and hyperparameters to MLflow.\n",
    "\n",
    "    Parameters:\n",
    "    - params: dict of XGBoost parameters\n",
    "    - dtrain, dtest: xgb.DMatrix (log-transformed labels)\n",
    "    - y_train_orig, y_test_orig: original target values (not log-transformed)\n",
    "    - run_name: MLflow run name\n",
    "    - num_boost_round: maximum number of boosting iterations\n",
    "    - early_stopping_rounds: rounds for early stopping\n",
    "    \"\"\"\n",
    "    # Train model\n",
    "    xgb_model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        evals=[(dtest, \"eval\")],\n",
    "        early_stopping_rounds=early_stopping_rounds,\n",
    "        verbose_eval=False,\n",
    "    )\n",
    "\n",
    "    # Predict and back-transform to original scale\n",
    "    y_train_pred = np.expm1(xgb_model.predict(dtrain))\n",
    "    y_test_pred = np.expm1(xgb_model.predict(dtest))\n",
    "\n",
    "    # Compute metrics\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train_orig, y_train_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test_orig, y_test_pred))\n",
    "    train_mae = mean_absolute_error(y_train_orig, y_train_pred)\n",
    "    test_mae = mean_absolute_error(y_test_orig, y_test_pred)\n",
    "    train_r2 = r2_score(y_train_orig, y_train_pred)\n",
    "    test_r2 = r2_score(y_test_orig, y_test_pred)\n",
    "\n",
    "    results = {\n",
    "        \"train_rmse\": train_rmse,\n",
    "        \"test_rmse\": test_rmse,\n",
    "        \"train_mae\": train_mae,\n",
    "        \"test_mae\": test_mae,\n",
    "        \"train_r2\": train_r2,\n",
    "        \"test_r2\": test_r2,\n",
    "    }\n",
    "\n",
    "    # Print summary\n",
    "    print(\n",
    "        f\"Train RMSE: {train_rmse:.2f}, MAE: {train_mae:.2f}, R²: {train_r2:.3f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Test RMSE: {test_rmse:.2f}, MAE: {test_mae:.2f}, R²: {test_r2:.3f}\"\n",
    "    )\n",
    "\n",
    "    # Log to MLflow\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        mlflow.xgboost.log_model(xgb_model, artifact_path=\"xgb_model\")\n",
    "        mlflow.log_metrics(results)\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "    return xgb_model, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert log1p targets\n",
    "dtrain = xgb.DMatrix(X_train, label=np.log1p(y_train))\n",
    "dtest = xgb.DMatrix(X_test, label=np.log1p(y_test))\n",
    "\n",
    "best_params = study_xgb.best_params\n",
    "best_params.update(\n",
    "    {\"objective\": \"reg:squarederror\", \"seed\": 42, \"tree_method\": \"hist\"}\n",
    ")\n",
    "\n",
    "best_xgb, results_xgb = evaluate_xgb_dmatrix(\n",
    "    best_params,\n",
    "    dtrain,\n",
    "    dtest,\n",
    "    y_train_orig=y_train,\n",
    "    y_test_orig=y_test,\n",
    "    run_name=\"XGB_Optuna_LogTransformed\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare log-transformed targets\n",
    "y_train_log = np.log1p(y_train)\n",
    "y_test_log = np.log1p(y_test)\n",
    "\n",
    "# Refit best RF on log targets and evaluate\n",
    "best_rf = RandomForestRegressor(**study_rf.best_params)\n",
    "best_rf, results_rf, y_test_pred = evaluate_model_log(\n",
    "    best_rf, X_train, y_train_log, X_test, y_test_log\n",
    ")\n",
    "\n",
    "# Log to MLflow\n",
    "log_to_mlflow(best_rf, \"RF_LogTransform_Optuna\", results_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"house_price_prediction\"\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "experiment_id = experiment.experiment_id\n",
    "\n",
    "\n",
    "runs_df = mlflow.search_runs(experiment_ids=[experiment_id])\n",
    "\n",
    "metrics_of_interest = [\n",
    "    \"metrics.train_rmse\",\n",
    "    \"metrics.test_rmse\",\n",
    "    \"metrics.train_r2\",\n",
    "    \"metrics.test_r2\",\n",
    "    \"metrics.train_mae\",\n",
    "    \"metrics.test_mae\",\n",
    "]\n",
    "comparison_df = runs_df[\n",
    "    [\"run_id\", \"tags.mlflow.runName\"] + metrics_of_interest\n",
    "]\n",
    "\n",
    "comparison_df.sort_values(\"metrics.test_mae\", ascending=True, inplace=True)\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = comparison_df.sort_values(\n",
    "    \"metrics.test_mae\", ascending=True\n",
    ").iloc[0]\n",
    "print(\"Best model based on test MAE:\")\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "#### 12. Extra feature engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "df = df.copy()\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Helper Functions\n",
    "# -----------------------\n",
    "def to_float(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    cleaned = re.sub(r\"[^\\d\\.]\", \"\", str(value))\n",
    "    return float(cleaned) if cleaned else np.nan\n",
    "\n",
    "\n",
    "def auto_log_transform(df, numeric_cols, threshold_skew=0.5):\n",
    "    log_cols = []\n",
    "    for col in numeric_cols:\n",
    "        if (df[col] > 0).all():\n",
    "            skewness = df[col].skew()\n",
    "            if abs(skewness) > threshold_skew:\n",
    "                df[f\"log_{col}\"] = np.log1p(df[col])\n",
    "                log_cols.append(f\"log_{col}\")\n",
    "    return log_cols\n",
    "\n",
    "\n",
    "def extract_floor(x):\n",
    "    if pd.isna(x) or x in [\"N/A\", \"Begane grond\"]:\n",
    "        return 0\n",
    "    match = re.search(r\"(\\d+)\", x)\n",
    "    return int(match.group(1)) if match else 0\n",
    "\n",
    "\n",
    "def simplify_roof(roof):\n",
    "    if pd.isna(roof) or roof == \"N/A\":\n",
    "        return \"Unknown\"\n",
    "    if \"Plat dak\" in roof:\n",
    "        return \"Flat\"\n",
    "    if \"Zadeldak\" in roof:\n",
    "        return \"Saddle\"\n",
    "    if \"Samengesteld dak\" in roof:\n",
    "        return \"Composite\"\n",
    "    if \"Mansarde\" in roof:\n",
    "        return \"Mansard\"\n",
    "    return \"Other\"\n",
    "\n",
    "\n",
    "def simplify_ownership(x):\n",
    "    if pd.isna(x) or x.strip() == \"\":\n",
    "        return \"Unknown\"\n",
    "    if \"Volle eigendom\" in x:\n",
    "        return \"Full\"\n",
    "    if \"Erfpacht\" in x and \"Gemeentelijk\" in x:\n",
    "        return \"Municipal\"\n",
    "    if \"Erfpacht\" in x:\n",
    "        return \"Leasehold\"\n",
    "    return \"Other\"\n",
    "\n",
    "\n",
    "def extract_lease_years(x, current_year=2025):\n",
    "    if pd.isna(x) or \"Volle eigendom\" in x or x.strip() == \"\":\n",
    "        return np.nan\n",
    "    match = re.search(r\"einddatum erfpacht: (\\d{2})-(\\d{2})-(\\d{4})\", x)\n",
    "    if match:\n",
    "        day, month, year = map(int, match.groups())\n",
    "        return max(year - current_year, 0)\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "def simplify_location(x):\n",
    "    if pd.isna(x):\n",
    "        return \"Unknown\"\n",
    "    if \"centrum\" in x:\n",
    "        return \"Central\"\n",
    "    if \"woonwijk\" in x:\n",
    "        return \"Residential\"\n",
    "    if \"vrij uitzicht\" in x:\n",
    "        return \"OpenView\"\n",
    "    if \"park\" in x:\n",
    "        return \"Park\"\n",
    "    return \"Other\"\n",
    "\n",
    "\n",
    "def drop_low_variance_dummies(df, threshold=0.95):\n",
    "    low_var_cols = [\n",
    "        col\n",
    "        for col in df.columns\n",
    "        if df[col].value_counts(normalize=True, dropna=False).iloc[0]\n",
    "        >= threshold\n",
    "    ]\n",
    "    return df.drop(columns=low_var_cols), low_var_cols\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 1. Numeric features\n",
    "# -----------------------\n",
    "numeric_features = [\n",
    "    \"size_num\",\n",
    "    \"contribution_vve_num\",\n",
    "    \"external_storage_num\",\n",
    "    \"living_area\",\n",
    "    \"nr_rooms\",\n",
    "    \"bathrooms\",\n",
    "    \"toilets\",\n",
    "    \"num_facilities\",\n",
    "    \"inhabitants_in_neighborhood\",\n",
    "    \"families_with_children_pct\",\n",
    "    \"price_per_m2_neighborhood\",\n",
    "]\n",
    "\n",
    "for col in numeric_features:\n",
    "    df[col] = df[col].apply(to_float)\n",
    "    df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "log_cols = auto_log_transform(df, numeric_features)\n",
    "\n",
    "# -----------------------\n",
    "# 2. Binary / flag features\n",
    "# -----------------------\n",
    "binary_flags = [\n",
    "    \"has_mechanische_ventilatie\",\n",
    "    \"has_tv_kabel\",\n",
    "    \"has_lift\",\n",
    "    \"has_natuurlijke_ventilatie\",\n",
    "    \"has_n/a\",\n",
    "    \"has_schuifpui\",\n",
    "    \"has_glasvezelkabel\",\n",
    "    \"has_frans_balkon\",\n",
    "    \"has_buitenzonwering\",\n",
    "    \"has_zonnepanelen\",\n",
    "    # Removed very low-variance flags here (optional)\n",
    "]\n",
    "\n",
    "for col in binary_flags:\n",
    "    df[col] = df[col].fillna(0).astype(int)\n",
    "\n",
    "# -----------------------\n",
    "# 3. Direct numeric features\n",
    "# -----------------------\n",
    "direct_numeric_features = [\n",
    "    \"bedrooms\",\n",
    "    \"year_of_construction\",\n",
    "    \"contribution_vve_num\",\n",
    "    \"size_num\",\n",
    "    \"external_storage_num\",\n",
    "    \"living_area\",\n",
    "    \"nr_rooms\",\n",
    "    \"bathrooms\",\n",
    "    \"toilets\",\n",
    "    \"num_facilities\",\n",
    "    \"floor_level\",\n",
    "    \"lease_years_remaining\",\n",
    "    \"backyard_num\",\n",
    "    \"balcony_flag\",\n",
    "]\n",
    "\n",
    "# -----------------------\n",
    "# 4. Energy label encoding\n",
    "# -----------------------\n",
    "df[\"energy_label\"] = df[\"energy_label\"].replace({0: \"G\"}).replace(\"N/A\", \"G\")\n",
    "energy_order = [\n",
    "    \"G\",\n",
    "    \"F\",\n",
    "    \"E\",\n",
    "    \"D\",\n",
    "    \"C\",\n",
    "    \"B\",\n",
    "    \"A\",\n",
    "    \"A+\",\n",
    "    \"A++\",\n",
    "    \"A+++\",\n",
    "    \"A++++\",\n",
    "]\n",
    "encoder_energy = OrdinalEncoder(categories=[energy_order], dtype=int)\n",
    "df[\"energy_label_encoded\"] = encoder_energy.fit_transform(df[[\"energy_label\"]])\n",
    "df.drop(columns=[\"energy_label\"], inplace=True)\n",
    "\n",
    "# -----------------------\n",
    "# 5. Categorical features (OHE)\n",
    "# -----------------------\n",
    "df[\"postal_district\"] = df[\"postal_code_clean\"].str[:3]\n",
    "postal_ohe = pd.get_dummies(\n",
    "    df[\"postal_district\"], prefix=\"district\", drop_first=True\n",
    ")\n",
    "\n",
    "df[\"status\"] = df[\"status\"].fillna(\"N/A\")\n",
    "status_ohe = pd.get_dummies(df[\"status\"], prefix=\"status\", drop_first=True)\n",
    "\n",
    "df[\"roof_type_simple\"] = df[\"roof_type\"].apply(simplify_roof)\n",
    "roof_ohe = pd.get_dummies(\n",
    "    df[\"roof_type_simple\"], prefix=\"roof\", drop_first=True\n",
    ")\n",
    "\n",
    "df[\"ownership_simple\"] = df[\"ownership_type\"].apply(simplify_ownership)\n",
    "ownership_ohe = pd.get_dummies(\n",
    "    df[\"ownership_simple\"], prefix=\"ownership\", drop_first=True\n",
    ")\n",
    "\n",
    "df[\"location_simple\"] = df[\"location\"].apply(simplify_location)\n",
    "location_ohe = pd.get_dummies(\n",
    "    df[\"location_simple\"], prefix=\"location\", drop_first=True\n",
    ")\n",
    "\n",
    "df[\"garden\"] = df[\"garden\"].fillna(\"None\")\n",
    "garden_ohe = pd.get_dummies(df[\"garden\"], prefix=\"garden\", drop_first=True)\n",
    "\n",
    "# -----------------------\n",
    "# 6. Numeric additions\n",
    "# -----------------------\n",
    "df[\"floor_level\"] = df[\"located_on\"].apply(extract_floor)\n",
    "df[\"lease_years_remaining\"] = (\n",
    "    df[\"ownership_type\"].apply(extract_lease_years).fillna(0)\n",
    ")\n",
    "df[\"backyard_num\"] = df[\"backyard\"].apply(to_float).fillna(0)\n",
    "df[\"balcony_flag\"] = df[\"balcony\"].apply(\n",
    "    lambda x: 0 if pd.isna(x) or x == \"N/A\" else 1\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# 7. Combine all features\n",
    "# -----------------------\n",
    "model_features = (\n",
    "    log_cols\n",
    "    + binary_flags\n",
    "    + direct_numeric_features\n",
    "    + [\"energy_label_encoded\"]\n",
    ")\n",
    "\n",
    "# Combine all OHE features\n",
    "ohe_all = pd.concat(\n",
    "    [\n",
    "        postal_ohe,\n",
    "        status_ohe,\n",
    "        roof_ohe,\n",
    "        ownership_ohe,\n",
    "        location_ohe,\n",
    "        garden_ohe,\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# Drop low-variance dummy columns\n",
    "ohe_reduced, dropped_cols = drop_low_variance_dummies(ohe_all, threshold=0.95)\n",
    "print(f\"Dropped {len(dropped_cols)} low-variance columns:\", dropped_cols)\n",
    "\n",
    "# Final X\n",
    "X = pd.concat([df[model_features], ohe_reduced], axis=1)\n",
    "y = df[\"price_num\"]\n",
    "\n",
    "print(\"Number of features for modeling:\", X.shape[1])\n",
    "print(\"Automatically log-transformed columns:\", log_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure numeric columns are numeric\n",
    "numeric_cols = log_cols + direct_numeric_features + [\"energy_label_encoded\"]\n",
    "X_numeric = X[numeric_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# Correlation matrix\n",
    "corr_matrix = X_numeric.corr()\n",
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation matrix for numeric features\")\n",
    "plt.show()\n",
    "\n",
    "# Identify highly correlated pairs\n",
    "high_corr = []\n",
    "cols = corr_matrix.columns\n",
    "for i in range(len(cols)):\n",
    "    for j in range(i + 1, len(cols)):\n",
    "        corr_val = corr_matrix.iloc[i, j]\n",
    "        if abs(corr_val) > 0.9:\n",
    "            high_corr.append((cols[i], cols[j], corr_val))\n",
    "\n",
    "print(\"Highly correlated numeric pairs (|r|>0.9):\")\n",
    "for pair in high_corr:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\n",
    "    \"size_num\",\n",
    "    \"living_area\",\n",
    "    \"nr_rooms\",\n",
    "    \"bathrooms\",\n",
    "    \"toilets\",\n",
    "    \"num_facilities\",\n",
    "    \"external_storage_num\",\n",
    "]\n",
    "X.drop(columns=cols_to_drop, inplace=True)\n",
    "# -----------------------\n",
    "# 8. Train/Test split\n",
    "# -----------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "## 13. Baseline models after feature engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "#### Baseline Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf, rf_results = evaluate_model(\n",
    "    RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42),\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    ")\n",
    "log_to_mlflow(rf, \"Random_Forest_Regression_feature_eng\", rf_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "#### Baseline XGboost with early stopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Convert to DMatrix\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Parameters\n",
    "params = {\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"max_depth\": 6,\n",
    "    \"eta\": 0.05,\n",
    "    \"seed\": 42,\n",
    "}\n",
    "\n",
    "# Train with early stopping\n",
    "xgb_model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=500,\n",
    "    evals=[(dtest, \"eval\")],\n",
    "    early_stopping_rounds=50,\n",
    "    verbose_eval=False,\n",
    ")\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = xgb_model.predict(dtrain)\n",
    "y_test_pred = xgb_model.predict(dtest)\n",
    "\n",
    "# Metrics\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\n",
    "    f\"Train RMSE: {train_rmse:.2f}, MAE: {train_mae:.2f}, train_R²: {train_r2:.3f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Test RMSE: {test_rmse:.2f}, MAE: {test_mae:.2f}, test_R²: {test_r2:.3f}\"\n",
    ")\n",
    "\n",
    "with mlflow.start_run(run_name=\"XGBoost_Regression_feeture_eng\"):\n",
    "    # Log model\n",
    "    mlflow.xgboost.log_model(xgb_model, artifact_path=\"xgb_model_feature_eng\")\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "    mlflow.log_metric(\"train_mae\", train_mae)\n",
    "    mlflow.log_metric(\"test_mae\", test_mae)\n",
    "    mlflow.log_metric(\"train_r2\", train_r2)\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "## 14. Optuna tuning after feature eng\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Optuna for XGBoost\n",
    "sampler = optuna.samplers.TPESampler(seed=42)\n",
    "pruner = optuna.pruners.MedianPruner(n_warmup_steps=10)\n",
    "\n",
    "study_xgb = optuna.create_study(\n",
    "    direction=\"minimize\", sampler=sampler, pruner=pruner\n",
    ")\n",
    "study_xgb.optimize(\n",
    "    lambda trial: objective_xgb(trial, X_train, y_train, X_test, y_test),\n",
    "    n_trials=200,\n",
    ")\n",
    "\n",
    "print(\"Best XGBoost params:\", study_xgb.best_params)\n",
    "print(\"Best XGBoost Test MAE:\", study_xgb.best_value)\n",
    "\n",
    "# Run Optuna for Random Forest\n",
    "study_rf = optuna.create_study(\n",
    "    direction=\"minimize\", sampler=sampler, pruner=pruner\n",
    ")\n",
    "study_rf.optimize(\n",
    "    lambda trial: objective_rf(trial, X_train, y_train, X_test, y_test),\n",
    "    n_trials=100,\n",
    ")\n",
    "\n",
    "print(\"Best RF params:\", study_rf.best_params)\n",
    "print(\"Best RF Test MAE:\", study_rf.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "## 15. Best params run after feature eng\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert log1p targets\n",
    "dtrain = xgb.DMatrix(X_train, label=np.log1p(y_train))\n",
    "dtest = xgb.DMatrix(X_test, label=np.log1p(y_test))\n",
    "\n",
    "best_params = study_xgb.best_params\n",
    "best_params.update(\n",
    "    {\"objective\": \"reg:squarederror\", \"seed\": 42, \"tree_method\": \"hist\"}\n",
    ")\n",
    "\n",
    "best_xgb, results_xgb = evaluate_xgb_dmatrix(\n",
    "    best_params,\n",
    "    dtrain,\n",
    "    dtest,\n",
    "    y_train_orig=y_train,\n",
    "    y_test_orig=y_test,\n",
    "    run_name=\"XGB_Optuna_LogTransformed_feature_eng\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare log-transformed targets\n",
    "y_train_log = np.log1p(y_train)\n",
    "y_test_log = np.log1p(y_test)\n",
    "\n",
    "# Refit best RF on log targets and evaluate\n",
    "best_rf = RandomForestRegressor(**study_rf.best_params)\n",
    "best_rf, results_rf, y_test_pred = evaluate_model_log(\n",
    "    best_rf, X_train, y_train_log, X_test, y_test_log\n",
    ")\n",
    "\n",
    "# Log to MLflow\n",
    "log_to_mlflow(best_rf, \"RF_LogTransform_Optuna_feature_eng\", results_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"house_price_prediction\"\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "experiment_id = experiment.experiment_id\n",
    "\n",
    "\n",
    "runs_df = mlflow.search_runs(experiment_ids=[experiment_id])\n",
    "\n",
    "metrics_of_interest = [\n",
    "    \"metrics.train_rmse\",\n",
    "    \"metrics.test_rmse\",\n",
    "    \"metrics.train_r2\",\n",
    "    \"metrics.test_r2\",\n",
    "    \"metrics.train_mae\",\n",
    "    \"metrics.test_mae\",\n",
    "]\n",
    "comparison_df = runs_df[\n",
    "    [\"run_id\", \"tags.mlflow.runName\"] + metrics_of_interest\n",
    "]\n",
    "\n",
    "comparison_df.sort_values(\"metrics.test_mae\", ascending=True, inplace=True)\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "I have chosen run_id 33688ff883c54d2fb4a14cbef2ae617a because the combination of statistcs looks the best: one of the highest R2 for both test and train, and rmse and mae are one of the lowest ones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mlflow.get_tracking_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "run_id = \"33688ff883c54d2fb4a14cbef2ae617a\"\n",
    "client = MlflowClient()\n",
    "\n",
    "artifacts = client.list_artifacts(\n",
    "    run_id, path=\"xgb_model\"\n",
    ")  # match the artifact_path you used\n",
    "for a in artifacts:\n",
    "    print(a.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = \"33688ff883c54d2fb4a14cbef2ae617a\"\n",
    "model_path = f\"runs:/{run_id}/xgb_model\"\n",
    "\n",
    "# Load the model\n",
    "loaded_model = mlflow.xgboost.load_model(model_path)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = loaded_model.predict(dtest)  # dtest = xgb.DMatrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = mlflow.get_run(run_id)\n",
    "print(run.data.metrics)  # Train/test RMSE, R2, etc.\n",
    "print(run.data.params)  # Model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "# Register model\n",
    "model_uri = f\"runs:/{run_id}/xgb_model\"\n",
    "registered_model_name = \"RealEstate_XGB\"\n",
    "model_version = mlflow.register_model(model_uri, registered_model_name)\n",
    "\n",
    "print(\n",
    "    f\"Model registered as {registered_model_name}, version {model_version.version}\"\n",
    ")\n",
    "# saved the best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74",
   "metadata": {},
   "source": [
    "#### 16. Cross validation for this best model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "cv_metrics = []\n",
    "\n",
    "X_np = X_train.values  # or X_train_scaled if scaling used\n",
    "y_np = y_train.values\n",
    "\n",
    "with mlflow.start_run(run_name=\"XGB_CV_last_model\"):\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_np)):\n",
    "        X_tr, X_val = X_np[train_idx], X_np[val_idx]\n",
    "        y_tr, y_val = y_np[train_idx], y_np[val_idx]\n",
    "\n",
    "        dtrain = xgb.DMatrix(X_tr, label=np.log1p(y_tr))\n",
    "        dval = xgb.DMatrix(X_val, label=np.log1p(y_val))\n",
    "\n",
    "        xgb_model = xgb.train(\n",
    "            best_params,\n",
    "            dtrain,\n",
    "            num_boost_round=500,\n",
    "            evals=[(dval, \"eval\")],\n",
    "            early_stopping_rounds=50,\n",
    "            verbose_eval=False,\n",
    "        )\n",
    "\n",
    "        # Predict and back-transform\n",
    "        y_val_pred = np.expm1(xgb_model.predict(dval))\n",
    "\n",
    "        # Metrics\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "        mae = mean_absolute_error(y_val, y_val_pred)\n",
    "        r2 = r2_score(y_val, y_val_pred)\n",
    "        cv_metrics.append({\"rmse\": rmse, \"mae\": mae, \"r2\": r2})\n",
    "\n",
    "        # Log metrics per fold\n",
    "        mlflow.log_metric(f\"fold_{fold+1}_rmse\", rmse)\n",
    "        mlflow.log_metric(f\"fold_{fold+1}_mae\", mae)\n",
    "        mlflow.log_metric(f\"fold_{fold+1}_r2\", r2)\n",
    "\n",
    "        # Plot predicted vs actual\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        sns.scatterplot(x=y_val, y=y_val_pred)\n",
    "        plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], \"r--\")\n",
    "        plt.xlabel(\"Actual\")\n",
    "        plt.ylabel(\"Predicted\")\n",
    "        plt.title(f\"Fold {fold+1} Predicted vs Actual\")\n",
    "        plt.show()  # show inline\n",
    "\n",
    "        # Log image via PIL\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format=\"png\")\n",
    "        buf.seek(0)\n",
    "        img = Image.open(buf)\n",
    "        mlflow.log_image(img, f\"fold_{fold+1}_pred_vs_actual.png\")\n",
    "        plt.close()\n",
    "\n",
    "# Aggregate metrics\n",
    "mean_rmse = np.mean([m[\"rmse\"] for m in cv_metrics])\n",
    "std_rmse = np.std([m[\"rmse\"] for m in cv_metrics])\n",
    "mean_mae = np.mean([m[\"mae\"] for m in cv_metrics])\n",
    "std_mae = np.std([m[\"mae\"] for m in cv_metrics])\n",
    "mean_r2 = np.mean([m[\"r2\"] for m in cv_metrics])\n",
    "std_r2 = np.std([m[\"r2\"] for m in cv_metrics])\n",
    "\n",
    "# Log aggregated metrics\n",
    "mlflow.log_metric(\"CV_mean_rmse\", mean_rmse)\n",
    "mlflow.log_metric(\"CV_std_rmse\", std_rmse)\n",
    "mlflow.log_metric(\"CV_mean_mae\", mean_mae)\n",
    "mlflow.log_metric(\"CV_std_mae\", std_mae)\n",
    "mlflow.log_metric(\"CV_mean_r2\", mean_r2)\n",
    "mlflow.log_metric(\"CV_std_r2\", std_r2)\n",
    "\n",
    "print(f\"CV RMSE: {mean_rmse:.2f} ± {std_rmse:.2f}\")\n",
    "print(f\"CV MAE: {mean_mae:.2f} ± {std_mae:.2f}\")\n",
    "print(f\"CV R²: {mean_r2:.3f} ± {std_r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = mlflow.get_run(run_id)\n",
    "print(run.data.metrics)  # Train/test RMSE, R2, etc.\n",
    "print(run.data.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare storage\n",
    "y_vals_all = []\n",
    "y_preds_all = []\n",
    "\n",
    "# Collect predictions from each fold\n",
    "for train_idx, val_idx in kf.split(X_np):\n",
    "    X_tr, X_val = X_np[train_idx], X_np[val_idx]\n",
    "    y_tr, y_val = y_np[train_idx], y_np[val_idx]\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_tr, label=np.log1p(y_tr))\n",
    "    dval = xgb.DMatrix(X_val, label=np.log1p(y_val))\n",
    "\n",
    "    xgb_model = xgb.train(\n",
    "        best_params,\n",
    "        dtrain,\n",
    "        num_boost_round=500,\n",
    "        evals=[(dval, \"eval\")],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=False,\n",
    "    )\n",
    "\n",
    "    y_val_pred = np.expm1(xgb_model.predict(dval))\n",
    "\n",
    "    y_vals_all.extend(y_val)\n",
    "    y_preds_all.extend(y_val_pred)\n",
    "\n",
    "# Convert to arrays\n",
    "y_vals_all = np.array(y_vals_all)\n",
    "y_preds_all = np.array(y_preds_all)\n",
    "residuals = y_vals_all - y_preds_all\n",
    "\n",
    "# Predicted vs Actual\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.scatterplot(x=y_vals_all, y=y_preds_all)\n",
    "plt.plot(\n",
    "    [y_vals_all.min(), y_vals_all.max()],\n",
    "    [y_vals_all.min(), y_vals_all.max()],\n",
    "    \"r--\",\n",
    "    label=\"Perfect Prediction\",\n",
    ")\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"CV: Predicted vs Actual (all folds)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Residual plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(residuals, kde=True, bins=20, color=\"skyblue\")\n",
    "plt.xlabel(\"Residual (Actual - Predicted)\")\n",
    "plt.title(\"CV Residuals Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79",
   "metadata": {},
   "source": [
    "#### Generating price range (for pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Number of bins\n",
    "n_bins = 10\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\"pred\": y_preds_all, \"residual\": residuals})\n",
    "\n",
    "# Use qcut instead of cut to ensure roughly equal-sized bins\n",
    "df[\"pred_bin\"] = pd.qcut(df[\"pred\"], q=n_bins, duplicates=\"drop\")\n",
    "\n",
    "# Compute 5th and 95th percentiles per bin\n",
    "bin_ranges = (\n",
    "    df.groupby(\"pred_bin\")[\"residual\"]\n",
    "    .agg(\n",
    "        lower_bound=lambda x: np.percentile(x, 5),\n",
    "        upper_bound=lambda x: np.percentile(x, 95),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "# Function to get price range\n",
    "def get_price_range(pred_price):\n",
    "    for _, row in bin_ranges.iterrows():\n",
    "        if row[\"pred_bin\"].left <= pred_price <= row[\"pred_bin\"].right:\n",
    "            return (\n",
    "                pred_price + row[\"lower_bound\"],\n",
    "                pred_price + row[\"upper_bound\"],\n",
    "            )\n",
    "    return pred_price, pred_price  # fallback if outside all bins\n",
    "\n",
    "\n",
    "# Example\n",
    "example_pred = 500_000\n",
    "lb, ub = get_price_range(example_pred)\n",
    "print(f\"Predicted price: {example_pred}, Range: {lb:.0f} - {ub:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81",
   "metadata": {},
   "source": [
    "Need to just figure out logging these ranges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
