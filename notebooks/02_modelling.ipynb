{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "#### 1. Imports and Set-up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "tracking_uri = \"../logs/mlruns\"\n",
    "os.makedirs(os.path.join(tracking_uri, \".trash\"), exist_ok=True)\n",
    "\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "mlflow.set_experiment(\"house_price_prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "#### 2. Load and prep data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "\n",
    "# Adjust the path to your project root folder\n",
    "project_root = os.path.abspath(\n",
    "    os.path.join(\"..\")\n",
    ")  # from notebooks/ up one level\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from src.data_loading.data_loading.data_loader import load_data_from_json\n",
    "from src.data_loading.preprocessing.preprocessing import preprocess_df\n",
    "from src.data_loading.preprocessing.imputation import impute_missing_values\n",
    "\n",
    "\n",
    "# go two levels up from notebook dir -> project root\n",
    "ROOT = (\n",
    "    Path(__file__).resolve().parents[2]\n",
    "    if \"__file__\" in globals()\n",
    "    else Path.cwd().parents[1]\n",
    ")\n",
    "CONFIG_PATH = (\n",
    "    ROOT\n",
    "    / \"house_price_prediction_project\"\n",
    "    / \"config\"\n",
    "    / \"preprocessing_config.yaml\"\n",
    ")\n",
    "\n",
    "with open(CONFIG_PATH) as f:\n",
    "    CONFIG = yaml.safe_load(f)\n",
    "\n",
    "df_raw = load_data_from_json(\"../data/parsed_json/*.json\")\n",
    "df_clean = preprocess_df(\n",
    "    df_raw,\n",
    "    drop_raw=CONFIG[\"preprocessing\"][\"drop_raw\"],\n",
    "    numeric_cols=CONFIG[\"preprocessing\"][\"numeric_cols\"],\n",
    ")\n",
    "df_clean = impute_missing_values(\n",
    "    df_clean, CONFIG[\"preprocessing\"][\"imputation\"]\n",
    ")\n",
    "# Drop price_num NaNs for the training of the model\n",
    "df_clean = df_clean[df_clean[\"price_num\"].notna()]\n",
    "df = df_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.data_prep_for_modelling.data_preparation import prepare_data\n",
    "\n",
    "FEATURES_CONFIG_PATH = (\n",
    "    ROOT / \"house_price_prediction_project\" / \"config\" / \"features.yaml\"\n",
    ")\n",
    "\n",
    "# Scaled features\n",
    "X_train_scaled, X_test_scaled, y_train, y_test, scaler, X_val, y_val = (\n",
    "    prepare_data(\n",
    "        df, config_path=FEATURES_CONFIG_PATH, model_name=\"linear_regression\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# # Raw features (no scaling)\n",
    "# X_train_raw, X_test_raw, y_train, y_test, _, X_val_raw, y_val_raw = prepare_data(\n",
    "#     df, config_path=FEATURES_CONFIG_PATH, model_name=\"linear_regression\", scale=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "#### 3. Code for evaluating and logging models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "#### 4. Linear Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.evaluate import ModelEvaluator\n",
    "from src.model.mlflow_logger import MLFlowLogger\n",
    "\n",
    "evaluator = ModelEvaluator()\n",
    "logger = MLFlowLogger()\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "trained_lr, y_train_pred, y_test_pred,  lr_results = evaluator.evaluate(\n",
    "    lr_model,\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    X_test_scaled,\n",
    "    y_test,\n",
    "    model_name=\"LinearRegression\",\n",
    ")\n",
    "logger.log_model(trained_lr, \"LinearRegression\", lr_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "#### 5. Random Forest Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.feature_engineering.encoding import encode_energy_label\n",
    "\n",
    "X_train, X_test, y_train, y_test, scaler, X_val, y_val = prepare_data(\n",
    "    df_clean, config_path=FEATURES_CONFIG_PATH, model_name=\"random_forest\"\n",
    ")\n",
    "X_train, energy_encoder = encode_energy_label(X_train, fit=True)\n",
    "\n",
    "X_test, _ = encode_energy_label(X_test, encoder=energy_encoder, fit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.energy_label_encoded.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor()\n",
    "\n",
    "trained_rf, y_train_pred, y_test_pred, rf_results = evaluator.evaluate(\n",
    "    rf_model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    model_name=\"RandomForestRegression\",\n",
    ")\n",
    "logger.log_model(trained_rf, \"RandomForestRegression\", rf_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "#### 6. XGBoost model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.utils import load_model_config\n",
    "\n",
    "X_train, X_test, y_train, y_test, scaler, X_val, y_val = prepare_data(\n",
    "    df_clean, config_path=FEATURES_CONFIG_PATH, model_name=\"XGBoost\"\n",
    ")\n",
    "X_train, energy_encoder = encode_energy_label(X_train, fit=True)\n",
    "\n",
    "X_test, _ = encode_energy_label(X_test, encoder=energy_encoder, fit=False)\n",
    "\n",
    "MODEL_CONFIG_PATH = (\n",
    "    ROOT / \"house_price_prediction_project\" / \"config\" / \"model_config.yaml\"\n",
    ")\n",
    "\n",
    "model_params, fit_params = load_model_config(\n",
    "    MODEL_CONFIG_PATH, model_name=\"xgb\"\n",
    ")\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(**model_params)\n",
    "\n",
    "trained_xgb, y_train_pred, y_test_pred, xgb_results = evaluator.evaluate(\n",
    "    xgb_model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    fit_params=fit_params,\n",
    "    model_name=\"XGBoostRegression\",\n",
    ")\n",
    "logger.log_model(trained_xgb, \"XGBoostRegression\", xgb_results)\n",
    "\n",
    "# xgb_model, results = evaluate_model(\n",
    "#     xgb_model,\n",
    "#     X_train,\n",
    "#     y_train,\n",
    "#     X_test,\n",
    "#     y_test,\n",
    "# )\n",
    "# log_to_mlflow(xgb_model, \"XGBoost_Regression\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "#### 7. XGBoost with early stopping and more tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, scaler, X_val, y_val = prepare_data(\n",
    "    df_clean,\n",
    "    config_path=FEATURES_CONFIG_PATH,\n",
    "    model_name=\"XGBoostEarlyStopping\",\n",
    ")\n",
    "X_train, energy_encoder = encode_energy_label(X_train, fit=True)\n",
    "\n",
    "X_test, _ = encode_energy_label(X_test, encoder=energy_encoder, fit=False)\n",
    "X_val, _ = encode_energy_label(X_val, encoder=energy_encoder, fit=False)\n",
    "\n",
    "xgb_model_params, xgb_fit_params = load_model_config(\n",
    "    MODEL_CONFIG_PATH, \"xgb_with_early_stopping\"\n",
    ")\n",
    "\n",
    "evaluator = ModelEvaluator()\n",
    "\n",
    "\n",
    "trained_xgb, y_train_pred, y_test_pred, xgb_results = evaluator.evaluate(\n",
    "    xgb_model_params,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    fit_params=xgb_fit_params,\n",
    "    use_xgb_train=True,\n",
    "    model_name=\"xgb_with_early_stopping\",\n",
    ")\n",
    "\n",
    "logger.log_model(\n",
    "    trained_xgb, \"xgb_with_early_stopping\", xgb_results, use_xgb_train=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "#### 7. Compare models using MLflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"house_price_prediction\"\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "experiment_id = experiment.experiment_id\n",
    "\n",
    "\n",
    "runs_df = mlflow.search_runs(experiment_ids=[experiment_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_of_interest = [\n",
    "    \"metrics.train_rmse\",\n",
    "    \"metrics.test_rmse\",\n",
    "    \"metrics.train_mae\",\n",
    "    \"metrics.test_mae\",\n",
    "    \"metrics.train_r2\",\n",
    "    \"metrics.test_r2\",\n",
    "]\n",
    "comparison_df = runs_df[\n",
    "    [\"run_id\", \"tags.mlflow.runName\"] + metrics_of_interest\n",
    "]\n",
    "\n",
    "comparison_df.sort_values(\"metrics.test_r2\", ascending=False, inplace=True)\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = comparison_df.sort_values(\n",
    "    \"metrics.test_r2\", ascending=False\n",
    ").iloc[0]\n",
    "print(\"Best model based on test R²:\")\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "#### 8. Hyperparameter tuning with Optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from src.model.objectives_optuna import objective_xgb, objective_rf\n",
    "\n",
    "HYPERPARAM_CONFIG_PATH = (\n",
    "    ROOT\n",
    "    / \"house_price_prediction_project\"\n",
    "    / \"config\"\n",
    "    / \"hyperparameters_optuna.yaml\"\n",
    ")\n",
    "\n",
    "# XGBoost study\n",
    "study_xgb = optuna.create_study(direction=\"minimize\")\n",
    "objective_xgb_partial = partial(\n",
    "    objective_xgb,\n",
    "    df=df_clean,\n",
    "    features_config=FEATURES_CONFIG_PATH,\n",
    "    hyperparam_config=HYPERPARAM_CONFIG_PATH,\n",
    "    model_name=\"XGBoostEarlyStopping\",\n",
    ")\n",
    "study_xgb.optimize(objective_xgb_partial, n_trials=30)\n",
    "\n",
    "print(\"Best XGBoost params:\", study_xgb.best_params)\n",
    "print(\"Best XGBoost Test RMSE:\", study_xgb.best_value)\n",
    "\n",
    "# RandomForest study\n",
    "study_rf = optuna.create_study(direction=\"minimize\")\n",
    "objective_rf_partial = partial(\n",
    "    objective_rf,\n",
    "    df=df_clean,\n",
    "    features_config=FEATURES_CONFIG_PATH,\n",
    "    hyperparam_config=HYPERPARAM_CONFIG_PATH,\n",
    "    model_name=\"random_forest_optuna\",\n",
    ")\n",
    "study_rf.optimize(objective_rf_partial, n_trials=30)\n",
    "\n",
    "print(\"Best RF params:\", study_rf.best_params)\n",
    "print(\"Best RF Test RMSE:\", study_rf.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "#### 9. RF and Xgboost with best parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = RandomForestRegressor(**study_rf.best_params)\n",
    "trained_rf, y_train_pred, y_test_pred, results_rf = evaluator.evaluate(\n",
    "    best_rf,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    use_xgb_train=False,\n",
    "    model_name=\"RF_Optuna\",\n",
    ")\n",
    "\n",
    "logger.log_model(trained_rf, \"RF_Optuna\", results_rf, use_xgb_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.feature_engineering.encoding import (\n",
    "    encode_energy_labels_train_test_val,\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test, _, X_val, y_val = prepare_data(\n",
    "    df_clean,\n",
    "    config_path=FEATURES_CONFIG_PATH,\n",
    "    model_name=\"XGBoostEarlyStopping\",\n",
    ")\n",
    "\n",
    "X_train, X_test, X_val, enc = encode_energy_labels_train_test_val(\n",
    "    X_train, X_test, X_val\n",
    ")\n",
    "\n",
    "\n",
    "xgb_model_params, xgb_fit_params = load_model_config(\n",
    "    MODEL_CONFIG_PATH, \"xgb_with_early_stopping\"\n",
    ")\n",
    "\n",
    "evaluator = ModelEvaluator()\n",
    "\n",
    "trained_xgb, _, _, xgb_results = evaluator.evaluate(\n",
    "    xgb_model_params,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    fit_params=xgb_fit_params,\n",
    "    use_xgb_train=True,\n",
    "    model_name=\"xgb_with_early_stopping_optuna\",\n",
    ")\n",
    "\n",
    "logger.log_model(\n",
    "    trained_xgb, \"xgb_with_early_stopping_optuna\", xgb_results, use_xgb_train=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "#### 10. Let's see how outliers skew RMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot target distribution\n",
    "sns.boxplot(y=y_test)\n",
    "plt.show()\n",
    "\n",
    "# Optional: scatter of predictions vs true values\n",
    "plt.scatter(y_test, y_test_pred, alpha=0.5)\n",
    "plt.xlabel(\"True\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute residuals\n",
    "residuals = y_test - y_test_pred\n",
    "\n",
    "# Summary stats\n",
    "print(\"Residuals summary:\")\n",
    "print(\"Min:\", np.min(residuals))\n",
    "print(\"Max:\", np.max(residuals))\n",
    "print(\"Median:\", np.median(residuals))\n",
    "print(\"Mean:\", np.mean(residuals))\n",
    "print(\"Std:\", np.std(residuals))\n",
    "\n",
    "# Plot histogram\n",
    "plt.hist(residuals, bins=50)\n",
    "plt.title(\"Residuals Distribution\")\n",
    "plt.xlabel(\"Residual\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Train MAE: {train_mae:.2f}\")\n",
    "print(f\"Test MAE:  {test_mae:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "So outliers are skewing the RMSE statistic quite heavily. Hence, I will log transform the target and dot he same analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = ModelEvaluator(\n",
    "    target_transform=np.log1p,\n",
    "    inverse_transform=np.expm1\n",
    ")\n",
    "\n",
    "trained_rf, y_train_pred, y_test_pred, results = evaluator.evaluate(\n",
    "    rf_model, X_train, y_train, X_test, y_test\n",
    ")\n",
    "logger.log_model(trained_rf, \"RF_LogTransform_Evaluator\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = ModelEvaluator(\n",
    "    target_transform=np.log1p,\n",
    "    inverse_transform=np.expm1\n",
    ")\n",
    "\n",
    "trained_xgb, y_train_pred, y_test_pred, results = evaluator.evaluate(\n",
    "    xgb_model, X_train, y_train, X_test, y_test\n",
    ")\n",
    "logger.log_model(trained_rf, \"XGB_LogTransform_Evaluator\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute residuals\n",
    "residuals = y_test - y_test_pred\n",
    "\n",
    "# Define extreme outliers: e.g., top 5% of absolute residuals\n",
    "threshold = np.percentile(np.abs(residuals), 95)\n",
    "outliers_mask = np.abs(residuals) >= threshold\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot non-outliers\n",
    "plt.scatter(\n",
    "    y_test[~outliers_mask],\n",
    "    y_test_pred[~outliers_mask],\n",
    "    alpha=0.5,\n",
    "    label=\"Normal listings\",\n",
    ")\n",
    "\n",
    "# Highlight extreme residuals\n",
    "plt.scatter(\n",
    "    y_test[outliers_mask],\n",
    "    y_test_pred[outliers_mask],\n",
    "    color=\"red\",\n",
    "    label=\"Extreme listings\",\n",
    ")\n",
    "\n",
    "# Diagonal line (perfect prediction)\n",
    "max_val = max(y_test.max(), y_test_pred.max())\n",
    "plt.plot(\n",
    "    [0, max_val],\n",
    "    [0, max_val],\n",
    "    color=\"black\",\n",
    "    linestyle=\"--\",\n",
    "    label=\"Perfect prediction\",\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Actual Price (€)\")\n",
    "plt.ylabel(\"Predicted Price (€)\")\n",
    "plt.title(\"Predicted vs Actual Prices with Extreme Listings Highlighted\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "This is a clear visualization to see how predictions behave across the entire range and highlight the extreme listings that inflate RMSE. Large RMSE is not a deal breaker since:\n",
    "\n",
    "**Statistical justification**\n",
    "Skewed distribution: My dataset has a few extremely expensive houses that are far from the mean. RMSE is sensitive to large errors because it squares residuals, so these few points dominate the metric.\n",
    "\n",
    "MAE is more robust: By reporting MAE alongside RMSE, I show the typical prediction error for most listings, which is a fairer assessment of model performance.\n",
    "\n",
    "Log-transform mitigates skew: Training on log1p(y) reduces the influence of outliers and stabilizes variance, producing a more reliable model for the bulk of the data.\n",
    "\n",
    "**Practical/business justification**\n",
    "\n",
    "The extreme listings (multi-million € homes) are rare. The model performs well on 99% of listings, which is what matters for most users or business decisions.\n",
    "\n",
    "Trying to perfectly predict the top 1–5% of luxury listings would:\n",
    "\n",
    "Require specialized models or additional data\n",
    "\n",
    "Complicate the pipeline\n",
    "\n",
    "Increase overfitting risk\n",
    "\n",
    "Reporting MAE and residual distributions communicates clearly that errors on extreme listings exist, but are expected and do not invalidate the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "#### 11. New approach and moving with optuna (will be changed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost with log-transform\n",
    "objective_xgb_partial = partial(\n",
    "    objective_xgb,\n",
    "    df=df_clean,\n",
    "    features_config=FEATURES_CONFIG_PATH,\n",
    "    hyperparam_config=HYPERPARAM_CONFIG_PATH,\n",
    "    model_name=\"XGBoostEarlyStopping\",\n",
    "    use_log=True,  # log-transform is applied\n",
    ")\n",
    "\n",
    "study_xgb = optuna.create_study(direction=\"minimize\")\n",
    "study_xgb.optimize(objective_xgb_partial, n_trials=30)\n",
    "\n",
    "\n",
    "# Random Forest with log-transform\n",
    "objective_rf_partial = partial(\n",
    "    objective_rf,\n",
    "    df=df_clean,\n",
    "    features_config=FEATURES_CONFIG_PATH,\n",
    "    hyperparam_config=HYPERPARAM_CONFIG_PATH,\n",
    "    model_name=\"random_forest_optuna\",\n",
    "    use_log=True,  # log-transform is applied\n",
    ")\n",
    "\n",
    "study_rf = optuna.create_study(direction=\"minimize\")\n",
    "study_rf.optimize(objective_rf_partial, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize evaluator with log-transform if used in Optuna\n",
    "evaluator = ModelEvaluator(\n",
    "    target_transform=np.log1p,\n",
    "    inverse_transform=np.expm1,\n",
    ")\n",
    "\n",
    "# --- Random Forest ---\n",
    "best_rf = RandomForestRegressor(**study_rf.best_params)\n",
    "trained_rf, y_train_pred, y_test_pred, results_rf = evaluator.evaluate(\n",
    "    best_rf,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    use_xgb_train=False,  # RF uses scikit-learn API\n",
    "    model_name=\"RF_Optuna_Log\",  # name for logging\n",
    ")\n",
    "\n",
    "logger.log_model(trained_rf, \"RF_Optuna_Log\", results_rf, use_xgb_train=False)\n",
    "\n",
    "\n",
    "# --- XGBoost ---\n",
    "best_xgb_params = study_xgb.best_params\n",
    "# Note: For XGBoost, we pass params dict to evaluator and set use_xgb_train=True\n",
    "trained_xgb, y_train_pred, y_test_pred, results_xgb = evaluator.evaluate(\n",
    "    best_xgb_params,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    use_xgb_train=True,  # use xgb.train\n",
    "    model_name=\"XGB_Optuna_Log\",\n",
    "    fit_params={\"num_boost_round\": 1000, \"early_stopping_rounds\": 50},\n",
    ")\n",
    "\n",
    "logger.log_model(trained_xgb, \"XGB_Optuna_Log\", results_xgb, use_xgb_train=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"house_price_prediction\"\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "experiment_id = experiment.experiment_id\n",
    "\n",
    "\n",
    "runs_df = mlflow.search_runs(experiment_ids=[experiment_id])\n",
    "\n",
    "metrics_of_interest = [\n",
    "    \"metrics.train_rmse\",\n",
    "    \"metrics.test_rmse\",\n",
    "    \"metrics.train_r2\",\n",
    "    \"metrics.test_r2\",\n",
    "    \"metrics.train_mae\",\n",
    "    \"metrics.test_mae\",\n",
    "]\n",
    "comparison_df = runs_df[\n",
    "    [\"run_id\", \"tags.mlflow.runName\"] + metrics_of_interest\n",
    "]\n",
    "\n",
    "comparison_df.sort_values(\"metrics.test_mae\", ascending=True, inplace=True)\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = comparison_df.sort_values(\n",
    "    \"metrics.test_mae\", ascending=True\n",
    ").iloc[0]\n",
    "print(\"Best model based on test MAE:\")\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "#### 12. Extra feature engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "df = df.copy()\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Helper Functions\n",
    "# -----------------------\n",
    "def to_float(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    cleaned = re.sub(r\"[^\\d\\.]\", \"\", str(value))\n",
    "    return float(cleaned) if cleaned else np.nan\n",
    "\n",
    "\n",
    "def auto_log_transform(df, numeric_cols, threshold_skew=0.5):\n",
    "    log_cols = []\n",
    "    for col in numeric_cols:\n",
    "        if (df[col] > 0).all():\n",
    "            skewness = df[col].skew()\n",
    "            if abs(skewness) > threshold_skew:\n",
    "                df[f\"log_{col}\"] = np.log1p(df[col])\n",
    "                log_cols.append(f\"log_{col}\")\n",
    "    return log_cols\n",
    "\n",
    "\n",
    "def extract_floor(x):\n",
    "    if pd.isna(x) or x in [\"N/A\", \"Begane grond\"]:\n",
    "        return 0\n",
    "    match = re.search(r\"(\\d+)\", x)\n",
    "    return int(match.group(1)) if match else 0\n",
    "\n",
    "\n",
    "def simplify_roof(roof):\n",
    "    if pd.isna(roof) or roof == \"N/A\":\n",
    "        return \"Unknown\"\n",
    "    if \"Plat dak\" in roof:\n",
    "        return \"Flat\"\n",
    "    if \"Zadeldak\" in roof:\n",
    "        return \"Saddle\"\n",
    "    if \"Samengesteld dak\" in roof:\n",
    "        return \"Composite\"\n",
    "    if \"Mansarde\" in roof:\n",
    "        return \"Mansard\"\n",
    "    return \"Other\"\n",
    "\n",
    "\n",
    "def simplify_ownership(x):\n",
    "    if pd.isna(x) or x.strip() == \"\":\n",
    "        return \"Unknown\"\n",
    "    if \"Volle eigendom\" in x:\n",
    "        return \"Full\"\n",
    "    if \"Erfpacht\" in x and \"Gemeentelijk\" in x:\n",
    "        return \"Municipal\"\n",
    "    if \"Erfpacht\" in x:\n",
    "        return \"Leasehold\"\n",
    "    return \"Other\"\n",
    "\n",
    "\n",
    "def extract_lease_years(x, current_year=2025):\n",
    "    if pd.isna(x) or \"Volle eigendom\" in x or x.strip() == \"\":\n",
    "        return np.nan\n",
    "    match = re.search(r\"einddatum erfpacht: (\\d{2})-(\\d{2})-(\\d{4})\", x)\n",
    "    if match:\n",
    "        day, month, year = map(int, match.groups())\n",
    "        return max(year - current_year, 0)\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "def simplify_location(x):\n",
    "    if pd.isna(x):\n",
    "        return \"Unknown\"\n",
    "    if \"centrum\" in x:\n",
    "        return \"Central\"\n",
    "    if \"woonwijk\" in x:\n",
    "        return \"Residential\"\n",
    "    if \"vrij uitzicht\" in x:\n",
    "        return \"OpenView\"\n",
    "    if \"park\" in x:\n",
    "        return \"Park\"\n",
    "    return \"Other\"\n",
    "\n",
    "\n",
    "def drop_low_variance_dummies(df, threshold=0.95):\n",
    "    low_var_cols = [\n",
    "        col\n",
    "        for col in df.columns\n",
    "        if df[col].value_counts(normalize=True, dropna=False).iloc[0]\n",
    "        >= threshold\n",
    "    ]\n",
    "    return df.drop(columns=low_var_cols), low_var_cols\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 1. Numeric features\n",
    "# -----------------------\n",
    "numeric_features = [\n",
    "    \"size_num\",\n",
    "    \"contribution_vve_num\",\n",
    "    \"external_storage_num\",\n",
    "    \"living_area\",\n",
    "    \"nr_rooms\",\n",
    "    \"bathrooms\",\n",
    "    \"toilets\",\n",
    "    \"num_facilities\",\n",
    "    \"inhabitants_in_neighborhood\",\n",
    "    \"families_with_children_pct\",\n",
    "    \"price_per_m2_neighborhood\",\n",
    "]\n",
    "\n",
    "for col in numeric_features:\n",
    "    df[col] = df[col].apply(to_float)\n",
    "    df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "log_cols = auto_log_transform(df, numeric_features)\n",
    "\n",
    "# -----------------------\n",
    "# 2. Binary / flag features\n",
    "# -----------------------\n",
    "binary_flags = [\n",
    "    \"has_mechanische_ventilatie\",\n",
    "    \"has_tv_kabel\",\n",
    "    \"has_lift\",\n",
    "    \"has_natuurlijke_ventilatie\",\n",
    "    \"has_n/a\",\n",
    "    \"has_schuifpui\",\n",
    "    \"has_glasvezelkabel\",\n",
    "    \"has_frans_balkon\",\n",
    "    \"has_buitenzonwering\",\n",
    "    \"has_zonnepanelen\",\n",
    "    # Removed very low-variance flags here (optional)\n",
    "]\n",
    "\n",
    "for col in binary_flags:\n",
    "    df[col] = df[col].fillna(0).astype(int)\n",
    "\n",
    "# -----------------------\n",
    "# 3. Direct numeric features\n",
    "# -----------------------\n",
    "direct_numeric_features = [\n",
    "    \"bedrooms\",\n",
    "    \"year_of_construction\",\n",
    "    \"contribution_vve_num\",\n",
    "    \"size_num\",\n",
    "    \"external_storage_num\",\n",
    "    \"living_area\",\n",
    "    \"nr_rooms\",\n",
    "    \"bathrooms\",\n",
    "    \"toilets\",\n",
    "    \"num_facilities\",\n",
    "    \"floor_level\",\n",
    "    \"lease_years_remaining\",\n",
    "    \"backyard_num\",\n",
    "    \"balcony_flag\",\n",
    "]\n",
    "\n",
    "# -----------------------\n",
    "# 4. Energy label encoding\n",
    "# -----------------------\n",
    "# df[\"energy_label\"] = df[\"energy_label\"].replace({0: \"G\"}).replace(\"N/A\", \"G\")\n",
    "# energy_order = [\n",
    "#     \"G\",\n",
    "#     \"F\",\n",
    "#     \"E\",\n",
    "#     \"D\",\n",
    "#     \"C\",\n",
    "#     \"B\",\n",
    "#     \"A\",\n",
    "#     \"A+\",\n",
    "#     \"A++\",\n",
    "#     \"A+++\",\n",
    "#     \"A++++\",\n",
    "# ]\n",
    "# encoder_energy = OrdinalEncoder(categories=[energy_order], dtype=int)\n",
    "# df[\"energy_label_encoded\"] = encoder_energy.fit_transform(df[[\"energy_label\"]])\n",
    "# df.drop(columns=[\"energy_label\"], inplace=True)\n",
    "\n",
    "# -----------------------\n",
    "# 5. Categorical features (OHE)\n",
    "# -----------------------\n",
    "df[\"postal_district\"] = df[\"postal_code_clean\"].str[:3]\n",
    "postal_ohe = pd.get_dummies(\n",
    "    df[\"postal_district\"], prefix=\"district\", drop_first=True\n",
    ")\n",
    "\n",
    "df[\"status\"] = df[\"status\"].fillna(\"N/A\")\n",
    "status_ohe = pd.get_dummies(df[\"status\"], prefix=\"status\", drop_first=True)\n",
    "\n",
    "df[\"roof_type_simple\"] = df[\"roof_type\"].apply(simplify_roof)\n",
    "roof_ohe = pd.get_dummies(\n",
    "    df[\"roof_type_simple\"], prefix=\"roof\", drop_first=True\n",
    ")\n",
    "\n",
    "df[\"ownership_simple\"] = df[\"ownership_type\"].apply(simplify_ownership)\n",
    "ownership_ohe = pd.get_dummies(\n",
    "    df[\"ownership_simple\"], prefix=\"ownership\", drop_first=True\n",
    ")\n",
    "\n",
    "df[\"location_simple\"] = df[\"location\"].apply(simplify_location)\n",
    "location_ohe = pd.get_dummies(\n",
    "    df[\"location_simple\"], prefix=\"location\", drop_first=True\n",
    ")\n",
    "\n",
    "df[\"garden\"] = df[\"garden\"].fillna(\"None\")\n",
    "garden_ohe = pd.get_dummies(df[\"garden\"], prefix=\"garden\", drop_first=True)\n",
    "\n",
    "# -----------------------\n",
    "# 6. Numeric additions\n",
    "# -----------------------\n",
    "df[\"floor_level\"] = df[\"located_on\"].apply(extract_floor)\n",
    "df[\"lease_years_remaining\"] = (\n",
    "    df[\"ownership_type\"].apply(extract_lease_years).fillna(0)\n",
    ")\n",
    "df[\"backyard_num\"] = df[\"backyard\"].apply(to_float).fillna(0)\n",
    "df[\"balcony_flag\"] = df[\"balcony\"].apply(\n",
    "    lambda x: 0 if pd.isna(x) or x == \"N/A\" else 1\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# 7. Combine all features\n",
    "# -----------------------\n",
    "model_features = (\n",
    "    log_cols\n",
    "    + binary_flags\n",
    "    + direct_numeric_features\n",
    "    + [\"energy_label_encoded\"]\n",
    ")\n",
    "\n",
    "# Combine all OHE features\n",
    "ohe_all = pd.concat(\n",
    "    [\n",
    "        postal_ohe,\n",
    "        status_ohe,\n",
    "        roof_ohe,\n",
    "        ownership_ohe,\n",
    "        location_ohe,\n",
    "        garden_ohe,\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# Drop low-variance dummy columns\n",
    "ohe_reduced, dropped_cols = drop_low_variance_dummies(ohe_all, threshold=0.95)\n",
    "print(f\"Dropped {len(dropped_cols)} low-variance columns:\", dropped_cols)\n",
    "\n",
    "# Final X\n",
    "X = pd.concat([df[model_features], ohe_reduced], axis=1)\n",
    "y = df[\"price_num\"]\n",
    "\n",
    "print(\"Number of features for modeling:\", X.shape[1])\n",
    "print(\"Automatically log-transformed columns:\", log_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure numeric columns are numeric\n",
    "numeric_cols = log_cols + direct_numeric_features + [\"energy_label_encoded\"]\n",
    "X_numeric = X[numeric_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# Correlation matrix\n",
    "corr_matrix = X_numeric.corr()\n",
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation matrix for numeric features\")\n",
    "plt.show()\n",
    "\n",
    "# Identify highly correlated pairs\n",
    "high_corr = []\n",
    "cols = corr_matrix.columns\n",
    "for i in range(len(cols)):\n",
    "    for j in range(i + 1, len(cols)):\n",
    "        corr_val = corr_matrix.iloc[i, j]\n",
    "        if abs(corr_val) > 0.9:\n",
    "            high_corr.append((cols[i], cols[j], corr_val))\n",
    "\n",
    "print(\"Highly correlated numeric pairs (|r|>0.9):\")\n",
    "for pair in high_corr:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\n",
    "    \"size_num\",\n",
    "    \"living_area\",\n",
    "    \"nr_rooms\",\n",
    "    \"bathrooms\",\n",
    "    \"toilets\",\n",
    "    \"num_facilities\",\n",
    "    \"external_storage_num\",\n",
    "]\n",
    "X.drop(columns=cols_to_drop, inplace=True)\n",
    "# -----------------------\n",
    "# 8. Train/Test split\n",
    "# -----------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "## 13. Baseline models after feature engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "#### Baseline Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf, rf_results = evaluate_model(\n",
    "    RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42),\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    ")\n",
    "log_to_mlflow(rf, \"Random_Forest_Regression_feature_eng\", rf_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "#### Baseline XGboost with early stopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Convert to DMatrix\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Parameters\n",
    "params = {\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"max_depth\": 6,\n",
    "    \"eta\": 0.05,\n",
    "    \"seed\": 42,\n",
    "}\n",
    "\n",
    "# Train with early stopping\n",
    "xgb_model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=500,\n",
    "    evals=[(dtest, \"eval\")],\n",
    "    early_stopping_rounds=50,\n",
    "    verbose_eval=False,\n",
    ")\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = xgb_model.predict(dtrain)\n",
    "y_test_pred = xgb_model.predict(dtest)\n",
    "\n",
    "# Metrics\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\n",
    "    f\"Train RMSE: {train_rmse:.2f}, MAE: {train_mae:.2f}, train_R²: {train_r2:.3f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Test RMSE: {test_rmse:.2f}, MAE: {test_mae:.2f}, test_R²: {test_r2:.3f}\"\n",
    ")\n",
    "\n",
    "with mlflow.start_run(run_name=\"XGBoost_Regression_feeture_eng\"):\n",
    "    # Log model\n",
    "    mlflow.xgboost.log_model(xgb_model, artifact_path=\"xgb_model_feature_eng\")\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "    mlflow.log_metric(\"train_mae\", train_mae)\n",
    "    mlflow.log_metric(\"test_mae\", test_mae)\n",
    "    mlflow.log_metric(\"train_r2\", train_r2)\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "## 14. Optuna tuning after feature eng\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Optuna for XGBoost\n",
    "sampler = optuna.samplers.TPESampler(seed=42)\n",
    "pruner = optuna.pruners.MedianPruner(n_warmup_steps=10)\n",
    "\n",
    "study_xgb = optuna.create_study(\n",
    "    direction=\"minimize\", sampler=sampler, pruner=pruner\n",
    ")\n",
    "study_xgb.optimize(\n",
    "    lambda trial: objective_xgb(trial, X_train, y_train, X_test, y_test),\n",
    "    n_trials=200,\n",
    ")\n",
    "\n",
    "print(\"Best XGBoost params:\", study_xgb.best_params)\n",
    "print(\"Best XGBoost Test MAE:\", study_xgb.best_value)\n",
    "\n",
    "# Run Optuna for Random Forest\n",
    "study_rf = optuna.create_study(\n",
    "    direction=\"minimize\", sampler=sampler, pruner=pruner\n",
    ")\n",
    "study_rf.optimize(\n",
    "    lambda trial: objective_rf(trial, X_train, y_train, X_test, y_test),\n",
    "    n_trials=100,\n",
    ")\n",
    "\n",
    "print(\"Best RF params:\", study_rf.best_params)\n",
    "print(\"Best RF Test MAE:\", study_rf.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "## 15. Best params run after feature eng\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert log1p targets\n",
    "dtrain = xgb.DMatrix(X_train, label=np.log1p(y_train))\n",
    "dtest = xgb.DMatrix(X_test, label=np.log1p(y_test))\n",
    "\n",
    "best_params = study_xgb.best_params\n",
    "best_params.update(\n",
    "    {\"objective\": \"reg:squarederror\", \"seed\": 42, \"tree_method\": \"hist\"}\n",
    ")\n",
    "\n",
    "best_xgb, results_xgb = evaluate_xgb_dmatrix(\n",
    "    best_params,\n",
    "    dtrain,\n",
    "    dtest,\n",
    "    y_train_orig=y_train,\n",
    "    y_test_orig=y_test,\n",
    "    run_name=\"XGB_Optuna_LogTransformed_feature_eng\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare log-transformed targets\n",
    "y_train_log = np.log1p(y_train)\n",
    "y_test_log = np.log1p(y_test)\n",
    "\n",
    "# Refit best RF on log targets and evaluate\n",
    "best_rf = RandomForestRegressor(**study_rf.best_params)\n",
    "best_rf, results_rf, y_test_pred = evaluate_model_log(\n",
    "    best_rf, X_train, y_train_log, X_test, y_test_log\n",
    ")\n",
    "\n",
    "# Log to MLflow\n",
    "log_to_mlflow(best_rf, \"RF_LogTransform_Optuna_feature_eng\", results_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"house_price_prediction\"\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "experiment_id = experiment.experiment_id\n",
    "\n",
    "\n",
    "runs_df = mlflow.search_runs(experiment_ids=[experiment_id])\n",
    "\n",
    "metrics_of_interest = [\n",
    "    \"metrics.train_rmse\",\n",
    "    \"metrics.test_rmse\",\n",
    "    \"metrics.train_r2\",\n",
    "    \"metrics.test_r2\",\n",
    "    \"metrics.train_mae\",\n",
    "    \"metrics.test_mae\",\n",
    "]\n",
    "comparison_df = runs_df[\n",
    "    [\"run_id\", \"tags.mlflow.runName\"] + metrics_of_interest\n",
    "]\n",
    "\n",
    "comparison_df.sort_values(\"metrics.test_mae\", ascending=True, inplace=True)\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "I have chosen run_id 33688ff883c54d2fb4a14cbef2ae617a because the combination of statistcs looks the best: one of the highest R2 for both test and train, and rmse and mae are one of the lowest ones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mlflow.get_tracking_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "run_id = \"33688ff883c54d2fb4a14cbef2ae617a\"\n",
    "client = MlflowClient()\n",
    "\n",
    "artifacts = client.list_artifacts(\n",
    "    run_id, path=\"xgb_model\"\n",
    ")  # match the artifact_path you used\n",
    "for a in artifacts:\n",
    "    print(a.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = \"33688ff883c54d2fb4a14cbef2ae617a\"\n",
    "model_path = f\"runs:/{run_id}/xgb_model\"\n",
    "\n",
    "# Load the model\n",
    "loaded_model = mlflow.xgboost.load_model(model_path)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = loaded_model.predict(dtest)  # dtest = xgb.DMatrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = mlflow.get_run(run_id)\n",
    "print(run.data.metrics)  # Train/test RMSE, R2, etc.\n",
    "print(run.data.params)  # Model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "# Register model\n",
    "model_uri = f\"runs:/{run_id}/xgb_model\"\n",
    "registered_model_name = \"RealEstate_XGB\"\n",
    "model_version = mlflow.register_model(model_uri, registered_model_name)\n",
    "\n",
    "print(\n",
    "    f\"Model registered as {registered_model_name}, version {model_version.version}\"\n",
    ")\n",
    "# saved the best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "#### 16. Cross validation for this best model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "cv_metrics = []\n",
    "\n",
    "X_np = X_train.values  # or X_train_scaled if scaling used\n",
    "y_np = y_train.values\n",
    "\n",
    "with mlflow.start_run(run_name=\"XGB_CV_last_model\"):\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_np)):\n",
    "        X_tr, X_val = X_np[train_idx], X_np[val_idx]\n",
    "        y_tr, y_val = y_np[train_idx], y_np[val_idx]\n",
    "\n",
    "        dtrain = xgb.DMatrix(X_tr, label=np.log1p(y_tr))\n",
    "        dval = xgb.DMatrix(X_val, label=np.log1p(y_val))\n",
    "\n",
    "        xgb_model = xgb.train(\n",
    "            best_params,\n",
    "            dtrain,\n",
    "            num_boost_round=500,\n",
    "            evals=[(dval, \"eval\")],\n",
    "            early_stopping_rounds=50,\n",
    "            verbose_eval=False,\n",
    "        )\n",
    "\n",
    "        # Predict and back-transform\n",
    "        y_val_pred = np.expm1(xgb_model.predict(dval))\n",
    "\n",
    "        # Metrics\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "        mae = mean_absolute_error(y_val, y_val_pred)\n",
    "        r2 = r2_score(y_val, y_val_pred)\n",
    "        cv_metrics.append({\"rmse\": rmse, \"mae\": mae, \"r2\": r2})\n",
    "\n",
    "        # Log metrics per fold\n",
    "        mlflow.log_metric(f\"fold_{fold+1}_rmse\", rmse)\n",
    "        mlflow.log_metric(f\"fold_{fold+1}_mae\", mae)\n",
    "        mlflow.log_metric(f\"fold_{fold+1}_r2\", r2)\n",
    "\n",
    "        # Plot predicted vs actual\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        sns.scatterplot(x=y_val, y=y_val_pred)\n",
    "        plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], \"r--\")\n",
    "        plt.xlabel(\"Actual\")\n",
    "        plt.ylabel(\"Predicted\")\n",
    "        plt.title(f\"Fold {fold+1} Predicted vs Actual\")\n",
    "        plt.show()  # show inline\n",
    "\n",
    "        # Log image via PIL\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format=\"png\")\n",
    "        buf.seek(0)\n",
    "        img = Image.open(buf)\n",
    "        mlflow.log_image(img, f\"fold_{fold+1}_pred_vs_actual.png\")\n",
    "        plt.close()\n",
    "\n",
    "# Aggregate metrics\n",
    "mean_rmse = np.mean([m[\"rmse\"] for m in cv_metrics])\n",
    "std_rmse = np.std([m[\"rmse\"] for m in cv_metrics])\n",
    "mean_mae = np.mean([m[\"mae\"] for m in cv_metrics])\n",
    "std_mae = np.std([m[\"mae\"] for m in cv_metrics])\n",
    "mean_r2 = np.mean([m[\"r2\"] for m in cv_metrics])\n",
    "std_r2 = np.std([m[\"r2\"] for m in cv_metrics])\n",
    "\n",
    "# Log aggregated metrics\n",
    "mlflow.log_metric(\"CV_mean_rmse\", mean_rmse)\n",
    "mlflow.log_metric(\"CV_std_rmse\", std_rmse)\n",
    "mlflow.log_metric(\"CV_mean_mae\", mean_mae)\n",
    "mlflow.log_metric(\"CV_std_mae\", std_mae)\n",
    "mlflow.log_metric(\"CV_mean_r2\", mean_r2)\n",
    "mlflow.log_metric(\"CV_std_r2\", std_r2)\n",
    "\n",
    "print(f\"CV RMSE: {mean_rmse:.2f} ± {std_rmse:.2f}\")\n",
    "print(f\"CV MAE: {mean_mae:.2f} ± {std_mae:.2f}\")\n",
    "print(f\"CV R²: {mean_r2:.3f} ± {std_r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = mlflow.get_run(run_id)\n",
    "print(run.data.metrics)  # Train/test RMSE, R2, etc.\n",
    "print(run.data.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare storage\n",
    "y_vals_all = []\n",
    "y_preds_all = []\n",
    "\n",
    "# Collect predictions from each fold\n",
    "for train_idx, val_idx in kf.split(X_np):\n",
    "    X_tr, X_val = X_np[train_idx], X_np[val_idx]\n",
    "    y_tr, y_val = y_np[train_idx], y_np[val_idx]\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_tr, label=np.log1p(y_tr))\n",
    "    dval = xgb.DMatrix(X_val, label=np.log1p(y_val))\n",
    "\n",
    "    xgb_model = xgb.train(\n",
    "        best_params,\n",
    "        dtrain,\n",
    "        num_boost_round=500,\n",
    "        evals=[(dval, \"eval\")],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=False,\n",
    "    )\n",
    "\n",
    "    y_val_pred = np.expm1(xgb_model.predict(dval))\n",
    "\n",
    "    y_vals_all.extend(y_val)\n",
    "    y_preds_all.extend(y_val_pred)\n",
    "\n",
    "# Convert to arrays\n",
    "y_vals_all = np.array(y_vals_all)\n",
    "y_preds_all = np.array(y_preds_all)\n",
    "residuals = y_vals_all - y_preds_all\n",
    "\n",
    "# Predicted vs Actual\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.scatterplot(x=y_vals_all, y=y_preds_all)\n",
    "plt.plot(\n",
    "    [y_vals_all.min(), y_vals_all.max()],\n",
    "    [y_vals_all.min(), y_vals_all.max()],\n",
    "    \"r--\",\n",
    "    label=\"Perfect Prediction\",\n",
    ")\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"CV: Predicted vs Actual (all folds)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Residual plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(residuals, kde=True, bins=20, color=\"skyblue\")\n",
    "plt.xlabel(\"Residual (Actual - Predicted)\")\n",
    "plt.title(\"CV Residuals Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "#### Generating price range (for pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Number of bins\n",
    "n_bins = 10\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\"pred\": y_preds_all, \"residual\": residuals})\n",
    "\n",
    "# Use qcut instead of cut to ensure roughly equal-sized bins\n",
    "df[\"pred_bin\"] = pd.qcut(df[\"pred\"], q=n_bins, duplicates=\"drop\")\n",
    "\n",
    "# Compute 5th and 95th percentiles per bin\n",
    "bin_ranges = (\n",
    "    df.groupby(\"pred_bin\")[\"residual\"]\n",
    "    .agg(\n",
    "        lower_bound=lambda x: np.percentile(x, 5),\n",
    "        upper_bound=lambda x: np.percentile(x, 95),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "# Function to get price range\n",
    "def get_price_range(pred_price):\n",
    "    for _, row in bin_ranges.iterrows():\n",
    "        if row[\"pred_bin\"].left <= pred_price <= row[\"pred_bin\"].right:\n",
    "            return (\n",
    "                pred_price + row[\"lower_bound\"],\n",
    "                pred_price + row[\"upper_bound\"],\n",
    "            )\n",
    "    return pred_price, pred_price  # fallback if outside all bins\n",
    "\n",
    "\n",
    "# Example\n",
    "example_pred = 500_000\n",
    "lb, ub = get_price_range(example_pred)\n",
    "print(f\"Predicted price: {example_pred}, Range: {lb:.0f} - {ub:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "Need to just figure out logging these ranges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
