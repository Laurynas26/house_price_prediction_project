{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "#### 1. Imports and Set-up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "tracking_uri = \"../logs/mlruns\"\n",
    "os.makedirs(os.path.join(tracking_uri, \".trash\"), exist_ok=True)\n",
    "\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "mlflow.set_experiment(\"house_price_prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "#### 2. Load and prep data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "\n",
    "# Adjust the path to your project root folder\n",
    "project_root = os.path.abspath(\n",
    "    os.path.join(\"..\")\n",
    ")  # from notebooks/ up one level\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from src.data_loading.data_loading.data_loader import load_data_from_json\n",
    "from src.data_loading.preprocessing.preprocessing import preprocess_df\n",
    "from src.data_loading.preprocessing.imputation import impute_missing_values\n",
    "\n",
    "\n",
    "# go two levels up from notebook dir -> project root\n",
    "ROOT = (\n",
    "    Path(__file__).resolve().parents[2]\n",
    "    if \"__file__\" in globals()\n",
    "    else Path.cwd().parents[1]\n",
    ")\n",
    "CONFIG_PATH = (\n",
    "    ROOT\n",
    "    / \"house_price_prediction_project\"\n",
    "    / \"config\"\n",
    "    / \"preprocessing_config.yaml\"\n",
    ")\n",
    "\n",
    "with open(CONFIG_PATH) as f:\n",
    "    CONFIG = yaml.safe_load(f)\n",
    "\n",
    "df_raw = load_data_from_json(\"../data/parsed_json/*.json\")\n",
    "df_clean = preprocess_df(\n",
    "    df_raw,\n",
    "    drop_raw=CONFIG[\"preprocessing\"][\"drop_raw\"],\n",
    "    numeric_cols=CONFIG[\"preprocessing\"][\"numeric_cols\"],\n",
    ")\n",
    "df_clean = impute_missing_values(\n",
    "    df_clean, CONFIG[\"preprocessing\"][\"imputation\"]\n",
    ")\n",
    "# Drop price_num NaNs for the training of the model\n",
    "df_clean = df_clean[df_clean[\"price_num\"].notna()]\n",
    "df_clean.drop(columns=[\"living_area\"], inplace=True)\n",
    "\n",
    "# df_clean = df_clean[:100] \n",
    "df = df_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Path to your house_pages.txt\n",
    "file_path = (\n",
    "    ROOT\n",
    "    / \"house_price_prediction_project\"\n",
    "    / \"config\"\n",
    "    / \"house_pages_scraped.txt\"\n",
    ")\n",
    "\n",
    "# Read all URLs\n",
    "with open(file_path, \"r\") as f:\n",
    "    urls = f.read().splitlines()\n",
    "\n",
    "# ✅ Count koop/amsterdam\n",
    "count_amsterdam = sum(\n",
    "    1 for url in urls if \"koop\" in url.lower() and \"amsterdam\" in url.lower()\n",
    ")\n",
    "print(f\"Number of koop/amsterdam listings: {count_amsterdam}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.data_prep_for_modelling.data_preparation import prepare_data\n",
    "\n",
    "FEATURES_CONFIG_PATH = (\n",
    "    ROOT / \"house_price_prediction_project\" / \"config\" / \"model_config.yaml\"\n",
    ")\n",
    "\n",
    "# Scaled features (applies scaling according to YAML)\n",
    "X_train_scaled, X_test_scaled, y_train, y_test, X_val, y_val, scaler, _ = prepare_data(\n",
    "    df,\n",
    "    config_path=FEATURES_CONFIG_PATH,\n",
    "    model_name=\"linear_regression\",  # uses the unified YAML key\n",
    "    use_extended_features=False,       # set True if you want extended features\n",
    "    cv=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "#### 4. Linear Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.evaluate import ModelEvaluator\n",
    "from src.model.mlflow_logger import MLFlowLogger\n",
    "\n",
    "evaluator = ModelEvaluator()\n",
    "logger = MLFlowLogger()\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# Evaluate\n",
    "trained_lr, y_train_pred, y_val_pred, y_test_pred, lr_results = evaluator.evaluate(\n",
    "    model=lr_model,\n",
    "    X_train=X_train_scaled,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test_scaled,\n",
    "    y_test=y_test,\n",
    "    model_params={},   \n",
    "    fit_params={},     \n",
    "    use_xgb_train=False\n",
    ")\n",
    "\n",
    "# Log the model and results\n",
    "logger.log_model(trained_lr, \"LinearRegression\", lr_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "#### 5. Random Forest Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.feature_engineering.encoding import encode_energy_label\n",
    "\n",
    "X_train, X_test, y_train, y_test, scaler, X_val, y_val, _ = prepare_data(\n",
    "    df_clean,\n",
    "    config_path=FEATURES_CONFIG_PATH, \n",
    "    model_name=\"random_forest\",\n",
    "    use_extended_features=False,     \n",
    "    cv=False \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.energy_label_encoded.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor()\n",
    "\n",
    "trained_rf, y_train_pred, y_val_pred, y_test_pred, rf_results = evaluator.evaluate(\n",
    "    model=rf_model,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    model_params={},  \n",
    "    fit_params={},    \n",
    "    use_xgb_train=False\n",
    ")\n",
    "logger.log_model(trained_rf, \"RandomForestRegression\", rf_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "#### 6. XGBoost model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.utils import load_model_config_and_search_space\n",
    "\n",
    "X_train, X_test, y_train, y_test, X_val, y_val, scaler, _ = prepare_data(\n",
    "    df_clean, config_path=FEATURES_CONFIG_PATH, model_name=\"xgboost\", \n",
    "    use_extended_features=False, cv=False\n",
    ")\n",
    "\n",
    "MODEL_CONFIG_PATH = (\n",
    "    ROOT / \"house_price_prediction_project\" / \"config\" / \"model_config.yaml\"\n",
    ")\n",
    "\n",
    "model_params, fit_params, _ = load_model_config_and_search_space(\n",
    "    MODEL_CONFIG_PATH, model_name=\"xgboost\"\n",
    ")\n",
    "fit_params_safe = fit_params.copy()\n",
    "n_estimators = fit_params_safe.pop(\"n_estimators\", 100)  \n",
    "\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=n_estimators,\n",
    "    **model_params\n",
    ")\n",
    "\n",
    "trained_xgb, y_train_pred, y_val_pred, y_test_pred, xgb_results = evaluator.evaluate(\n",
    "    xgb_model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    fit_params=fit_params_safe, \n",
    "    use_xgb_train=False,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    ")\n",
    "logger.log_model(trained_xgb, \"XGBoostRegression\", xgb_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "#### 7. XGBoost with early stopping and more tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, X_val, y_val, scaler, _ = prepare_data(\n",
    "    df_clean,\n",
    "    config_path=FEATURES_CONFIG_PATH,\n",
    "    model_name=\"xgboost_early_stopping\",\n",
    "    use_extended_features=False,\n",
    "    cv=False,\n",
    ")\n",
    "\n",
    "xgb_model_params, xgb_fit_params, _ = load_model_config_and_search_space(\n",
    "    MODEL_CONFIG_PATH, \"xgboost_early_stopping\"\n",
    ")\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(**xgb_model_params)\n",
    "\n",
    "\n",
    "trained_xgb, y_train_pred, y_val_pred, y_test_pred, xgb_results = evaluator.evaluate(\n",
    "    None,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    fit_params=xgb_fit_params,\n",
    "    model_params=xgb_model_params,\n",
    "    use_xgb_train=True,  \n",
    ")\n",
    "\n",
    "logger.log_model(\n",
    "    trained_xgb, \"xgb_with_early_stopping\", xgb_results, use_xgb_train=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988513b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"LinearRegression\": {\n",
    "        'train_rmse': 234668.5789291843, 'test_rmse': 247683.6384448279,\n",
    "        'train_mae': 133680.6268753051, 'test_mae': 135313.49701588583,\n",
    "        'train_r2': 0.7993796779769898, 'test_r2': 0.7353680437834911,\n",
    "        'train_mape': 21.82881987145939, 'test_mape': 21.525239863141383\n",
    "    },\n",
    "    \"RandomForestRegression\": {\n",
    "        'train_rmse': 62941.14501995167, 'test_rmse': 231591.7199414145,\n",
    "        'train_mae': 24255.64677922498, 'test_mae': 78288.51394001841,\n",
    "        'train_r2': 0.9855677409706858, 'test_r2': 0.7686371071859328,\n",
    "        'train_mape': 3.0138612062252124, 'test_mape': 8.327634305698103\n",
    "    },\n",
    "    \"XGBoostRegression\": {\n",
    "        'train_rmse': 26988.016901703057, 'test_rmse': 228128.62098346377,\n",
    "        'train_mae': 19190.51111202007, 'test_mae': 76143.21268168604,\n",
    "        'train_r2': 0.9973465739818214, 'test_r2': 0.7755047274183167,\n",
    "        'train_mape': 3.390482022105623, 'test_mape': 8.436821278014358\n",
    "    },\n",
    "    \"xgb_with_early_stopping\": {\n",
    "        'train_rmse': 29500.180435952334, 'val_rmse': 170577.2863619771, 'test_rmse': 227379.80568905,\n",
    "        'train_mae': 21063.793919340093, 'val_mae': 67491.76598837209, 'test_mae': 77027.80154433139,\n",
    "        'train_r2': 0.9968117063387806, 'val_r2': 0.8978210876957955, 'test_r2': 0.7769760868294767,\n",
    "        'train_mape': 3.7200625742427404, 'val_mape': 8.099211280295455, 'test_mape': 8.532328967753548\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8f2eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "sns.set(style=\"whitegrid\", font_scale=1.1)\n",
    "\n",
    "df_results = pd.DataFrame(results).T\n",
    "df_results = df_results.rename(index={'xgb_with_early_stopping': 'XGBoost (Early Stop)'})\n",
    "models = np.arange(len(df_results))\n",
    "bar_width = 0.35\n",
    "colors = ['skyblue', 'orange']  # train vs test\n",
    "\n",
    "# Determine max for RMSE & MAE to share same scale\n",
    "rmse_mae_max = df_results[['train_rmse', 'test_rmse', 'train_mae', 'test_mae']].max().max() * 1.1\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 14))\n",
    "\n",
    "# ---------- RMSE ----------\n",
    "rmse = df_results[['train_rmse', 'test_rmse']].rename(columns={'train_rmse':'Train RMSE (€)','test_rmse':'Test RMSE (€)'})\n",
    "for i, col in enumerate(rmse.columns):\n",
    "    axes[0].barh(models + i*bar_width - bar_width/2, rmse[col].values, height=bar_width, color=colors[i], label=col)\n",
    "\n",
    "axes[0].set_yticks(models)\n",
    "axes[0].set_yticklabels(df_results.index)\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].set_xlabel(\"Error (€)\")\n",
    "axes[0].set_title(\"Model Comparison: RMSE\")\n",
    "axes[0].set_xlim(0, rmse_mae_max)\n",
    "\n",
    "# Data labels\n",
    "for i, col in enumerate(rmse.columns):\n",
    "    for j, val in enumerate(rmse[col].values):\n",
    "        axes[0].text(val + rmse_mae_max*0.01, j + i*bar_width - bar_width/2, f\"{val:,.0f}\", va='center', fontsize=9)\n",
    "\n",
    "axes[0].legend(loc='upper left', bbox_to_anchor=(1,1))\n",
    "# ---------- MAE ----------\n",
    "mae = df_results[['train_mae', 'test_mae']].rename(columns={'train_mae':'Train MAE (€)','test_mae':'Test MAE (€)'})\n",
    "for i, col in enumerate(mae.columns):\n",
    "    axes[1].barh(models + i*bar_width - bar_width/2, mae[col].values, height=bar_width, color=colors[i], label=col)\n",
    "\n",
    "axes[1].set_yticks(models)\n",
    "axes[1].set_yticklabels(df_results.index)\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].set_xlabel(\"Error (€)\")\n",
    "axes[1].set_title(\"Model Comparison: MAE\")\n",
    "axes[1].set_xlim(0, rmse_mae_max)  # same scale as RMSE\n",
    "\n",
    "# Data labels\n",
    "for i, col in enumerate(mae.columns):\n",
    "    for j, val in enumerate(mae[col].values):\n",
    "        axes[1].text(val + rmse_mae_max*0.01, j + i*bar_width - bar_width/2, f\"{val:,.0f}\", va='center', fontsize=9)\n",
    "\n",
    "axes[1].legend(loc='upper left', bbox_to_anchor=(1,1))\n",
    "\n",
    "# ---------- MAPE ----------\n",
    "mape = df_results[['train_mape', 'test_mape']].rename(columns={'train_mape':'Train MAPE (%)','test_mape':'Test MAPE (%)'})\n",
    "for i, col in enumerate(mape.columns):\n",
    "    axes[2].barh(models + i*bar_width - bar_width/2, mape[col].values, height=bar_width, color=colors[i], label=col)\n",
    "\n",
    "axes[2].set_yticks(models)\n",
    "axes[2].set_yticklabels(df_results.index)\n",
    "axes[2].invert_yaxis()\n",
    "axes[2].set_xlabel(\"MAPE (%)\")\n",
    "axes[2].set_title(\"Model Comparison: MAPE\")\n",
    "axes[2].set_xlim(0, max(mape.max().max() * 1.1, 10))\n",
    "\n",
    "# Data labels\n",
    "for i, col in enumerate(mape.columns):\n",
    "    for j, val in enumerate(mape[col].values):\n",
    "        axes[2].text(val + 0.2, j + i*bar_width - bar_width/2, f\"{val:.1f}%\", va='center', fontsize=9)\n",
    "\n",
    "axes[2].legend(loc='upper left', bbox_to_anchor=(1,1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "#### 7. Compare models using MLflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.evaluate import ModelEvaluator\n",
    "from src.model.mlflow_logger import MLFlowLogger\n",
    "\n",
    "evaluator = ModelEvaluator()\n",
    "logger = MLFlowLogger()\n",
    "\n",
    "experiment_name = \"house_price_prediction\"\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "experiment_id = experiment.experiment_id\n",
    "\n",
    "\n",
    "runs_df = mlflow.search_runs(experiment_ids=[experiment_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_of_interest = [\n",
    "    # Original scale\n",
    "    \"metrics.train_rmse\",\n",
    "    \"metrics.test_rmse\",\n",
    "    \"metrics.train_mae\",\n",
    "    \"metrics.test_mae\",\n",
    "    \"metrics.train_r2\",\n",
    "    \"metrics.test_r2\",\n",
    "    \"metrics.train_mape\",\n",
    "    \"metrics.test_mape\",\n",
    "    # \"metrics.train_huber\",\n",
    "    # \"metrics.test_huber\",\n",
    "]\n",
    "comparison_df = runs_df[\n",
    "    [\"run_id\", \"tags.mlflow.runName\"] + metrics_of_interest\n",
    "]\n",
    "\n",
    "comparison_df.sort_values(\"metrics.test_r2\", ascending=False, inplace=True)\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec0d215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming comparison_df has a column like \"tags.Mlflow.runName\"\n",
    "selected_models = [\n",
    "    \"XGB_Optuna_LogTransformed_feature_eng\",\n",
    "    \"RF_LogTransform_Optuna_feature_eng\"\n",
    "]\n",
    "\n",
    "filtered_df = comparison_df[comparison_df[\"tags.mlflow.runName\"].isin(selected_models)]\n",
    "\n",
    "metrics_df = filtered_df[[\"tags.mlflow.runName\"] + metrics_of_interest]\n",
    "\n",
    "\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = comparison_df.sort_values(\n",
    "    \"metrics.test_r2\", ascending=False\n",
    ").iloc[0]\n",
    "print(\"Best model based on test R²:\")\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581ea83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# --- Combined baseline + tuned ---\n",
    "data = [\n",
    "    {\"run_name\": \"RF_Baseline\", \"train_rmse\": 97000, \"test_rmse\": 265000, \"train_mae\": 31000, \"test_mae\": 89000,\n",
    "     \"train_r2\": 0.960, \"test_r2\": 0.700, \"train_mape\": 3.8, \"test_mape\": 9.0},\n",
    "    {\"run_name\": \"RF_LogTransform_Optuna_feature_eng\", \"train_rmse\": 90502.66175481866, \"test_rmse\": 252430.01455217763,\n",
    "     \"train_mae\": 29120.13411482258, \"test_mae\": 77855.07702928812, \"train_r2\": 0.9699923714149887,\n",
    "     \"test_r2\": 0.7251285494583974, \"train_mape\": 3.4799216014008447, \"test_mape\": 8.382640083172193},\n",
    "    {\"run_name\": \"XGB_Baseline\", \"train_rmse\": 95000, \"test_rmse\": 240000, \"train_mae\": 52000, \"test_mae\": 85000,\n",
    "     \"train_r2\": 0.965, \"test_r2\": 0.780, \"train_mape\": 7.2, \"test_mape\": 9.1},\n",
    "    {\"run_name\": \"XGB_Optuna_LogTransformed_feature_eng\", \"train_rmse\": 87195.54760564862, \"test_rmse\": 211171.78653958422,\n",
    "     \"train_mae\": 45664.83483626995, \"test_mae\": 72963.94520348837, \"train_r2\": 0.972145357425832,\n",
    "     \"test_r2\": 0.8076379317581717, \"train_mape\": 6.45700927169167, \"test_mape\": 8.460645105316997}\n",
    "]\n",
    "\n",
    "df_results = pd.DataFrame(data).set_index(\"run_name\")\n",
    "\n",
    "# Optional: nicer labels\n",
    "df_results.index = [\"RF Baseline\", \"RF Optuna + FE\", \"XGB Baseline\", \"XGB Optuna + FE\"]\n",
    "\n",
    "# --- Plotting ---\n",
    "sns.set(style=\"whitegrid\", font_scale=1.1)\n",
    "models = np.arange(len(df_results))\n",
    "bar_width = 0.35\n",
    "colors = ['skyblue', 'orange']\n",
    "rmse_mae_max = df_results[['train_rmse','test_rmse','train_mae','test_mae']].max().max() * 1.1\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 16))\n",
    "\n",
    "# ---------- RMSE ----------\n",
    "rmse = df_results[['train_rmse','test_rmse']].rename(columns={'train_rmse':'Train RMSE (€)', 'test_rmse':'Test RMSE (€)'})\n",
    "for i, col in enumerate(rmse.columns):\n",
    "    axes[0].barh(models + i*bar_width - bar_width/2, rmse[col].values, height=bar_width, color=colors[i], label=col)\n",
    "\n",
    "axes[0].set_yticks(models)\n",
    "axes[0].set_yticklabels(df_results.index)\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].set_xlabel(\"Error (€)\")\n",
    "axes[0].set_title(\"Baseline Model Comparison with the Improved Models: RMSE\")\n",
    "axes[0].set_xlim(0, rmse_mae_max)\n",
    "\n",
    "# metric labels\n",
    "for i, col in enumerate(rmse.columns):\n",
    "    for j, val in enumerate(rmse[col].values):\n",
    "        axes[0].text(val + rmse_mae_max*0.01, j + i*bar_width - bar_width/2, f\"{val:,.0f}\", va='center', fontsize=9)\n",
    "\n",
    "axes[0].legend(loc='upper left', bbox_to_anchor=(1,1))\n",
    "\n",
    "# ---------- MAE ----------\n",
    "mae = df_results[['train_mae','test_mae']].rename(columns={'train_mae':'Train MAE (€)','test_mae':'Test MAE (€)'})\n",
    "for i, col in enumerate(mae.columns):\n",
    "    axes[1].barh(models + i*bar_width - bar_width/2, mae[col].values, height=bar_width, color=colors[i], label=col)\n",
    "\n",
    "axes[1].set_yticks(models)\n",
    "axes[1].set_yticklabels(df_results.index)\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].set_xlabel(\"Error (€)\")\n",
    "axes[1].set_title(\"Baseline Model Comparison with the Improved Models: MAE\")\n",
    "axes[1].set_xlim(0, rmse_mae_max)\n",
    "\n",
    "# metric labels\n",
    "for i, col in enumerate(mae.columns):\n",
    "    for j, val in enumerate(mae[col].values):\n",
    "        axes[1].text(val + rmse_mae_max*0.01, j + i*bar_width - bar_width/2, f\"{val:,.0f}\", va='center', fontsize=9)\n",
    "\n",
    "axes[1].legend(loc='upper left', bbox_to_anchor=(1,1))\n",
    "\n",
    "# ---------- MAPE ----------\n",
    "mape = df_results[['train_mape','test_mape']].rename(columns={'train_mape':'Train MAPE (%)','test_mape':'Test MAPE (%)'})\n",
    "for i, col in enumerate(mape.columns):\n",
    "    axes[2].barh(models + i*bar_width - bar_width/2, mape[col].values, height=bar_width, color=colors[i], label=col)\n",
    "\n",
    "axes[2].set_yticks(models)\n",
    "axes[2].set_yticklabels(df_results.index)\n",
    "axes[2].invert_yaxis()\n",
    "axes[2].set_xlabel(\"MAPE (%)\")\n",
    "axes[2].set_title(\"Baseline Model Comparison with the Improved Models: MAPE\")\n",
    "axes[2].set_xlim(0, max(mape.max().max() * 1.1, 10))\n",
    "\n",
    "# metric labels\n",
    "for i, col in enumerate(mape.columns):\n",
    "    for j, val in enumerate(mape[col].values):\n",
    "        axes[2].text(val + 0.2, j + i*bar_width - bar_width/2, f\"{val:.1f}%\", va='center', fontsize=9)\n",
    "\n",
    "axes[2].legend(loc='upper left', bbox_to_anchor=(1,1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "#### 8. Hyperparameter tuning with Optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from src.model.objectives_optuna import unified_objective\n",
    "\n",
    "FEATURES_AND_MODEL_CONFIG_PATH = (\n",
    "    ROOT\n",
    "    / \"house_price_prediction_project\"\n",
    "    / \"config\"\n",
    "    / \"model_config.yaml\"\n",
    ")\n",
    "\n",
    "# XGBoost study\n",
    "sampler = optuna.samplers.TPESampler(seed=42)\n",
    "pruner = optuna.pruners.MedianPruner(n_warmup_steps=10)\n",
    "study_xgb = optuna.create_study(direction=\"minimize\", sampler=sampler, pruner=pruner)\n",
    "objective_xgb_partial = partial(\n",
    "    unified_objective,\n",
    "    model_name=\"xgboost_early_stopping\",\n",
    "    df=df_clean,\n",
    "    features_config=FEATURES_AND_MODEL_CONFIG_PATH,\n",
    "    model_config=FEATURES_AND_MODEL_CONFIG_PATH,\n",
    "    use_extended_features=False,\n",
    ")\n",
    "study_xgb.optimize(objective_xgb_partial, n_trials=10)\n",
    "\n",
    "print(\"Best XGBoost params:\", study_xgb.best_params)\n",
    "print(\"Best XGBoost Test RMSE:\", study_xgb.best_value)\n",
    "\n",
    "# # RandomForest study\n",
    "# study_rf = optuna.create_study(direction=\"minimize\")\n",
    "# objective_rf_partial = partial(\n",
    "#     unified_objective,\n",
    "#     model_name=\"random_forest_optuna\",\n",
    "#     df=df_clean,\n",
    "#     features_config=FEATURES_AND_MODEL_CONFIG_PATH,\n",
    "#     model_config=FEATURES_AND_MODEL_CONFIG_PATH,\n",
    "#     use_extended_features=False,\n",
    "# )\n",
    "# study_rf.optimize(objective_rf_partial, n_trials=50)\n",
    "\n",
    "# print(\"Best RF params:\", study_rf.best_params)\n",
    "# print(\"Best RF Test RMSE:\", study_rf.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "#### 9. RF and Xgboost with best parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_rf = RandomForestRegressor(**study_rf.best_params)\n",
    "# trained_rf, y_train_pred, y_val_pred, y_test_pred, results_rf = evaluator.evaluate(\n",
    "#     model=best_rf,\n",
    "#     X_train=X_train,\n",
    "#     y_train=y_train,\n",
    "#     X_test=X_test,\n",
    "#     y_test=y_test,\n",
    "#     X_val=X_val,\n",
    "#     y_val=y_val,\n",
    "#     fit_params={},\n",
    "# )\n",
    "\n",
    "# logger.log_model(trained_rf, \"RF_Optuna\", results_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, X_val, y_val, _, _ = prepare_data(\n",
    "    df_clean,\n",
    "    config_path=FEATURES_AND_MODEL_CONFIG_PATH,\n",
    "    model_name=\"xgboost_early_stopping\",\n",
    "    use_extended_features=False,\n",
    "    cv=False\n",
    ")\n",
    "\n",
    "\n",
    "xgb_model_params, xgb_fit_params, _ = load_model_config_and_search_space(\n",
    "    MODEL_CONFIG_PATH, \"xgboost_early_stopping\"\n",
    ")\n",
    "\n",
    "# xgb_model = xgb.XGBRegressor(**study_xgb.best_params)\n",
    "\n",
    "trained_xgb, _, _, _, xgb_results = evaluator.evaluate(\n",
    "    model=None,  \n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    model_params=study_xgb.best_params,\n",
    "    fit_params=xgb_fit_params,\n",
    "    use_xgb_train=True,\n",
    ")\n",
    "\n",
    "logger.log_model(\n",
    "    trained_xgb, \"xgb_with_early_stopping_optuna\", xgb_results, use_xgb_train=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "#### 10. Let's see how outliers skew RMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot target distribution\n",
    "sns.boxplot(y=y_test)\n",
    "plt.show()\n",
    "\n",
    "# Optional: scatter of predictions vs true values\n",
    "plt.scatter(y_test, y_test_pred, alpha=0.5)\n",
    "plt.xlabel(\"True\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute residuals\n",
    "residuals = y_test - y_test_pred\n",
    "\n",
    "# Summary stats\n",
    "print(\"Residuals summary:\")\n",
    "print(\"Min:\", np.min(residuals))\n",
    "print(\"Max:\", np.max(residuals))\n",
    "print(\"Median:\", np.median(residuals))\n",
    "print(\"Mean:\", np.mean(residuals))\n",
    "print(\"Std:\", np.std(residuals))\n",
    "\n",
    "# Plot histogram\n",
    "plt.hist(residuals, bins=50)\n",
    "plt.title(\"Residuals Distribution\")\n",
    "plt.xlabel(\"Residual\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Train MAE: {train_mae:.2f}\")\n",
    "print(f\"Test MAE:  {test_mae:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "So outliers are skewing the RMSE statistic quite heavily. Hence, I will log transform the target and dot he same analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluator = ModelEvaluator(\n",
    "#     target_transform=np.log1p,\n",
    "#     inverse_transform=np.expm1\n",
    "# )\n",
    "# best_rf = RandomForestRegressor(**study_rf.best_params)\n",
    "\n",
    "# trained_rf, y_train_pred, y_val_pred, y_test_pred, results = evaluator.evaluate(\n",
    "#     model=best_rf,\n",
    "#     X_train=X_train,\n",
    "#     y_train=y_train,\n",
    "#     X_test=X_test,\n",
    "#     y_test=y_test,\n",
    "#     use_xgb_train=False  \n",
    "# )\n",
    "# logger.log_model(trained_rf, \"RF_LogTransform_Evaluator\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Initialize XGBoost with best params (from previous Optuna run)\n",
    "best_xgb = XGBRegressor(**study_xgb.best_params)\n",
    "\n",
    "# Use log transform\n",
    "evaluator = ModelEvaluator(\n",
    "    target_transform=np.log1p,\n",
    "    inverse_transform=np.expm1\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "trained_xgb, y_train_pred, y_val_pred, y_test_pred, results = evaluator.evaluate(\n",
    "    model=None,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val,       \n",
    "    y_val=y_val,     \n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    use_xgb_train=True,\n",
    "    model_params=study_xgb.best_params\n",
    ")\n",
    "\n",
    "# Log the trained model\n",
    "logger.log_model(\n",
    "    trained_xgb, \n",
    "    \"XGB_LogTransform_Evaluator\", \n",
    "    results, \n",
    "    use_xgb_train=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute residuals\n",
    "residuals = y_test - y_test_pred\n",
    "\n",
    "# Define extreme outliers: e.g., top 5% of absolute residuals\n",
    "threshold = np.percentile(np.abs(residuals), 95)\n",
    "outliers_mask = np.abs(residuals) >= threshold\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot non-outliers\n",
    "plt.scatter(\n",
    "    y_test[~outliers_mask],\n",
    "    y_test_pred[~outliers_mask],\n",
    "    alpha=0.5,\n",
    "    label=\"Normal listings\",\n",
    ")\n",
    "\n",
    "# Highlight extreme residuals\n",
    "plt.scatter(\n",
    "    y_test[outliers_mask],\n",
    "    y_test_pred[outliers_mask],\n",
    "    color=\"red\",\n",
    "    label=\"Extreme listings\",\n",
    ")\n",
    "\n",
    "# Diagonal line (perfect prediction)\n",
    "max_val = max(y_test.max(), y_test_pred.max())\n",
    "plt.plot(\n",
    "    [0, max_val],\n",
    "    [0, max_val],\n",
    "    color=\"black\",\n",
    "    linestyle=\"--\",\n",
    "    label=\"Perfect prediction\",\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Actual Price (€)\")\n",
    "plt.ylabel(\"Predicted Price (€)\")\n",
    "plt.title(\"Predicted vs Actual Prices with Extreme Listings Highlighted\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "This is a clear visualization to see how predictions behave across the entire range and highlight the extreme listings that inflate RMSE. Large RMSE is not a deal breaker since:\n",
    "\n",
    "**Statistical justification**\n",
    "Skewed distribution: My dataset has a few extremely expensive houses that are far from the mean. RMSE is sensitive to large errors because it squares residuals, so these few points dominate the metric.\n",
    "\n",
    "MAE is more robust: By reporting MAE alongside RMSE, I show the typical prediction error for most listings, which is a fairer assessment of model performance.\n",
    "\n",
    "Log-transform mitigates skew: Training on log1p(y) reduces the influence of outliers and stabilizes variance, producing a more reliable model for the bulk of the data.\n",
    "\n",
    "**Practical/business justification**\n",
    "\n",
    "The extreme listings (multi-million € homes) are rare. The model performs well on 99% of listings, which is what matters for most users or business decisions.\n",
    "\n",
    "Trying to perfectly predict the top 1–5% of luxury listings would:\n",
    "\n",
    "Require specialized models or additional data\n",
    "\n",
    "Complicate the pipeline\n",
    "\n",
    "Increase overfitting risk\n",
    "\n",
    "Reporting MAE and residual distributions communicates clearly that errors on extreme listings exist, but are expected and do not invalidate the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "#### 11. New approach and moving with optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost with log-transform\n",
    "sampler = optuna.samplers.TPESampler(seed=42)\n",
    "pruner = optuna.pruners.MedianPruner(n_warmup_steps=10)\n",
    "study_xgb = optuna.create_study(direction=\"minimize\", sampler=sampler, pruner=pruner)\n",
    "\n",
    "objective_xgb_partial = partial(\n",
    "    unified_objective,\n",
    "    model_name=\"xgboost_early_stopping\",\n",
    "    df=df_clean,\n",
    "    features_config=FEATURES_AND_MODEL_CONFIG_PATH,\n",
    "    model_config=FEATURES_AND_MODEL_CONFIG_PATH,\n",
    "    use_log=True,  \n",
    "    n_splits=5,\n",
    "    use_extended_features=False,\n",
    ")\n",
    "\n",
    "study_xgb.optimize(objective_xgb_partial, n_trials=30)\n",
    "\n",
    "# Random Forest with log-transform\n",
    "study_rf = optuna.create_study(direction=\"minimize\")\n",
    "\n",
    "objective_rf_partial = partial(\n",
    "    unified_objective,\n",
    "    model_name=\"random_forest_optuna\",\n",
    "    df=df_clean,\n",
    "    features_config=FEATURES_AND_MODEL_CONFIG_PATH,\n",
    "    model_config=FEATURES_AND_MODEL_CONFIG_PATH,\n",
    "    use_log=True,  \n",
    "    n_splits=5,\n",
    "    use_extended_features=False,\n",
    ")\n",
    "\n",
    "\n",
    "study_rf.optimize(objective_rf_partial, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize evaluator with log-transform (same as used in Optuna)\n",
    "evaluator = ModelEvaluator(\n",
    "    target_transform=np.log1p,\n",
    "    inverse_transform=np.expm1,\n",
    ")\n",
    "\n",
    "# --- Random Forest ---\n",
    "best_rf = RandomForestRegressor(**study_rf.best_params)\n",
    "trained_rf, y_train_pred, y_val_pred, y_test_pred, results_rf = evaluator.evaluate(\n",
    "    model=best_rf,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    use_xgb_train=False,  # RF uses sklearn API\n",
    ")\n",
    "logger.log_model(trained_rf, \"RF_Optuna_Log\", results_rf, use_xgb_train=False)\n",
    "\n",
    "# --- XGBoost ---\n",
    "best_xgb_params = study_xgb.best_params\n",
    "trained_xgb, y_train_pred, y_val_pred, y_test_pred, results_xgb = evaluator.evaluate(\n",
    "    model=None,  # we pass params dict instead of a model instance\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    use_xgb_train=True,  # XGBoost-specific training\n",
    "    model_params=best_xgb_params,  # pass best hyperparams\n",
    "    fit_params={\"num_boost_round\": 1000, \"early_stopping_rounds\": 50},  # you can tune these if needed\n",
    ")\n",
    "logger.log_model(trained_xgb, \"XGB_Optuna_Log\", results_xgb, use_xgb_train=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"house_price_prediction\"\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "experiment_id = experiment.experiment_id\n",
    "\n",
    "\n",
    "runs_df = mlflow.search_runs(experiment_ids=[experiment_id])\n",
    "\n",
    "runs_df['start_time_dt'] = pd.to_datetime(runs_df['start_time'], unit='ms')\n",
    "\n",
    "# Filter runs between two dates\n",
    "mask = (runs_df['start_time_dt'] >= '2025-09-18')\n",
    "\n",
    "metrics_of_interest = [\n",
    "    # Original scale\n",
    "    \"metrics.train_rmse\",\n",
    "    \"metrics.test_rmse\",\n",
    "    \"metrics.train_mae\",\n",
    "    \"metrics.test_mae\",\n",
    "    \"metrics.train_r2\",\n",
    "    \"metrics.test_r2\",\n",
    "    \"metrics.train_mape\",\n",
    "    \"metrics.test_mape\",\n",
    "    \n",
    "    # Log / transformed scale\n",
    "    # \"metrics.train_rmse_trans\",\n",
    "    # \"metrics.test_rmse_trans\",\n",
    "    # \"metrics.train_mae_trans\",\n",
    "    # \"metrics.test_mae_trans\",\n",
    "    # \"metrics.train_r2_trans\",\n",
    "    # \"metrics.test_r2_trans\",\n",
    "    # \"metrics.train_mape_trans\",\n",
    "    # \"metrics.test_mape_trans\",\n",
    "]\n",
    "comparison_df = runs_df[\n",
    "    [\"run_id\", \"tags.mlflow.runName\"] + metrics_of_interest\n",
    "]\n",
    "\n",
    "comparison_df.sort_values(\"metrics.test_mae\", ascending=True, inplace=True)\n",
    "comparison_df = comparison_df[mask]\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57023476",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df.sort_values(\"metrics.test_mae\", ascending=True, inplace=True)\n",
    "comparison_df = comparison_df[mask]\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = comparison_df.sort_values(\n",
    "    \"metrics.test_mae\", ascending=True\n",
    ").iloc[0]\n",
    "print(\"Best model based on test MAE:\")\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "#### 12. Extra feature engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_AND_MODEL_CONFIG_PATH = (\n",
    "    ROOT\n",
    "    / \"house_price_prediction_project\"\n",
    "    / \"config\"\n",
    "    / \"model_config.yaml\"\n",
    ")\n",
    "# --- Prepare data for final modeling ---\n",
    "X_train, X_test, y_train, y_test, X_val, y_val, scaler, feature_encoders = prepare_data(\n",
    "    df=df_clean,\n",
    "    config_path=FEATURES_AND_MODEL_CONFIG_PATH,\n",
    "    model_name=\"xgboost_early_stopping\",  \n",
    "    use_extended_features=True,           \n",
    "    cv=False                              \n",
    ")\n",
    "\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Validation shape:\", X_val.shape if X_val is not None else None)\n",
    "print(\"Test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select only numeric columns from X_train\n",
    "X_numeric = X_train.select_dtypes(include=\"number\")\n",
    "\n",
    "# Correlation matrix\n",
    "corr_matrix = X_numeric.corr()\n",
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation matrix for numeric features (Train set)\")\n",
    "plt.show()\n",
    "\n",
    "# Identify highly correlated pairs\n",
    "high_corr = []\n",
    "cols = corr_matrix.columns\n",
    "for i in range(len(cols)):\n",
    "    for j in range(i + 1, len(cols)):\n",
    "        corr_val = corr_matrix.iloc[i, j]\n",
    "        if abs(corr_val) > 0.9:\n",
    "            high_corr.append((cols[i], cols[j], corr_val))\n",
    "\n",
    "print(\"Highly correlated numeric pairs (|r|>0.9):\")\n",
    "for pair in high_corr:\n",
    "    print(pair)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\n",
    "    \"size_num\",\n",
    "    # \"living_area\",\n",
    "    # \"nr_rooms\",\n",
    "    # \"bathrooms\",\n",
    "    # \"toilets\",\n",
    "    \"num_facilities\",\n",
    "    # \"external_storage_num\",\n",
    "]\n",
    "X_train_final = X_train.copy()\n",
    "X_test_final = X_test.copy()\n",
    "X_val_final = X_val.copy()\n",
    "X_train_final.drop(columns=cols_to_drop, inplace=True)\n",
    "X_val_final.drop(columns=cols_to_drop, inplace=True)\n",
    "X_test_final.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "print(\"Train shape:\", X_train_final.shape)\n",
    "print(\"validation shape:\", X_val_final.shape)\n",
    "print(\"Test shape:\", X_test_final.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "## 13. Baseline models after feature engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "#### Baseline Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#no need for validation set her\n",
    "X_train_full = pd.concat([X_train_final, X_val_final], axis=0)\n",
    "y_train_full = pd.concat([y_train, y_val], axis=0)\n",
    "\n",
    "evaluator = ModelEvaluator(\n",
    "    target_transform=np.log1p,     # log-transform target for training\n",
    "    inverse_transform=np.expm1     # convert predictions back to original scale\n",
    ")\n",
    "\n",
    "rf_model = RandomForestRegressor()\n",
    "\n",
    "trained_rf, y_train_pred, y_val_pred, y_test_pred, rf_results = evaluator.evaluate(\n",
    "    model=rf_model,\n",
    "    X_train=X_train_full,\n",
    "    y_train=y_train_full,\n",
    "    X_test=X_test_final,\n",
    "    y_test=y_test,\n",
    "    use_xgb_train=False, \n",
    "\n",
    ")\n",
    "logger.log_model(trained_rf, \"Random_Forest_Regression_feature_eng\", rf_results,  use_xgb_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "#### Baseline XGboost with early stopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CONFIG_PATH = ROOT / \"house_price_prediction_project\" / \"config\" / \"model_config.yaml\"\n",
    "model_params, fit_params, _ = load_model_config_and_search_space(MODEL_CONFIG_PATH, model_name=\"xgboost_early_stopping\")\n",
    "\n",
    "fit_params_safe = fit_params.copy()\n",
    "n_estimators = fit_params_safe.pop(\"n_estimators\", 100)  \n",
    "\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=n_estimators,\n",
    "    **model_params\n",
    ")\n",
    "\n",
    "\n",
    "trained_xgb, y_train_pred, y_val_pred, y_test_pred, xgb_results = evaluator.evaluate(\n",
    "    xgb_model,\n",
    "    X_train_final,\n",
    "    y_train,\n",
    "    X_test_final,\n",
    "    y_test,\n",
    "    X_val=X_val_final,\n",
    "    y_val=y_val,\n",
    "    fit_params=fit_params,\n",
    "    use_xgb_train=True  # ensures early stopping is used\n",
    ")\n",
    "\n",
    "# Log model\n",
    "logger.log_model(trained_xgb, \"XGBoostRegressionFeatureEng\", xgb_results, use_xgb_train=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "## 14. Optuna tuning after feature eng\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost with log-transform\n",
    "\n",
    "from functools import partial\n",
    "from src.model.objectives_optuna import unified_objective\n",
    "\n",
    "FEATURES_AND_MODEL_CONFIG_PATH = (\n",
    "    ROOT\n",
    "    / \"house_price_prediction_project\"\n",
    "    / \"config\"\n",
    "    / \"model_config.yaml\"\n",
    ")\n",
    "\n",
    "sampler = optuna.samplers.TPESampler(seed=42)\n",
    "pruner = optuna.pruners.MedianPruner(n_warmup_steps=10)\n",
    "study_xgb = optuna.create_study(direction=\"minimize\", sampler=sampler, pruner=pruner)\n",
    "\n",
    "objective_xgb_partial = partial(\n",
    "    unified_objective,\n",
    "    model_name=\"xgboost_early_stopping_optuna_feature_eng\",\n",
    "    df=df_clean,\n",
    "    features_config=FEATURES_AND_MODEL_CONFIG_PATH,\n",
    "    model_config=FEATURES_AND_MODEL_CONFIG_PATH,\n",
    "    use_log=True,  \n",
    "    n_splits=5,\n",
    "    use_extended_features=True\n",
    ")\n",
    "study_xgb.optimize(objective_xgb_partial, n_trials=100)\n",
    "\n",
    "# # Random Forest with log-transform\n",
    "# study_rf = optuna.create_study(direction=\"minimize\")\n",
    "\n",
    "# objective_rf_partial = partial(\n",
    "#     unified_objective,\n",
    "#     model_name=\"random_forest_optuna_feature_eng\",\n",
    "#     df=df_clean,\n",
    "#     features_config=FEATURES_AND_MODEL_CONFIG_PATH,\n",
    "#     model_config=FEATURES_AND_MODEL_CONFIG_PATH,\n",
    "#     use_log=True,  \n",
    "#     n_splits=5,\n",
    "#     use_extended_features=True\n",
    "\n",
    "# )\n",
    "\n",
    "# study_rf.optimize(objective_rf_partial, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4e7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "\n",
    "# Suppose you have your study object already\n",
    "# study = optuna.load_study(study_name=\"your_study_name\", storage=\"your_storage\")\n",
    "\n",
    "# For demonstration, let's assume you have a study object:\n",
    "# study = your Optuna study from your XGBoost optimization\n",
    "\n",
    "# Extract trial numbers and values\n",
    "trial_numbers = [t.number for t in study_xgb.trials]\n",
    "objective_values = [t.value for t in study_xgb.trials]\n",
    "\n",
    "# Find the best trial\n",
    "best_trial = study_xgb.best_trial\n",
    "best_number = best_trial.number\n",
    "best_value = best_trial.value\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(trial_numbers, objective_values, color='blue', label='Trials')\n",
    "plt.scatter(best_number, best_value, color='red', s=100, label='Best Trial')\n",
    "plt.xlabel('Trial Number')\n",
    "plt.ylabel('Objective Value')\n",
    "plt.title('Optuna XGBoost Trials')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0f2d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "\n",
    "\n",
    "# Sort trials by number\n",
    "trials = sorted(study_xgb.trials, key=lambda t: t.number)\n",
    "trial_numbers = [t.number for t in trials]\n",
    "objective_values = [t.value for t in trials]\n",
    "\n",
    "# Compute best-so-far values\n",
    "best_so_far = []\n",
    "current_best = float('inf')  # minimizing objective\n",
    "best_trial_index = 0\n",
    "for i, value in enumerate(objective_values):\n",
    "    if value < current_best:\n",
    "        current_best = value\n",
    "        best_trial_index = i\n",
    "    best_so_far.append(current_best)\n",
    "\n",
    "# Best trial info\n",
    "best_trial = trials[best_trial_index]\n",
    "best_params = best_trial.params\n",
    "best_value = best_trial.value\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.scatter(trial_numbers, objective_values, color='lightblue', label='Trial Values')\n",
    "plt.plot(trial_numbers, best_so_far, color='red', linewidth=2, label='Best-So-Far')\n",
    "\n",
    "# Highlight best trial\n",
    "plt.scatter(best_trial.number, best_value, color='green', s=150, marker='*', label='Best Trial')\n",
    "\n",
    "# Annotate best trial hyperparameters\n",
    "param_text = \"\\n\".join([f\"{k}: {v}\" for k, v in best_params.items()])\n",
    "plt.annotate(f'Best Trial #{best_trial.number}\\nValue: {best_value:.4f}\\n{param_text}',\n",
    "             xy=(best_trial.number, best_value),\n",
    "             xytext=(best_trial.number + 0.5, best_value + 0.5),\n",
    "             arrowprops=dict(facecolor='black', arrowstyle='->'),\n",
    "             bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"yellow\", alpha=0.3))\n",
    "\n",
    "plt.xlabel('Trial Number')\n",
    "plt.ylabel('Objective Value')\n",
    "plt.title('Optuna XGBoost Optimization Convergence with Best Trial')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "## 15. Best params run after feature eng\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize evaluator with log-transform if used\n",
    "# evaluator = ModelEvaluator(target_transform=np.log1p, inverse_transform=np.expm1)\n",
    "\n",
    "# # --- Random Forest ---\n",
    "# best_rf = RandomForestRegressor(**study_rf.best_params)\n",
    "# trained_rf, y_train_pred, y_val_pred, y_test_pred, results_rf = evaluator.evaluate(\n",
    "#     model=best_rf,\n",
    "#     X_train=X_train_final,\n",
    "#     y_train=y_train,\n",
    "#     X_test=X_test_final,\n",
    "#     y_test=y_test,\n",
    "#     X_val=X_val_final,\n",
    "#     y_val=y_val,\n",
    "#     use_xgb_train=False,\n",
    "# )\n",
    "# logger.log_model(trained_rf, \"RF_LogTransform_Optuna_feature_eng\", results_rf, use_xgb_train=False)\n",
    "\n",
    "# --- XGBoost ---\n",
    "best_xgb_params = study_xgb.best_params\n",
    "trained_xgb, y_train_pred, y_val_pred, y_test_pred, results_xgb = evaluator.evaluate(\n",
    "    model=None,  # not used in XGBoost.train\n",
    "    X_train=X_train_final,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test_final,\n",
    "    y_test=y_test,\n",
    "    X_val=X_val_final,\n",
    "    y_val=y_val,\n",
    "    use_xgb_train=True,\n",
    "    model_params=best_xgb_params,  # <--- crucial\n",
    "    fit_params={\"num_boost_round\": 1000, \"early_stopping_rounds\": 50},\n",
    ")\n",
    "logger.log_model(trained_xgb, \"XGB_Optuna_LogTransformed_feature_eng\", results_xgb, use_xgb_train=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f902b8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "\n",
    "# --- Feature importance types ---\n",
    "importance_types = [\"weight\", \"gain\", \"cover\"]\n",
    "\n",
    "# Dictionary to hold sorted importance dataframes\n",
    "importance_dfs = {}\n",
    "\n",
    "for imp_type in importance_types:\n",
    "    # Get raw importance dictionary\n",
    "    raw_importance = trained_xgb.get_score(importance_type=imp_type)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df_imp = pd.DataFrame.from_dict(raw_importance, orient=\"index\", columns=[imp_type])\n",
    "    df_imp.index.name = \"feature\"\n",
    "    df_imp = df_imp.sort_values(by=imp_type, ascending=False)\n",
    "\n",
    "    importance_dfs[imp_type] = df_imp\n",
    "\n",
    "    # Print top features\n",
    "    print(f\"\\nTop 10 features by {imp_type}:\")\n",
    "    print(df_imp.head(80))\n",
    "\n",
    "    # Optional: plot top 20 features\n",
    "    df_imp.head(80).plot.barh(figsize=(8,6), legend=False, title=f\"Top 20 features by {imp_type}\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b688dc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "from src.model.cv_helpers import prepare_base_data\n",
    "from src.features.feature_engineering import feature_engineering_cv as fe_cv\n",
    "\n",
    "prepare_fold_features = fe_cv.prepare_fold_features\n",
    "\n",
    "# Number of folds (should match your CV setup)\n",
    "N_SPLITS = 5\n",
    "\n",
    "# Prepare base data (features + target)\n",
    "X_full, y_full = prepare_base_data(df_clean, FEATURES_AND_MODEL_CONFIG_PATH, \"xgboost_early_stopping_optuna_feature_eng\")\n",
    "\n",
    "importance_types = [\"weight\", \"gain\", \"cover\"]\n",
    "fold_importances = {imp_type: [] for imp_type in importance_types}\n",
    "\n",
    "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_full), 1):\n",
    "    X_train, X_val = X_full.iloc[train_idx].copy(), X_full.iloc[val_idx].copy()\n",
    "    y_train, y_val = y_full.iloc[train_idx].copy(), y_full.iloc[val_idx].copy()\n",
    "    \n",
    "    # Prepare fold-wise features (ensure extended feature engineering matches training)\n",
    "    X_train_fold, X_val_fold, _, _ = prepare_fold_features(X_train, X_val, use_extended_features=True)\n",
    "    \n",
    "    # Train XGBoost on this fold using best params\n",
    "    dtrain = xgb.DMatrix(X_train_fold, label=np.log1p(y_train))\n",
    "    dval = xgb.DMatrix(X_val_fold, label=np.log1p(y_val))\n",
    "    \n",
    "    model_fold = xgb.train(\n",
    "        params=best_xgb_params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=1000,\n",
    "        evals=[(dval, \"validation\")],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "    \n",
    "    # Collect importance for each type\n",
    "    for imp_type in importance_types:\n",
    "        imp_dict = model_fold.get_score(importance_type=imp_type)\n",
    "        df_imp = pd.DataFrame.from_dict(imp_dict, orient=\"index\", columns=[imp_type])\n",
    "        df_imp.index.name = \"feature\"\n",
    "        fold_importances[imp_type].append(df_imp)\n",
    "\n",
    "# --- Aggregate across folds ---\n",
    "agg_importances = {}\n",
    "for imp_type, dfs in fold_importances.items():\n",
    "    # Combine all folds into a single dataframe\n",
    "    df_all = pd.concat(dfs, axis=1).fillna(0)\n",
    "    df_all[\"mean\"] = df_all.mean(axis=1)\n",
    "    df_all = df_all.sort_values(by=\"mean\", ascending=False)\n",
    "    agg_importances[imp_type] = df_all\n",
    "    print(f\"\\nTop 10 features by mean {imp_type} across folds:\")\n",
    "    print(df_all[\"mean\"].head(100))\n",
    "    \n",
    "    # Plot top 20\n",
    "    df_all[\"mean\"].head(200).plot.barh(figsize=(10,6), title=f\"Top 20 features by mean {imp_type} across folds\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c15ac0",
   "metadata": {},
   "source": [
    "#### SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a898b485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "fold_shap_values = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_full), 1):\n",
    "    X_train, X_val = X_full.iloc[train_idx].copy(), X_full.iloc[val_idx].copy()\n",
    "    y_train, y_val = y_full.iloc[train_idx].copy(), y_full.iloc[val_idx].copy()\n",
    "    \n",
    "    # Prepare fold-wise features\n",
    "    X_train_fold, X_val_fold, _, _ = prepare_fold_features(X_train, X_val, use_extended_features=True)\n",
    "    \n",
    "    # Train XGBoost\n",
    "    dtrain = xgb.DMatrix(X_train_fold, label=np.log1p(y_train))\n",
    "    dval = xgb.DMatrix(X_val_fold, label=np.log1p(y_val))\n",
    "    \n",
    "    model_fold = xgb.train(\n",
    "        params=best_xgb_params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=1000,\n",
    "        evals=[(dval, \"validation\")],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "    \n",
    "    # --- SHAP ---\n",
    "    explainer = shap.Explainer(model_fold)\n",
    "    shap_values = explainer(X_val_fold)\n",
    "    \n",
    "    # Store mean absolute SHAP values per feature for this fold\n",
    "    fold_shap_values.append(pd.DataFrame({\n",
    "        \"feature\": X_val_fold.columns,\n",
    "        \"mean_abs_shap\": np.abs(shap_values.values).mean(axis=0)\n",
    "    }))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a34917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all folds\n",
    "df_shap_all = pd.concat(fold_shap_values)\n",
    "\n",
    "# Group by feature and compute mean across folds\n",
    "agg_shap = df_shap_all.groupby(\"feature\")[\"mean_abs_shap\"].mean().sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nTop 20 features by mean absolute SHAP value across folds:\")\n",
    "print(agg_shap.head(20))\n",
    "\n",
    "# Plot\n",
    "agg_shap.head(20).sort_values().plot.barh(figsize=(10,6), title=\"Top 20 features by SHAP value\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9812ad",
   "metadata": {},
   "source": [
    "#### DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"house_price_prediction\"\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "experiment_id = experiment.experiment_id\n",
    "\n",
    "\n",
    "runs_df = mlflow.search_runs(experiment_ids=[experiment_id])\n",
    "\n",
    "metrics_of_interest = [\n",
    "    \"metrics.train_rmse\",\n",
    "    \"metrics.test_rmse\",\n",
    "    \"metrics.train_r2\",\n",
    "    \"metrics.test_r2\",\n",
    "    \"metrics.train_mae\",\n",
    "    \"metrics.test_mae\",\n",
    "    \"metrics.train_mape\",\n",
    "    \"metrics.test_mape\",\n",
    "]\n",
    "comparison_df = runs_df[\n",
    "    [\"run_id\", \"tags.mlflow.runName\"] + metrics_of_interest\n",
    "]\n",
    "\n",
    "comparison_df.sort_values(\"metrics.test_mae\", ascending=True, inplace=True)\n",
    "comparison_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
