{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "#### 1. Imports and Set-up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "tracking_uri = \"../logs/mlruns\"\n",
    "os.makedirs(os.path.join(tracking_uri, \".trash\"), exist_ok=True)\n",
    "\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "mlflow.set_experiment(\"house_price_prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "#### 2. Load and prep data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "\n",
    "# Adjust the path to your project root folder\n",
    "project_root = os.path.abspath(\n",
    "    os.path.join(\"..\")\n",
    ")  # from notebooks/ up one level\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from src.data_loading.data_loading.data_loader import load_data_from_json\n",
    "from src.data_loading.preprocessing.preprocessing import preprocess_df\n",
    "from src.data_loading.preprocessing.imputation import impute_missing_values\n",
    "\n",
    "\n",
    "# go two levels up from notebook dir -> project root\n",
    "ROOT = (\n",
    "    Path(__file__).resolve().parents[2]\n",
    "    if \"__file__\" in globals()\n",
    "    else Path.cwd().parents[1]\n",
    ")\n",
    "CONFIG_PATH = (\n",
    "    ROOT\n",
    "    / \"house_price_prediction_project\"\n",
    "    / \"config\"\n",
    "    / \"preprocessing_config.yaml\"\n",
    ")\n",
    "\n",
    "with open(CONFIG_PATH) as f:\n",
    "    CONFIG = yaml.safe_load(f)\n",
    "\n",
    "df_raw = load_data_from_json(\"../data/parsed_json/*.json\")\n",
    "df_clean = preprocess_df(\n",
    "    df_raw,\n",
    "    drop_raw=CONFIG[\"preprocessing\"][\"drop_raw\"],\n",
    "    numeric_cols=CONFIG[\"preprocessing\"][\"numeric_cols\"],\n",
    ")\n",
    "df_clean = impute_missing_values(\n",
    "    df_clean, CONFIG[\"preprocessing\"][\"imputation\"]\n",
    ")\n",
    "# Drop price_num NaNs for the training of the model\n",
    "df_clean = df_clean[df_clean[\"price_num\"].notna()]\n",
    "df_clean.drop(columns=[\"living_area\"], inplace=True)\n",
    "# df_clean = df_clean[:100]\n",
    "df = df_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Path to your house_pages.txt\n",
    "file_path = (\n",
    "    ROOT\n",
    "    / \"house_price_prediction_project\"\n",
    "    / \"config\"\n",
    "    / \"house_pages_scraped.txt\"\n",
    ")\n",
    "\n",
    "# Read all URLs\n",
    "with open(file_path, \"r\") as f:\n",
    "    urls = f.read().splitlines()\n",
    "\n",
    "# ✅ Count koop/amsterdam\n",
    "count_amsterdam = sum(\n",
    "    1 for url in urls if \"koop\" in url.lower() and \"amsterdam\" in url.lower()\n",
    ")\n",
    "print(f\"Number of koop/amsterdam listings: {count_amsterdam}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.data_prep_for_modelling.data_preparation import prepare_data\n",
    "\n",
    "FEATURES_CONFIG_PATH = (\n",
    "    ROOT / \"house_price_prediction_project\" / \"config\" / \"model_config.yaml\"\n",
    ")\n",
    "\n",
    "# Scaled features (applies scaling according to YAML)\n",
    "X_train_scaled, X_test_scaled, y_train, y_test, X_val, y_val, scaler, _ = prepare_data(\n",
    "    df,\n",
    "    config_path=FEATURES_CONFIG_PATH,\n",
    "    model_name=\"linear_regression\",  # uses the unified YAML key\n",
    "    use_extended_features=False,       # set True if you want extended features\n",
    "    cv=False\n",
    ")\n",
    "\n",
    "# # Raw features (no scaling)\n",
    "# X_train_raw, X_test_raw, y_train, y_test, _, X_val_raw, y_val_raw = prepare_data(\n",
    "#     df,\n",
    "#     config_path=FEATURES_CONFIG_PATH,\n",
    "#     model_name=\"linear_regression\",\n",
    "#     use_extended_features=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "#### 4. Linear Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.evaluate import ModelEvaluator\n",
    "from src.model.mlflow_logger import MLFlowLogger\n",
    "\n",
    "evaluator = ModelEvaluator()\n",
    "logger = MLFlowLogger()\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# Evaluate\n",
    "trained_lr, y_train_pred, y_val_pred, y_test_pred, lr_results = evaluator.evaluate(\n",
    "    model=lr_model,\n",
    "    X_train=X_train_scaled,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test_scaled,\n",
    "    y_test=y_test,\n",
    "    model_params={},   \n",
    "    fit_params={},     \n",
    "    use_xgb_train=False\n",
    ")\n",
    "\n",
    "# Log the model and results\n",
    "logger.log_model(trained_lr, \"LinearRegression\", lr_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "#### 5. Random Forest Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.feature_engineering.encoding import encode_energy_label\n",
    "\n",
    "X_train, X_test, y_train, y_test, scaler, X_val, y_val, _ = prepare_data(\n",
    "    df_clean,\n",
    "    config_path=FEATURES_CONFIG_PATH, \n",
    "    model_name=\"random_forest\",\n",
    "    use_extended_features=False,     \n",
    "    cv=False \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.energy_label_encoded.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor()\n",
    "\n",
    "trained_rf, y_train_pred, y_val_pred, y_test_pred, rf_results = evaluator.evaluate(\n",
    "    model=rf_model,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    model_params={},  \n",
    "    fit_params={},    \n",
    "    use_xgb_train=False\n",
    ")\n",
    "logger.log_model(trained_rf, \"RandomForestRegression\", rf_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "#### 6. XGBoost model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.utils import load_model_config_and_search_space\n",
    "\n",
    "X_train, X_test, y_train, y_test, X_val, y_val, scaler, _ = prepare_data(\n",
    "    df_clean, config_path=FEATURES_CONFIG_PATH, model_name=\"xgboost\", \n",
    "    use_extended_features=False, cv=False\n",
    ")\n",
    "\n",
    "MODEL_CONFIG_PATH = (\n",
    "    ROOT / \"house_price_prediction_project\" / \"config\" / \"model_config.yaml\"\n",
    ")\n",
    "\n",
    "model_params, fit_params, _ = load_model_config_and_search_space(\n",
    "    MODEL_CONFIG_PATH, model_name=\"xgboost\"\n",
    ")\n",
    "fit_params_safe = fit_params.copy()\n",
    "n_estimators = fit_params_safe.pop(\"n_estimators\", 100)  \n",
    "\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=n_estimators,\n",
    "    **model_params\n",
    ")\n",
    "\n",
    "trained_xgb, y_train_pred, y_val_pred, y_test_pred, xgb_results = evaluator.evaluate(\n",
    "    xgb_model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    fit_params=fit_params_safe, \n",
    "    use_xgb_train=False,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    ")\n",
    "logger.log_model(trained_xgb, \"XGBoostRegression\", xgb_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "#### 7. XGBoost with early stopping and more tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, X_val, y_val, scaler, _ = prepare_data(\n",
    "    df_clean,\n",
    "    config_path=FEATURES_CONFIG_PATH,\n",
    "    model_name=\"xgboost_early_stopping\",\n",
    "    use_extended_features=False,\n",
    "    cv=False,\n",
    ")\n",
    "\n",
    "xgb_model_params, xgb_fit_params, _ = load_model_config_and_search_space(\n",
    "    MODEL_CONFIG_PATH, \"xgboost_early_stopping\"\n",
    ")\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(**xgb_model_params)\n",
    "\n",
    "\n",
    "trained_xgb, y_train_pred, y_val_pred, y_test_pred, xgb_results = evaluator.evaluate(\n",
    "    xgb_model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    fit_params=xgb_fit_params,\n",
    "    use_xgb_train=True,  \n",
    ")\n",
    "\n",
    "logger.log_model(\n",
    "    trained_xgb, \"xgb_with_early_stopping\", xgb_results, use_xgb_train=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "#### 7. Compare models using MLflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"house_price_prediction\"\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "experiment_id = experiment.experiment_id\n",
    "\n",
    "\n",
    "runs_df = mlflow.search_runs(experiment_ids=[experiment_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_of_interest = [\n",
    "    # Original scale\n",
    "    \"metrics.train_rmse\",\n",
    "    \"metrics.test_rmse\",\n",
    "    \"metrics.train_mae\",\n",
    "    \"metrics.test_mae\",\n",
    "    \"metrics.train_r2\",\n",
    "    \"metrics.test_r2\",\n",
    "    \"metrics.train_mape\",\n",
    "    \"metrics.test_mape\",\n",
    "    \n",
    "    # Log / transformed scale\n",
    "    # \"metrics.train_rmse_trans\",\n",
    "    # \"metrics.test_rmse_trans\",\n",
    "    # \"metrics.train_mae_trans\",\n",
    "    # \"metrics.test_mae_trans\",\n",
    "    # \"metrics.train_r2_trans\",\n",
    "    # \"metrics.test_r2_trans\",\n",
    "    # \"metrics.train_mape_trans\",\n",
    "    # \"metrics.test_mape_trans\",\n",
    "]\n",
    "comparison_df = runs_df[\n",
    "    [\"run_id\", \"tags.mlflow.runName\"] + metrics_of_interest\n",
    "]\n",
    "\n",
    "comparison_df.sort_values(\"metrics.test_r2\", ascending=False, inplace=True)\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = comparison_df.sort_values(\n",
    "    \"metrics.test_r2\", ascending=False\n",
    ").iloc[0]\n",
    "print(\"Best model based on test R²:\")\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "#### 8. Hyperparameter tuning with Optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from src.model.objectives_optuna import unified_objective\n",
    "\n",
    "FEATURES_AND_MODEL_CONFIG_PATH = (\n",
    "    ROOT\n",
    "    / \"house_price_prediction_project\"\n",
    "    / \"config\"\n",
    "    / \"model_config.yaml\"\n",
    ")\n",
    "\n",
    "# XGBoost study\n",
    "sampler = optuna.samplers.TPESampler(seed=42)\n",
    "pruner = optuna.pruners.MedianPruner(n_warmup_steps=10)\n",
    "study_xgb = optuna.create_study(direction=\"minimize\", sampler=sampler, pruner=pruner)\n",
    "objective_xgb_partial = partial(\n",
    "    unified_objective,\n",
    "    model_name=\"xgboost_early_stopping\",\n",
    "    df=df_clean,\n",
    "    features_config=FEATURES_AND_MODEL_CONFIG_PATH,\n",
    "    model_config=FEATURES_AND_MODEL_CONFIG_PATH,\n",
    "    use_extended_features=False,\n",
    ")\n",
    "study_xgb.optimize(objective_xgb_partial, n_trials=30)\n",
    "\n",
    "print(\"Best XGBoost params:\", study_xgb.best_params)\n",
    "print(\"Best XGBoost Test RMSE:\", study_xgb.best_value)\n",
    "\n",
    "# RandomForest study\n",
    "study_rf = optuna.create_study(direction=\"minimize\")\n",
    "objective_rf_partial = partial(\n",
    "    unified_objective,\n",
    "    model_name=\"random_forest_optuna\",\n",
    "    df=df_clean,\n",
    "    features_config=FEATURES_AND_MODEL_CONFIG_PATH,\n",
    "    model_config=FEATURES_AND_MODEL_CONFIG_PATH,\n",
    "    use_extended_features=False,\n",
    ")\n",
    "study_rf.optimize(objective_rf_partial, n_trials=30)\n",
    "\n",
    "print(\"Best RF params:\", study_rf.best_params)\n",
    "print(\"Best RF Test RMSE:\", study_rf.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "#### 9. RF and Xgboost with best parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = RandomForestRegressor(**study_rf.best_params)\n",
    "trained_rf, y_train_pred, y_val_pred, y_test_pred, results_rf = evaluator.evaluate(\n",
    "    model=best_rf,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    fit_params={},\n",
    ")\n",
    "\n",
    "logger.log_model(trained_rf, \"RF_Optuna\", results_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, X_val, y_val, _, _ = prepare_data(\n",
    "    df_clean,\n",
    "    config_path=FEATURES_AND_MODEL_CONFIG_PATH,\n",
    "    model_name=\"xgboost_early_stopping\",\n",
    "    use_extended_features=False,\n",
    "    cv=False\n",
    ")\n",
    "\n",
    "\n",
    "xgb_model_params, xgb_fit_params, _ = load_model_config_and_search_space(\n",
    "    MODEL_CONFIG_PATH, \"xgboost_early_stopping\"\n",
    ")\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(**study_xgb.best_params)\n",
    "\n",
    "trained_xgb, _, _, _, xgb_results = evaluator.evaluate(\n",
    "    model=xgb_model,  \n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    fit_params=xgb_fit_params,\n",
    "    use_xgb_train=True,\n",
    ")\n",
    "\n",
    "logger.log_model(\n",
    "    trained_xgb, \"xgb_with_early_stopping_optuna\", xgb_results, use_xgb_train=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "#### 10. Let's see how outliers skew RMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot target distribution\n",
    "sns.boxplot(y=y_test)\n",
    "plt.show()\n",
    "\n",
    "# Optional: scatter of predictions vs true values\n",
    "plt.scatter(y_test, y_test_pred, alpha=0.5)\n",
    "plt.xlabel(\"True\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute residuals\n",
    "residuals = y_test - y_test_pred\n",
    "\n",
    "# Summary stats\n",
    "print(\"Residuals summary:\")\n",
    "print(\"Min:\", np.min(residuals))\n",
    "print(\"Max:\", np.max(residuals))\n",
    "print(\"Median:\", np.median(residuals))\n",
    "print(\"Mean:\", np.mean(residuals))\n",
    "print(\"Std:\", np.std(residuals))\n",
    "\n",
    "# Plot histogram\n",
    "plt.hist(residuals, bins=50)\n",
    "plt.title(\"Residuals Distribution\")\n",
    "plt.xlabel(\"Residual\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Train MAE: {train_mae:.2f}\")\n",
    "print(f\"Test MAE:  {test_mae:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "So outliers are skewing the RMSE statistic quite heavily. Hence, I will log transform the target and dot he same analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = ModelEvaluator(\n",
    "    target_transform=np.log1p,\n",
    "    inverse_transform=np.expm1\n",
    ")\n",
    "best_rf = RandomForestRegressor(**study_rf.best_params)\n",
    "\n",
    "trained_rf, y_train_pred, y_val_pred, y_test_pred, results = evaluator.evaluate(\n",
    "    model=best_rf,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    use_xgb_train=False  \n",
    ")\n",
    "logger.log_model(trained_rf, \"RF_LogTransform_Evaluator\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Initialize XGBoost with best params (from previous Optuna run)\n",
    "best_xgb = XGBRegressor(**study_xgb.best_params)\n",
    "\n",
    "# Use log transform\n",
    "evaluator = ModelEvaluator(\n",
    "    target_transform=np.log1p,\n",
    "    inverse_transform=np.expm1\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "trained_xgb, y_train_pred, y_val_pred, y_test_pred, results = evaluator.evaluate(\n",
    "    model=best_xgb,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val,       \n",
    "    y_val=y_val,     \n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    use_xgb_train=True\n",
    ")\n",
    "\n",
    "# Log the trained model\n",
    "logger.log_model(\n",
    "    trained_xgb, \n",
    "    \"XGB_LogTransform_Evaluator\", \n",
    "    results, \n",
    "    use_xgb_train=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute residuals\n",
    "residuals = y_test - y_test_pred\n",
    "\n",
    "# Define extreme outliers: e.g., top 5% of absolute residuals\n",
    "threshold = np.percentile(np.abs(residuals), 95)\n",
    "outliers_mask = np.abs(residuals) >= threshold\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot non-outliers\n",
    "plt.scatter(\n",
    "    y_test[~outliers_mask],\n",
    "    y_test_pred[~outliers_mask],\n",
    "    alpha=0.5,\n",
    "    label=\"Normal listings\",\n",
    ")\n",
    "\n",
    "# Highlight extreme residuals\n",
    "plt.scatter(\n",
    "    y_test[outliers_mask],\n",
    "    y_test_pred[outliers_mask],\n",
    "    color=\"red\",\n",
    "    label=\"Extreme listings\",\n",
    ")\n",
    "\n",
    "# Diagonal line (perfect prediction)\n",
    "max_val = max(y_test.max(), y_test_pred.max())\n",
    "plt.plot(\n",
    "    [0, max_val],\n",
    "    [0, max_val],\n",
    "    color=\"black\",\n",
    "    linestyle=\"--\",\n",
    "    label=\"Perfect prediction\",\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Actual Price (€)\")\n",
    "plt.ylabel(\"Predicted Price (€)\")\n",
    "plt.title(\"Predicted vs Actual Prices with Extreme Listings Highlighted\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "This is a clear visualization to see how predictions behave across the entire range and highlight the extreme listings that inflate RMSE. Large RMSE is not a deal breaker since:\n",
    "\n",
    "**Statistical justification**\n",
    "Skewed distribution: My dataset has a few extremely expensive houses that are far from the mean. RMSE is sensitive to large errors because it squares residuals, so these few points dominate the metric.\n",
    "\n",
    "MAE is more robust: By reporting MAE alongside RMSE, I show the typical prediction error for most listings, which is a fairer assessment of model performance.\n",
    "\n",
    "Log-transform mitigates skew: Training on log1p(y) reduces the influence of outliers and stabilizes variance, producing a more reliable model for the bulk of the data.\n",
    "\n",
    "**Practical/business justification**\n",
    "\n",
    "The extreme listings (multi-million € homes) are rare. The model performs well on 99% of listings, which is what matters for most users or business decisions.\n",
    "\n",
    "Trying to perfectly predict the top 1–5% of luxury listings would:\n",
    "\n",
    "Require specialized models or additional data\n",
    "\n",
    "Complicate the pipeline\n",
    "\n",
    "Increase overfitting risk\n",
    "\n",
    "Reporting MAE and residual distributions communicates clearly that errors on extreme listings exist, but are expected and do not invalidate the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "#### 11. New approach and moving with optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost with log-transform\n",
    "sampler = optuna.samplers.TPESampler(seed=42)\n",
    "pruner = optuna.pruners.MedianPruner(n_warmup_steps=10)\n",
    "study_xgb = optuna.create_study(direction=\"minimize\", sampler=sampler, pruner=pruner)\n",
    "\n",
    "objective_xgb_partial = partial(\n",
    "    unified_objective,\n",
    "    model_name=\"xgboost_early_stopping\",\n",
    "    df=df_clean,\n",
    "    features_config=FEATURES_AND_MODEL_CONFIG_PATH,\n",
    "    model_config=FEATURES_AND_MODEL_CONFIG_PATH,\n",
    "    use_log=True,  \n",
    "    n_splits=5,\n",
    "    use_extended_features=False,\n",
    ")\n",
    "\n",
    "study_xgb.optimize(objective_xgb_partial, n_trials=30)\n",
    "\n",
    "# Random Forest with log-transform\n",
    "study_rf = optuna.create_study(direction=\"minimize\")\n",
    "\n",
    "objective_rf_partial = partial(\n",
    "    unified_objective,\n",
    "    model_name=\"random_forest_optuna\",\n",
    "    df=df_clean,\n",
    "    features_config=FEATURES_AND_MODEL_CONFIG_PATH,\n",
    "    model_config=FEATURES_AND_MODEL_CONFIG_PATH,\n",
    "    use_log=True,  \n",
    "    n_splits=5,\n",
    "    use_extended_features=False,\n",
    ")\n",
    "\n",
    "\n",
    "study_rf.optimize(objective_rf_partial, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize evaluator with log-transform (same as used in Optuna)\n",
    "evaluator = ModelEvaluator(\n",
    "    target_transform=np.log1p,\n",
    "    inverse_transform=np.expm1,\n",
    ")\n",
    "\n",
    "# --- Random Forest ---\n",
    "best_rf = RandomForestRegressor(**study_rf.best_params)\n",
    "trained_rf, y_train_pred, y_val_pred, y_test_pred, results_rf = evaluator.evaluate(\n",
    "    model=best_rf,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    use_xgb_train=False,  # RF uses sklearn API\n",
    ")\n",
    "logger.log_model(trained_rf, \"RF_Optuna_Log\", results_rf, use_xgb_train=False)\n",
    "\n",
    "# --- XGBoost ---\n",
    "best_xgb_params = study_xgb.best_params\n",
    "trained_xgb, y_train_pred, y_val_pred, y_test_pred, results_xgb = evaluator.evaluate(\n",
    "    model=None,  # we pass params dict instead of a model instance\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    use_xgb_train=True,  # XGBoost-specific training\n",
    "    model_params=best_xgb_params,  # pass best hyperparams\n",
    "    fit_params={\"num_boost_round\": 1000, \"early_stopping_rounds\": 50},  # you can tune these if needed\n",
    ")\n",
    "logger.log_model(trained_xgb, \"XGB_Optuna_Log\", results_xgb, use_xgb_train=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"house_price_prediction\"\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "experiment_id = experiment.experiment_id\n",
    "\n",
    "\n",
    "runs_df = mlflow.search_runs(experiment_ids=[experiment_id])\n",
    "\n",
    "runs_df['start_time_dt'] = pd.to_datetime(runs_df['start_time'], unit='ms')\n",
    "\n",
    "# Filter runs between two dates\n",
    "mask = (runs_df['start_time_dt'] >= '2025-09-18')\n",
    "\n",
    "metrics_of_interest = [\n",
    "    # Original scale\n",
    "    \"metrics.train_rmse\",\n",
    "    \"metrics.test_rmse\",\n",
    "    \"metrics.train_mae\",\n",
    "    \"metrics.test_mae\",\n",
    "    \"metrics.train_r2\",\n",
    "    \"metrics.test_r2\",\n",
    "    \"metrics.train_mape\",\n",
    "    \"metrics.test_mape\",\n",
    "    \n",
    "    # Log / transformed scale\n",
    "    # \"metrics.train_rmse_trans\",\n",
    "    # \"metrics.test_rmse_trans\",\n",
    "    # \"metrics.train_mae_trans\",\n",
    "    # \"metrics.test_mae_trans\",\n",
    "    # \"metrics.train_r2_trans\",\n",
    "    # \"metrics.test_r2_trans\",\n",
    "    # \"metrics.train_mape_trans\",\n",
    "    # \"metrics.test_mape_trans\",\n",
    "]\n",
    "comparison_df = runs_df[\n",
    "    [\"run_id\", \"tags.mlflow.runName\"] + metrics_of_interest\n",
    "]\n",
    "\n",
    "comparison_df.sort_values(\"metrics.test_mae\", ascending=True, inplace=True)\n",
    "comparison_df = comparison_df[mask]\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = comparison_df.sort_values(\n",
    "    \"metrics.test_mae\", ascending=True\n",
    ").iloc[0]\n",
    "print(\"Best model based on test MAE:\")\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "#### 12. Extra feature engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_AND_MODEL_CONFIG_PATH = (\n",
    "    ROOT\n",
    "    / \"house_price_prediction_project\"\n",
    "    / \"config\"\n",
    "    / \"model_config.yaml\"\n",
    ")\n",
    "# --- Prepare data for final modeling ---\n",
    "X_train, X_test, y_train, y_test, X_val, y_val, scaler, feature_encoders = prepare_data(\n",
    "    df=df_clean,\n",
    "    config_path=FEATURES_AND_MODEL_CONFIG_PATH,\n",
    "    model_name=\"xgboost_early_stopping\",  \n",
    "    use_extended_features=True,           \n",
    "    cv=False                              \n",
    ")\n",
    "\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Validation shape:\", X_val.shape if X_val is not None else None)\n",
    "print(\"Test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select only numeric columns from X_train\n",
    "X_numeric = X_train.select_dtypes(include=\"number\")\n",
    "\n",
    "# Correlation matrix\n",
    "corr_matrix = X_numeric.corr()\n",
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation matrix for numeric features (Train set)\")\n",
    "plt.show()\n",
    "\n",
    "# Identify highly correlated pairs\n",
    "high_corr = []\n",
    "cols = corr_matrix.columns\n",
    "for i in range(len(cols)):\n",
    "    for j in range(i + 1, len(cols)):\n",
    "        corr_val = corr_matrix.iloc[i, j]\n",
    "        if abs(corr_val) > 0.9:\n",
    "            high_corr.append((cols[i], cols[j], corr_val))\n",
    "\n",
    "print(\"Highly correlated numeric pairs (|r|>0.9):\")\n",
    "for pair in high_corr:\n",
    "    print(pair)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\n",
    "    \"size_num\",\n",
    "    # \"living_area\",\n",
    "    # \"nr_rooms\",\n",
    "    # \"bathrooms\",\n",
    "    # \"toilets\",\n",
    "    \"num_facilities\",\n",
    "    # \"external_storage_num\",\n",
    "]\n",
    "X_train_final = X_train.copy()\n",
    "X_test_final = X_test.copy()\n",
    "X_val_final = X_val.copy()\n",
    "X_train_final.drop(columns=cols_to_drop, inplace=True)\n",
    "X_val_final.drop(columns=cols_to_drop, inplace=True)\n",
    "X_test_final.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "print(\"Train shape:\", X_train_final.shape)\n",
    "print(\"validation shape:\", X_val_final.shape)\n",
    "print(\"Test shape:\", X_test_final.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "## 13. Baseline models after feature engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "#### Baseline Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#no need for validation set her\n",
    "X_train_full = pd.concat([X_train_final, X_val_final], axis=0)\n",
    "y_train_full = pd.concat([y_train, y_val], axis=0)\n",
    "\n",
    "evaluator = ModelEvaluator(\n",
    "    target_transform=np.log1p,     # log-transform target for training\n",
    "    inverse_transform=np.expm1     # convert predictions back to original scale\n",
    ")\n",
    "\n",
    "rf_model = RandomForestRegressor()\n",
    "\n",
    "trained_rf, y_train_pred, y_val_pred, y_test_pred, rf_results = evaluator.evaluate(\n",
    "    model=rf_model,\n",
    "    X_train=X_train_full,\n",
    "    y_train=y_train_full,\n",
    "    X_test=X_test_final,\n",
    "    y_test=y_test,\n",
    "    use_xgb_train=False, \n",
    "\n",
    ")\n",
    "logger.log_model(trained_rf, \"Random_Forest_Regression_feature_eng\", rf_results,  use_xgb_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "#### Baseline XGboost with early stopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CONFIG_PATH = ROOT / \"house_price_prediction_project\" / \"config\" / \"model_config.yaml\"\n",
    "model_params, fit_params, _ = load_model_config_and_search_space(MODEL_CONFIG_PATH, model_name=\"xgboost_early_stopping\")\n",
    "\n",
    "fit_params_safe = fit_params.copy()\n",
    "n_estimators = fit_params_safe.pop(\"n_estimators\", 100)  \n",
    "\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=n_estimators,\n",
    "    **model_params\n",
    ")\n",
    "\n",
    "\n",
    "trained_xgb, y_train_pred, y_val_pred, y_test_pred, xgb_results = evaluator.evaluate(\n",
    "    xgb_model,\n",
    "    X_train_final,\n",
    "    y_train,\n",
    "    X_test_final,\n",
    "    y_test,\n",
    "    X_val=X_val_final,\n",
    "    y_val=y_val,\n",
    "    fit_params=fit_params,\n",
    "    use_xgb_train=True  # ensures early stopping is used\n",
    ")\n",
    "\n",
    "# Log model\n",
    "logger.log_model(trained_xgb, \"XGBoostRegressionFeatureEng\", xgb_results, use_xgb_train=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "## 14. Optuna tuning after feature eng\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost with log-transform\n",
    "\n",
    "from functools import partial\n",
    "from src.model.objectives_optuna import unified_objective\n",
    "\n",
    "FEATURES_AND_MODEL_CONFIG_PATH = (\n",
    "    ROOT\n",
    "    / \"house_price_prediction_project\"\n",
    "    / \"config\"\n",
    "    / \"model_config.yaml\"\n",
    ")\n",
    "\n",
    "sampler = optuna.samplers.TPESampler(seed=42)\n",
    "pruner = optuna.pruners.MedianPruner(n_warmup_steps=10)\n",
    "study_xgb = optuna.create_study(direction=\"minimize\", sampler=sampler, pruner=pruner)\n",
    "\n",
    "objective_xgb_partial = partial(\n",
    "    unified_objective,\n",
    "    model_name=\"xgboost_early_stopping_optuna_feature_eng\",\n",
    "    df=df_clean,\n",
    "    features_config=FEATURES_AND_MODEL_CONFIG_PATH,\n",
    "    model_config=FEATURES_AND_MODEL_CONFIG_PATH,\n",
    "    use_log=True,  \n",
    "    n_splits=5,\n",
    "    use_extended_features=True\n",
    ")\n",
    "study_xgb.optimize(objective_xgb_partial, n_trials=30)\n",
    "\n",
    "# Random Forest with log-transform\n",
    "study_rf = optuna.create_study(direction=\"minimize\")\n",
    "\n",
    "objective_rf_partial = partial(\n",
    "    unified_objective,\n",
    "    model_name=\"random_forest_optuna_feature_eng\",\n",
    "    df=df_clean,\n",
    "    features_config=FEATURES_AND_MODEL_CONFIG_PATH,\n",
    "    model_config=FEATURES_AND_MODEL_CONFIG_PATH,\n",
    "    use_log=True,  \n",
    "    n_splits=5,\n",
    "    use_extended_features=True\n",
    "\n",
    ")\n",
    "\n",
    "study_rf.optimize(objective_rf_partial, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_clean.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "## 15. Best params run after feature eng\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize evaluator with log-transform if used\n",
    "evaluator = ModelEvaluator(target_transform=np.log1p, inverse_transform=np.expm1)\n",
    "\n",
    "# --- Random Forest ---\n",
    "best_rf = RandomForestRegressor(**study_rf.best_params)\n",
    "trained_rf, y_train_pred, y_val_pred, y_test_pred, results_rf = evaluator.evaluate(\n",
    "    model=best_rf,\n",
    "    X_train=X_train_final,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test_final,\n",
    "    y_test=y_test,\n",
    "    X_val=X_val_final,\n",
    "    y_val=y_val,\n",
    "    use_xgb_train=False,\n",
    ")\n",
    "logger.log_model(trained_rf, \"RF_LogTransform_Optuna_feature_eng\", results_rf, use_xgb_train=False)\n",
    "\n",
    "# --- XGBoost ---\n",
    "best_xgb_params = study_xgb.best_params\n",
    "trained_xgb, y_train_pred, y_val_pred, y_test_pred, results_xgb = evaluator.evaluate(\n",
    "    model=best_xgb_params,\n",
    "    X_train=X_train_final,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test_final,\n",
    "    y_test=y_test,\n",
    "    X_val=X_val_final,\n",
    "    y_val=y_val,\n",
    "    use_xgb_train=True,\n",
    "    fit_params={\"num_boost_round\": 1000, \"early_stopping_rounds\": 50},\n",
    ")\n",
    "logger.log_model(trained_xgb, \"XGB_Optuna_LogTransformed_feature_eng\", results_xgb, use_xgb_train=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"house_price_prediction\"\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "experiment_id = experiment.experiment_id\n",
    "\n",
    "\n",
    "runs_df = mlflow.search_runs(experiment_ids=[experiment_id])\n",
    "\n",
    "metrics_of_interest = [\n",
    "    \"metrics.train_rmse\",\n",
    "    \"metrics.test_rmse\",\n",
    "    \"metrics.train_r2\",\n",
    "    \"metrics.test_r2\",\n",
    "    \"metrics.train_mae\",\n",
    "    \"metrics.test_mae\",\n",
    "    \"metrics.train_mape\",\n",
    "    \"metrics.test_mape\",\n",
    "]\n",
    "comparison_df = runs_df[\n",
    "    [\"run_id\", \"tags.mlflow.runName\"] + metrics_of_interest\n",
    "]\n",
    "\n",
    "comparison_df.sort_values(\"metrics.test_mae\", ascending=True, inplace=True)\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "I have chosen run_id 33688ff883c54d2fb4a14cbef2ae617a because the combination of statistcs looks the best: one of the highest R2 for both test and train, and rmse and mae are one of the lowest ones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mlflow.get_tracking_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "run_id = \"33688ff883c54d2fb4a14cbef2ae617a\"\n",
    "client = MlflowClient()\n",
    "\n",
    "artifacts = client.list_artifacts(\n",
    "    run_id, path=\"xgb_model\"\n",
    ")  # match the artifact_path you used\n",
    "for a in artifacts:\n",
    "    print(a.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = \"33688ff883c54d2fb4a14cbef2ae617a\"\n",
    "model_path = f\"runs:/{run_id}/xgb_model\"\n",
    "\n",
    "# Load the model\n",
    "loaded_model = mlflow.xgboost.load_model(model_path)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = loaded_model.predict(dtest)  # dtest = xgb.DMatrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = mlflow.get_run(run_id)\n",
    "print(run.data.metrics)  # Train/test RMSE, R2, etc.\n",
    "print(run.data.params)  # Model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "# Register model\n",
    "model_uri = f\"runs:/{run_id}/xgb_model\"\n",
    "registered_model_name = \"RealEstate_XGB\"\n",
    "model_version = mlflow.register_model(model_uri, registered_model_name)\n",
    "\n",
    "print(\n",
    "    f\"Model registered as {registered_model_name}, version {model_version.version}\"\n",
    ")\n",
    "# saved the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = mlflow.get_run(run_id)\n",
    "print(run.data.metrics)  # Train/test RMSE, R2, etc.\n",
    "print(run.data.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare storage\n",
    "y_vals_all = []\n",
    "y_preds_all = []\n",
    "\n",
    "# Collect predictions from each fold\n",
    "for train_idx, val_idx in kf.split(X_np):\n",
    "    X_tr, X_val = X_np[train_idx], X_np[val_idx]\n",
    "    y_tr, y_val = y_np[train_idx], y_np[val_idx]\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_tr, label=np.log1p(y_tr))\n",
    "    dval = xgb.DMatrix(X_val, label=np.log1p(y_val))\n",
    "\n",
    "    xgb_model = xgb.train(\n",
    "        best_params,\n",
    "        dtrain,\n",
    "        num_boost_round=500,\n",
    "        evals=[(dval, \"eval\")],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=False,\n",
    "    )\n",
    "\n",
    "    y_val_pred = np.expm1(xgb_model.predict(dval))\n",
    "\n",
    "    y_vals_all.extend(y_val)\n",
    "    y_preds_all.extend(y_val_pred)\n",
    "\n",
    "# Convert to arrays\n",
    "y_vals_all = np.array(y_vals_all)\n",
    "y_preds_all = np.array(y_preds_all)\n",
    "residuals = y_vals_all - y_preds_all\n",
    "\n",
    "# Predicted vs Actual\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.scatterplot(x=y_vals_all, y=y_preds_all)\n",
    "plt.plot(\n",
    "    [y_vals_all.min(), y_vals_all.max()],\n",
    "    [y_vals_all.min(), y_vals_all.max()],\n",
    "    \"r--\",\n",
    "    label=\"Perfect Prediction\",\n",
    ")\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"CV: Predicted vs Actual (all folds)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Residual plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(residuals, kde=True, bins=20, color=\"skyblue\")\n",
    "plt.xlabel(\"Residual (Actual - Predicted)\")\n",
    "plt.title(\"CV Residuals Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "#### Generating price range (for pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Number of bins\n",
    "n_bins = 10\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\"pred\": y_preds_all, \"residual\": residuals})\n",
    "\n",
    "# Use qcut instead of cut to ensure roughly equal-sized bins\n",
    "df[\"pred_bin\"] = pd.qcut(df[\"pred\"], q=n_bins, duplicates=\"drop\")\n",
    "\n",
    "# Compute 5th and 95th percentiles per bin\n",
    "bin_ranges = (\n",
    "    df.groupby(\"pred_bin\")[\"residual\"]\n",
    "    .agg(\n",
    "        lower_bound=lambda x: np.percentile(x, 5),\n",
    "        upper_bound=lambda x: np.percentile(x, 95),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "# Function to get price range\n",
    "def get_price_range(pred_price):\n",
    "    for _, row in bin_ranges.iterrows():\n",
    "        if row[\"pred_bin\"].left <= pred_price <= row[\"pred_bin\"].right:\n",
    "            return (\n",
    "                pred_price + row[\"lower_bound\"],\n",
    "                pred_price + row[\"upper_bound\"],\n",
    "            )\n",
    "    return pred_price, pred_price  # fallback if outside all bins\n",
    "\n",
    "\n",
    "# Example\n",
    "example_pred = 500_000\n",
    "lb, ub = get_price_range(example_pred)\n",
    "print(f\"Predicted price: {example_pred}, Range: {lb:.0f} - {ub:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70",
   "metadata": {},
   "source": [
    "Need to just figure out logging these ranges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
